{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time \n",
    "import datetime \n",
    "import numpy as np\n",
    "from config1 import username1,password1,host1,port1,database1,census_key\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, func, inspect, desc\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from timeit import default_timer as timer\n",
    "from census import Census\n",
    "from us import states\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0711763\n"
     ]
    }
   ],
   "source": [
    "# Database Setup\n",
    "start = timer()\n",
    "connection1=f'{username1}:{password1}@{host1}:{port1}/{database1}'\n",
    "engine1 = create_engine(f'postgresql://{connection1}')\n",
    "\n",
    "# Pull Data\n",
    "orders=pd.read_sql_query('select * from orders', con=engine1)\n",
    "state_heatmap=pd.read_sql_query('select * from state_heatmap', con=engine1)\n",
    "county_heatmap=pd.read_sql_query('select * from county_heatmap', con=engine1)\n",
    "state_cases=pd.read_sql_query('select * from state_cases', con=engine1)\n",
    "state_deaths=pd.read_sql_query('select * from state_deaths', con=engine1)\n",
    "county_cases1=pd.read_sql_query('select * from county_cases1', con=engine1)\n",
    "county_cases2=pd.read_sql_query('select * from county_cases2', con=engine1)\n",
    "county_cases3=pd.read_sql_query('select * from county_cases3', con=engine1)\n",
    "county_deaths1=pd.read_sql_query('select * from county_deaths1', con=engine1)\n",
    "county_deaths2=pd.read_sql_query('select * from county_deaths2', con=engine1)\n",
    "county_deaths3=pd.read_sql_query('select * from county_deaths3', con=engine1)\n",
    "\n",
    "# Concats\n",
    "county_cases=pd.concat([county_cases1,county_cases2,county_cases3], ignore_index=True)\n",
    "county_deaths=pd.concat([county_deaths1,county_deaths2,county_deaths3], ignore_index=True)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5179384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry Randall\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "C:\\Users\\Henry Randall\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    }
   ],
   "source": [
    "# Call Cencus Data\n",
    "start = timer()\n",
    "c = Census(census_key, year=2018)\n",
    "census_data = c.acs5.get(('B01003_001E', 'B17001_002E','B19013_001E','B01001A_002E','B01001A_017E','B01002_001E','B02001_001E',\n",
    "                          'B02001_003E','B03001_003E'), {'for': 'county:*'})\n",
    "\n",
    "# Convert to DataFrame\n",
    "census_df = pd.DataFrame(census_data)\n",
    "\n",
    "# Column Reordering\n",
    "census_df= census_df.rename(columns={'B01003_001E': 'Population',\n",
    "                                     'B17001_002E': 'Poverty Count',\n",
    "                                     'B19013_001E': 'Median Household Income',\n",
    "                                     'B01001A_002E': 'male pop',\n",
    "                                     'B01001A_017E':'female pop',\n",
    "                                     'B01002_001E': 'median age',\n",
    "                                     'B02001_001E': 'total race pop',\n",
    "                                     'B02001_003E': 'black pop',\n",
    "                                     'B03001_003E': 'hispanic pop',\n",
    "                                     'state':'State',\n",
    "                                     'county':'County'})\n",
    "census_df['fips']=census_df['State']+census_df['County']\n",
    "census_df['%male']=census_df['male pop']/(census_df['male pop']+census_df['female pop'])\n",
    "census_df['%black']=census_df['black pop']/(census_df['total race pop'])\n",
    "census_df['%hispanic']=census_df['hispanic pop']/(census_df['total race pop'])\n",
    "state_census1=census_df.groupby(\"State\")[\"Population\",'Poverty Count','male pop','female pop','total race pop',\n",
    "                                        'black pop','hispanic pop'].sum()\n",
    "state_census2=census_df.groupby(\"State\")[\"Median Household Income\",'median age'].mean()\n",
    "state_census1['%male']=state_census1['male pop']/(state_census1['male pop']+state_census1['female pop'])\n",
    "state_census1['%black']=state_census1['black pop']/(state_census1['total race pop'])\n",
    "state_census1['%hispanic']=state_census1['hispanic pop']/(state_census1['total race pop'])\n",
    "census_df=census_df.drop(['male pop','female pop','total race pop','black pop','hispanic pop'], axis=1)\n",
    "state_census1=state_census1.drop(['male pop','female pop','total race pop','black pop','hispanic pop'], axis=1)\n",
    "state_census1=state_census1.reset_index()\n",
    "state_census2=state_census2.reset_index()\n",
    "state_census1=state_census1.rename(columns={'State':'fips'})\n",
    "state_census2=state_census2.rename(columns={'State':'fips'})\n",
    "state_census=state_census1.merge(state_census2,on='fips')\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0260071999999987\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_area={}\n",
    "with open('stateborders.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "data=data['features']\n",
    "k=0\n",
    "for state in data:\n",
    "    state_area[k] = {\"state\":data[k]['properties']['NAME'],\"fips\": data[k]['properties']['STATE'],\n",
    "                     \"area\": data[k]['properties']['CENSUSAREA']}\n",
    "    k=k+1\n",
    "state_area = pd.DataFrame.from_dict(state_area, \"index\")\n",
    "\n",
    "county_area={}\n",
    "with open('countyborders.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "data=data['features']\n",
    "k=0\n",
    "for county in data:\n",
    "    county_area[k] = {\"fips\": (data[k]['properties']['STATE'])+(data[k]['properties']['COUNTY']),\n",
    "                      \"area\": data[k]['properties']['CENSUSAREA']}\n",
    "    k=k+1\n",
    "county_area = pd.DataFrame.from_dict(county_area, \"index\")\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01188020000000023\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_census=state_census.merge(state_area, on='fips')\n",
    "state_census.iloc[8,8]='District Of Columbia'\n",
    "county_census=census_df.merge(county_area, on='fips')\n",
    "county_census.iloc[291,1]=10300\n",
    "county_census.iloc[291,2]=33422\n",
    "state_census['Poverty Rate'] = 100 * \\\n",
    "    state_census['Poverty Count'].astype(\n",
    "        int) / state_census['Population'].astype(int)\n",
    "state_census['Population Density'] = 1 * \\\n",
    "    state_census['Population'].astype(\n",
    "        int) / state_census['area'].astype(int)\n",
    "state_census=state_census.drop(['Poverty Count','area'], axis=1)\n",
    "# Convert Poverty Copunt to Poverty Rate (Poverty Count / Population)\n",
    "county_census['Poverty Rate'] = 100 * \\\n",
    "    county_census['Poverty Count'].astype(\n",
    "        int) / county_census['Population'].astype(int)\n",
    "county_census['Population Density'] = 1 * \\\n",
    "    county_census['Population'].astype(\n",
    "        int) / county_census['area'].astype(int)\n",
    "county_census=county_census.drop(['Poverty Count','area','State','County'], axis=1)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_heatmap=county_heatmap.merge(county_census,on='fips')\n",
    "state_heatmap=state_heatmap.merge(state_census,on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latdata_url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "latdata=pd.read_csv(latdata_url, error_bad_lines=False)\n",
    "latdata=latdata.rename(columns={'Province_State': 'State'})\n",
    "latdata=latdata.reset_index()\n",
    "latdata=latdata.drop(columns=['index'])\n",
    "latdata.dropna(subset = [\"Admin2\"], inplace=True)\n",
    "latdata=latdata[latdata.Admin2 != 'Unassigned']\n",
    "latdata=latdata.dropna()\n",
    "latdata=latdata[~latdata['Admin2'].astype(str).str.startswith('Out of')]\n",
    "latdata=latdata[latdata.Admin2 != 'Out of*']\n",
    "latdata=latdata.reset_index()\n",
    "latdata['FIPS']=latdata.FIPS.map('{0:0>5.0f}'.format)\n",
    "latdata=latdata[['State','FIPS','Lat','Long_']]\n",
    "state_latdata=latdata.groupby('State').mean()\n",
    "latdata=latdata.drop(columns=['State'])\n",
    "state_latdata=state_latdata.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "cases_model = keras.models.load_model(\"Cases\")\n",
    "deaths_model = keras.models.load_model(\"Deaths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Loops Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2097.2675296\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "# Set number of days to predict\n",
    "n=14\n",
    "for q in range(n):\n",
    "    # Trim Matrix to only what we need for the models\n",
    "    county_cases_cut=county_cases.copy()\n",
    "    county_deaths_cut=county_deaths.copy()\n",
    "    state_cases_cut=state_cases.copy()\n",
    "    state_deaths_cut=state_deaths.copy()\n",
    "    county_cases_cut.drop(county_cases_cut.columns[3:-14],axis=1,inplace=True)\n",
    "    county_deaths_cut.drop(county_deaths_cut.columns[3:-8],axis=1,inplace=True)\n",
    "    state_cases_cut.drop(state_cases_cut.columns[1:-14],axis=1,inplace=True)\n",
    "    state_deaths_cut.drop(state_deaths_cut.columns[1:-8],axis=1,inplace=True)\n",
    "\n",
    "    #Find daily totals - county cases\n",
    "    county_cases_cut_daily=county_cases_cut.copy()\n",
    "    [r,c]=county_cases_cut_daily.shape\n",
    "    for j in range (0,r):\n",
    "        last=0\n",
    "        for i in range (3,c):\n",
    "            current=county_cases_cut_daily.iloc[j,i]-last\n",
    "            last=county_cases_cut_daily.iloc[j,i]\n",
    "            county_cases_cut_daily.iat[j,i]=current\n",
    "    county_cases_cut_daily.drop(county_cases_cut_daily.columns[3],axis=1,inplace=True)     \n",
    "\n",
    "    #Find daily totals - county deaths\n",
    "    county_deaths_cut_daily=county_deaths_cut.copy()\n",
    "    [r,c]=county_deaths_cut_daily.shape\n",
    "    for j in range (0,r):\n",
    "        last=0\n",
    "        for i in range (3,c):\n",
    "            current=county_deaths_cut_daily.iloc[j,i]-last\n",
    "            last=county_deaths_cut_daily.iloc[j,i]\n",
    "            county_deaths_cut_daily.iat[j,i]=current    \n",
    "    county_deaths_cut_daily.drop(county_deaths_cut_daily.columns[3],axis=1,inplace=True)\n",
    "\n",
    "    #Find daily totals - state cases\n",
    "    state_cases_cut_daily=state_cases_cut.copy()\n",
    "    [r,c]=state_cases_cut_daily.shape\n",
    "    for j in range (0,r):\n",
    "        last=0\n",
    "        for i in range (1,c):\n",
    "            current=state_cases_cut_daily.iloc[j,i]-last\n",
    "            last=state_cases_cut_daily.iloc[j,i]\n",
    "            state_cases_cut_daily.iat[j,i]=current\n",
    "    state_cases_cut_daily.drop(state_cases_cut_daily.columns[1],axis=1,inplace=True)\n",
    "\n",
    "    #Find daily totals - state deaths\n",
    "    state_deaths_cut_daily=state_deaths_cut.copy()\n",
    "    [r,c]=state_deaths_cut_daily.shape\n",
    "    for j in range (0,r):\n",
    "        last=0\n",
    "        for i in range (1,c):\n",
    "            current=state_deaths_cut_daily.iloc[j,i]-last\n",
    "            last=state_deaths_cut_daily.iloc[j,i]\n",
    "            state_deaths_cut_daily.iat[j,i]=current\n",
    "    state_deaths_cut_daily.drop(state_deaths_cut_daily.columns[1],axis=1,inplace=True)\n",
    "\n",
    "    #Find 7day totals - county cases\n",
    "    county_cases_cut_7day=county_cases_cut_daily.copy()\n",
    "    [r,c]=county_cases_cut_7day.shape\n",
    "    for j in range (0,r):\n",
    "        for i in range (9,c):\n",
    "            county_cases_cut_7day.iloc[j,i]=statistics.mean([county_cases_cut_daily.iloc[j,i-6],county_cases_cut_daily.iloc[j,i-5],\n",
    "                    county_cases_cut_daily.iloc[j,i-4],county_cases_cut_daily.iloc[j,i-3],county_cases_cut_daily.iloc[j,i-3],\n",
    "                    county_cases_cut_daily.iloc[j,i-1],county_cases_cut_daily.iloc[j,i]])\n",
    "    county_cases_cut_7day = county_cases_cut_7day.drop(county_cases_cut_7day.columns[3:9],axis=1)\n",
    "\n",
    "    #Find 7day totals - county deaths\n",
    "    county_deaths_cut_7day=county_deaths_cut_daily.copy()\n",
    "    [r,c]=county_deaths_cut_7day.shape\n",
    "    for j in range (0,r):\n",
    "        last=0\n",
    "        for i in range (9,c):\n",
    "            county_deaths_cut_7day.iloc[j,i]=statistics.mean([county_deaths_cut_daily.iloc[j,i-6],county_deaths_cut_daily.iloc[j,i-5],\n",
    "                    county_deaths_cut_daily.iloc[j,i-4],county_deaths_cut_daily.iloc[j,i-3],county_deaths_cut_daily.iloc[j,i-3],\n",
    "                    county_deaths_cut_daily.iloc[j,i-1],county_deaths_cut_daily.iloc[j,i]])\n",
    "    county_deaths_cut_7day = county_deaths_cut_7day.drop(county_deaths_cut_7day.columns[3:9],axis=1)\n",
    "\n",
    "    #Find 7day totals - state cases\n",
    "    state_cases_cut_7day=state_cases_cut_daily.copy()\n",
    "    [r,c]=state_cases_cut_7day.shape\n",
    "    for j in range (0,r):\n",
    "        for i in range (7,c):\n",
    "            state_cases_cut_7day.iloc[j,i]=statistics.mean([state_cases_cut_daily.iloc[j,i-6],state_cases_cut_daily.iloc[j,i-5],\n",
    "                    state_cases_cut_daily.iloc[j,i-4],state_cases_cut_daily.iloc[j,i-3],state_cases_cut_daily.iloc[j,i-2],\n",
    "                    state_cases_cut_daily.iloc[j,i-1],state_cases_cut_daily.iloc[j,i]])\n",
    "    state_cases_cut_7day = state_cases_cut_7day.drop(state_cases_cut_7day.columns[1:7],axis=1)\n",
    "\n",
    "    #Find 7day totals - county deaths\n",
    "    state_deaths_cut_7day=state_deaths_cut_daily.copy()\n",
    "    [r,c]=state_deaths_cut_7day.shape\n",
    "    for j in range (0,r):\n",
    "        last=0\n",
    "        for i in range (7,c):\n",
    "            state_deaths_cut_7day.iloc[j,i]=statistics.mean([state_deaths_cut_daily.iloc[j,i-6],state_deaths_cut_daily.iloc[j,i-5],\n",
    "                    state_deaths_cut_daily.iloc[j,i-4],state_deaths_cut_daily.iloc[j,i-3],state_deaths_cut_daily.iloc[j,i-2],\n",
    "                    state_deaths_cut_daily.iloc[j,i-1],state_deaths_cut_daily.iloc[j,i]])\n",
    "    state_deaths_cut_7day = state_deaths_cut_7day.drop(state_deaths_cut_7day.columns[1:7],axis=1)\n",
    "\n",
    "    # Cut out day 1 cases for the death model\n",
    "    countycases1_cut_7day=county_cases_cut_7day.copy()\n",
    "    statecases1_cut_7day=state_cases_cut_7day.copy()\n",
    "    countycases1_cut_7day.drop(countycases1_cut_7day.columns[4:],axis=1,inplace=True)\n",
    "    statecases1_cut_7day.drop(statecases1_cut_7day.columns[2:],axis=1,inplace=True)\n",
    "    county_cases_cut_7day.drop(county_cases_cut_7day.columns[3:-1],axis=1,inplace=True)\n",
    "    state_cases_cut_7day.drop(state_cases_cut_7day.columns[1:-1],axis=1,inplace=True)\n",
    "\n",
    "    # Proximity Cases - State\n",
    "    rad5_state_7day={}\n",
    "    [r,c]=state_cases_cut_7day.shape\n",
    "    for j in range (0,r):\n",
    "        lat=state_latdata.iloc[j,1]\n",
    "        lon=state_latdata.iloc[j,2]\n",
    "        index5=[]\n",
    "        for k in range (0,r):\n",
    "            dist=math.sqrt(((state_latdata.iloc[k,1]-lat)**2)+((state_latdata.iloc[k,2]-lon)**2))\n",
    "            if dist<5:\n",
    "                index5.append(state_latdata.iloc[k,0])\n",
    "        rad5_state_7day[j]=((((state_cases_cut_7day[state_cases_cut_7day['State'].isin(index5)]).sum())[1:])/(((state_heatmap[state_heatmap['state'].str.lower().isin([x.lower() for x in index5])]).sum())['population']))*100000\n",
    "    rad5_state_7day = pd.DataFrame.from_dict(rad5_state_7day, \"index\")\n",
    "    rad5_state_7day.insert(0, 'State', state_cases_cut_7day['State'])\n",
    "    rad5_state_7day = rad5_state_7day.fillna(0)\n",
    "\n",
    "    # Proximity Cases - County\n",
    "    rad5_county_7day={}\n",
    "    [r,c]=county_cases_cut_7day.shape\n",
    "    for j in range (0,r):\n",
    "        lat=latdata.iloc[j,1]\n",
    "        lon=latdata.iloc[j,2]\n",
    "        index5=[]\n",
    "        for k in range (0,r):\n",
    "            dist=math.sqrt(((latdata.iloc[k,1]-lat)**2)+((latdata.iloc[k,2]-lon)**2))\n",
    "            if dist<5:\n",
    "                index5.append(latdata.iloc[k,0])\n",
    "        rad5_county_7day[j]=((((county_cases_cut_7day[county_cases_cut_7day['FIPS'].isin(index5)]).sum())[3:])/(((county_heatmap[county_heatmap['fips'].isin(index5)]).sum())['population']))*100000\n",
    "    rad5_county_7day = pd.DataFrame.from_dict(rad5_county_7day, \"index\")\n",
    "    rad5_county_7day.insert(0, 'FIPS', county_cases_cut_7day['FIPS'])\n",
    "    rad5_county_7day.insert(1, 'County', county_cases_cut_7day['County'])\n",
    "    rad5_county_7day.insert(2, 'State', county_cases_cut_7day['State'])\n",
    "    rad5_county_7day = rad5_county_7day.fillna(0)\n",
    "\n",
    "    # Trim Dataframes\n",
    "    county_cases_cut.drop(county_cases_cut.columns[1:-1],axis=1,inplace=True)\n",
    "    county_deaths_cut.drop(county_deaths_cut.columns[1:-1],axis=1,inplace=True)\n",
    "    state_cases_cut.drop(state_cases_cut.columns[1:-1],axis=1,inplace=True)\n",
    "    state_deaths_cut.drop(state_deaths_cut.columns[1:-1],axis=1,inplace=True)\n",
    "\n",
    "    #  State Cases Forecast\n",
    "    state_predict_cases=state_heatmap[['state','Population','Population Density','%black','%hispanic','median age']]\n",
    "    state_predict_deaths=state_heatmap[['state','Population','Population Density','%black','%hispanic','Median Household Income',\n",
    "                                        'median age']]\n",
    "\n",
    "    state_predict_cases.iloc[8,0]='District of Columbia'\n",
    "    state_predict_deaths.iloc[8,0]='District of Columbia'\n",
    "\n",
    "    state_predict_cases=state_predict_cases.merge(state_cases_cut, left_on='state', right_on='State')\n",
    "    state_predict_cases.drop('State',axis=1,inplace=True)\n",
    "    state_predict_cases.columns = [*state_predict_cases.columns[:-1], 'day7']\n",
    "    state_predict_cases['day7']=(state_predict_cases['day7']*10000)/state_predict_cases['Population']\n",
    "\n",
    "    state_predict_cases=state_predict_cases.merge(rad5_state_7day, left_on='state', right_on='State')\n",
    "    state_predict_cases.drop('State',axis=1,inplace=True)\n",
    "    state_predict_cases.columns = [*state_predict_cases.columns[:-1], 'rad5']\n",
    "\n",
    "    state_predict_cases=state_predict_cases.merge(state_cases_cut_7day, left_on='state', right_on='State')\n",
    "    state_predict_cases.columns = [*state_predict_cases.columns[:-1], '7day7']\n",
    "    state_predict_cases['7day7']=(state_predict_cases['7day7']*10000)/state_predict_cases['Population']\n",
    "    state_predict_cases.drop('State',axis=1,inplace=True)\n",
    "\n",
    "    # State Death Forecast\n",
    "    state_predict_deaths=state_predict_deaths.merge(statecases1_cut_7day, left_on='state', right_on='State')\n",
    "    state_predict_deaths.columns = [*state_predict_deaths.columns[:-1], 'casesday1']\n",
    "    state_predict_deaths.drop('State',axis=1,inplace=True)\n",
    "    state_predict_deaths['casesday1']=(state_predict_deaths['casesday1']*10000)/state_predict_deaths['Population']\n",
    "\n",
    "    state_predict_deaths=state_predict_deaths.merge(state_deaths_cut, left_on='state', right_on='State')\n",
    "    state_predict_deaths.columns = [*state_predict_deaths.columns[:-1], 'day7']\n",
    "    state_predict_deaths.drop('State',axis=1,inplace=True)\n",
    "    state_predict_deaths['day7']=(state_predict_deaths['day7']*10000)/state_predict_deaths['Population']\n",
    "\n",
    "    state_predict_deaths=state_predict_deaths.merge(state_deaths_cut_7day, left_on='state', right_on='State')\n",
    "    state_predict_deaths.columns = [*state_predict_deaths.columns[:-1], '7day7']\n",
    "    state_predict_deaths['7day7']=(state_predict_deaths['7day7']*10000)/state_predict_deaths['Population']\n",
    "    state_predict_deaths.drop('State',axis=1,inplace=True)\n",
    "\n",
    "    # County Cases Forecast\n",
    "    county_predict_cases=county_heatmap[['fips','Population','Population Density','%black','%hispanic','median age']]\n",
    "    county_predict_deaths=county_heatmap[['fips','Population','Population Density','%black','%hispanic','Median Household Income',\n",
    "                                        'median age']]\n",
    "\n",
    "    county_predict_cases=county_predict_cases.merge(county_cases_cut, left_on='fips', right_on='FIPS')\n",
    "    county_predict_cases.drop('FIPS',axis=1,inplace=True)\n",
    "    county_predict_cases.columns = [*county_predict_cases.columns[:-1], 'day7']\n",
    "    county_predict_cases['day7']=(county_predict_cases['day7']*10000)/county_predict_cases['Population']\n",
    "\n",
    "    county_predict_cases=county_predict_cases.merge(rad5_county_7day, left_on='fips', right_on='FIPS')\n",
    "    county_predict_cases.drop('FIPS',axis=1,inplace=True)\n",
    "    county_predict_cases.columns = [*county_predict_cases.columns[:-1], 'rad5']\n",
    "    county_predict_cases.drop('State',axis=1,inplace=True)\n",
    "    county_predict_cases.drop('County',axis=1,inplace=True)\n",
    "\n",
    "    county_predict_cases=county_predict_cases.merge(county_cases_cut_7day, left_on='fips', right_on='FIPS')\n",
    "    county_predict_cases.drop('FIPS',axis=1,inplace=True)\n",
    "    county_predict_cases.columns = [*county_predict_cases.columns[:-1], '7day7']\n",
    "    county_predict_cases['7day7']=(county_predict_cases['7day7']*10000)/county_predict_cases['Population']\n",
    "    county_predict_cases.drop('State',axis=1,inplace=True)\n",
    "    county_predict_cases.drop('County',axis=1,inplace=True)\n",
    "\n",
    "    # County Deaths forecast\n",
    "    county_predict_deaths=county_predict_deaths.merge(countycases1_cut_7day, left_on='fips', right_on='FIPS')\n",
    "    county_predict_deaths.columns = [*county_predict_deaths.columns[:-1], 'casesday1']\n",
    "    county_predict_deaths.drop('FIPS',axis=1,inplace=True)\n",
    "    county_predict_deaths['casesday1']=(county_predict_deaths['casesday1']*10000)/county_predict_deaths['Population']\n",
    "    county_predict_deaths.drop('State',axis=1,inplace=True)\n",
    "    county_predict_deaths.drop('County',axis=1,inplace=True)\n",
    "\n",
    "    county_predict_deaths=county_predict_deaths.merge(county_deaths_cut, left_on='fips', right_on='FIPS')\n",
    "    county_predict_deaths.columns = [*county_predict_deaths.columns[:-1], 'day7']\n",
    "    county_predict_deaths.drop('FIPS',axis=1,inplace=True)\n",
    "    county_predict_deaths['day7']=(county_predict_deaths['day7']*10000)/county_predict_deaths['Population']\n",
    "\n",
    "    county_predict_deaths=county_predict_deaths.merge(county_deaths_cut_7day, left_on='fips', right_on='FIPS')\n",
    "    county_predict_deaths.columns = [*county_predict_deaths.columns[:-1], '7day7']\n",
    "    county_predict_deaths['7day7']=(county_predict_deaths['7day7']*10000)/county_predict_deaths['Population']\n",
    "    county_predict_deaths.drop('FIPS',axis=1,inplace=True)\n",
    "    county_predict_deaths.drop('State',axis=1,inplace=True)\n",
    "    county_predict_deaths.drop('County',axis=1,inplace=True)\n",
    "\n",
    "    # Predict State Deaths\n",
    "    state_predict_deaths1=state_predict_deaths.copy()\n",
    "    state_predict_deaths1.drop(state_predict_deaths1.columns[:2],axis=1,inplace=True)\n",
    "    state_predict_deaths['prediction']= deaths_model.predict(state_predict_deaths1)\n",
    "    state_predict_deaths['prediction']=((state_predict_deaths['prediction']*state_predict_deaths['Population']))/10000\n",
    "    state_predict_deaths.drop(state_predict_deaths.columns[1:-1],axis=1,inplace=True)\n",
    "    state_predict_deaths['prediction']=state_predict_deaths['prediction'].astype(np.int64)\n",
    "    num = state_predict_deaths._get_numeric_data()\n",
    "    num[num < 0] = 0\n",
    "\n",
    "    # Predict State Cases\n",
    "    state_predict_cases1=state_predict_cases.copy()\n",
    "    state_predict_cases1.drop(state_predict_cases1.columns[:2],axis=1,inplace=True)\n",
    "    state_predict_cases['prediction']= cases_model.predict(state_predict_cases1)\n",
    "    state_predict_cases['prediction']=((state_predict_cases['prediction']*state_predict_cases['Population']))/10000\n",
    "    state_predict_cases.drop(state_predict_cases.columns[1:-1],axis=1,inplace=True)\n",
    "    state_predict_cases['prediction']=state_predict_cases['prediction'].astype(np.int64)\n",
    "    num = state_predict_cases._get_numeric_data()\n",
    "    num[num < 0] = 0\n",
    "\n",
    "    # Predict County Deaths\n",
    "    county_predict_deaths1=county_predict_deaths.copy()\n",
    "    county_predict_deaths1.drop(county_predict_deaths1.columns[:2],axis=1,inplace=True)\n",
    "    county_predict_deaths['prediction']= deaths_model.predict(county_predict_deaths1)\n",
    "    county_predict_deaths['prediction']=((county_predict_deaths['prediction']*county_predict_deaths['Population']))/10000\n",
    "    county_predict_deaths.drop(county_predict_deaths.columns[1:-1],axis=1,inplace=True)\n",
    "    county_predict_deaths['prediction']=county_predict_deaths['prediction'].astype(np.int64)\n",
    "    num = county_predict_deaths._get_numeric_data()\n",
    "    num[num < 0] = 0\n",
    "\n",
    "    # Predict County Cases\n",
    "    county_predict_cases1=county_predict_cases.copy()\n",
    "    county_predict_cases1.drop(county_predict_cases1.columns[:2],axis=1,inplace=True)\n",
    "    county_predict_cases['prediction']= cases_model.predict(county_predict_cases1)\n",
    "    county_predict_cases['prediction']=((county_predict_cases['prediction']*county_predict_cases['Population']))/10000\n",
    "    county_predict_cases.drop(county_predict_cases.columns[1:-1],axis=1,inplace=True)\n",
    "    county_predict_cases['prediction']=county_predict_cases['prediction'].astype(np.int64)\n",
    "    num = county_predict_cases._get_numeric_data()\n",
    "    num[num < 0] = 0\n",
    "\n",
    "    # Merge State Cases\n",
    "    state_cases=state_cases.merge(state_predict_cases,left_on='State',right_on='state')\n",
    "    state_cases.drop('state',axis=1,inplace=True)\n",
    "    state_cases['prediction']=state_cases['prediction']+state_cases.iloc[:,-2]\n",
    "    newdate=pd.to_datetime(state_cases.columns[-2])\n",
    "    newdate=newdate+pd.DateOffset(1)\n",
    "    newdate= newdate.strftime(\"%#m/%d/%y\")\n",
    "    state_cases = state_cases.rename(columns={\"prediction\": newdate})\n",
    "\n",
    "    # Merge State Deaths\n",
    "    state_deaths=state_deaths.merge(state_predict_deaths,left_on='State',right_on='state')\n",
    "    state_deaths.drop('state',axis=1,inplace=True)\n",
    "    state_deaths['prediction']=state_deaths['prediction']+state_deaths.iloc[:,-2]\n",
    "    newdate=pd.to_datetime(state_deaths.columns[-2])\n",
    "    newdate=newdate+pd.DateOffset(1)\n",
    "    newdate= newdate.strftime(\"%#m/%d/%y\")\n",
    "    state_deaths = state_deaths.rename(columns={\"prediction\": newdate})\n",
    "\n",
    "    # Merge County Cases\n",
    "    county_cases=county_cases.merge(county_predict_cases,left_on='FIPS',right_on='fips')\n",
    "    county_cases.drop('fips',axis=1,inplace=True)\n",
    "    county_cases['prediction']=county_cases['prediction']+county_cases.iloc[:,-2]\n",
    "    newdate=pd.to_datetime(county_cases.columns[-2])\n",
    "    newdate=newdate+pd.DateOffset(1)\n",
    "    newdate= newdate.strftime(\"%#m/%d/%y\")\n",
    "    county_cases=county_cases.rename(columns={\"prediction\": newdate})\n",
    "\n",
    "    # Merge County Death\n",
    "    county_deaths=county_deaths.merge(county_predict_deaths,left_on='FIPS',right_on='fips')\n",
    "    county_deaths.drop('fips',axis=1,inplace=True)\n",
    "    county_deaths['prediction']=county_deaths['prediction']+county_deaths.iloc[:,-2]\n",
    "    newdate=pd.to_datetime(county_deaths.columns[-2])\n",
    "    newdate=newdate+pd.DateOffset(1)\n",
    "    newdate= newdate.strftime(\"%#m/%d/%y\")\n",
    "    county_deaths = county_deaths.rename(columns={\"prediction\": newdate})\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Arrays\n",
    "[county_cases1,county_cases2,county_cases3]=np.array_split(county_cases, 3)\n",
    "[county_deaths1,county_deaths2,county_deaths3]=np.array_split(county_deaths,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_cases1.to_sql(name='county_cases1', con=engine1, if_exists='replace', index=False)\n",
    "county_cases2.to_sql(name='county_cases2', con=engine1, if_exists='replace', index=False)\n",
    "county_cases3.to_sql(name='county_cases3', con=engine1, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_deaths1.to_sql(name='county_deaths1', con=engine1, if_exists='replace', index=False)\n",
    "county_deaths2.to_sql(name='county_deaths2', con=engine1, if_exists='replace', index=False)\n",
    "county_deaths3.to_sql(name='county_deaths3', con=engine1, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cases.to_sql(name='state_cases', con=engine1, if_exists='replace', index=False)\n",
    "state_deaths.to_sql(name='state_deaths', con=engine1, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
