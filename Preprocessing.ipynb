{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time \n",
    "import datetime \n",
    "import numpy as np\n",
    "from config1 import username1,password1,host1,port1,database1,census_key\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, func, inspect, desc\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from timeit import default_timer as timer\n",
    "from census import Census\n",
    "from us import states\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.254906100000001\n"
     ]
    }
   ],
   "source": [
    "# Database Setup\n",
    "start = timer()\n",
    "connection1=f'{username1}:{password1}@{host1}:{port1}/{database1}'\n",
    "engine1 = create_engine(f'postgresql://{connection1}')\n",
    "\n",
    "# Pull Data\n",
    "state_heatmap=pd.read_sql_query('select * from state_heatmap', con=engine1)\n",
    "county_heatmap=pd.read_sql_query('select * from county_heatmap', con=engine1)\n",
    "state_cases=pd.read_sql_query('select * from state_cases', con=engine1)\n",
    "state_deaths=pd.read_sql_query('select * from state_deaths', con=engine1)\n",
    "county_cases1=pd.read_sql_query('select * from county_cases1', con=engine1)\n",
    "county_cases2=pd.read_sql_query('select * from county_cases2', con=engine1)\n",
    "county_cases3=pd.read_sql_query('select * from county_cases3', con=engine1)\n",
    "county_deaths1=pd.read_sql_query('select * from county_deaths1', con=engine1)\n",
    "county_deaths2=pd.read_sql_query('select * from county_deaths2', con=engine1)\n",
    "county_deaths3=pd.read_sql_query('select * from county_deaths3', con=engine1)\n",
    "\n",
    "# Concats\n",
    "county_cases=pd.concat([county_cases1,county_cases2,county_cases3], ignore_index=True)\n",
    "county_deaths=pd.concat([county_deaths1,county_deaths2,county_deaths3], ignore_index=True)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.889087400000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry Randall\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    }
   ],
   "source": [
    "# Call Cencus Data\n",
    "start = timer()\n",
    "c = Census(census_key, year=2018)\n",
    "census_data = c.acs5.get(('B01003_001E', 'B17001_002E'), {'for': 'county:*'})\n",
    "\n",
    "# Convert to DataFrame\n",
    "census_df = pd.DataFrame(census_data)\n",
    "\n",
    "# Column Reordering\n",
    "census_df= census_df.rename(columns={'B01003_001E': 'Population',\n",
    "                                      'B17001_002E': 'Poverty Count',\n",
    "                                      'state':'State',\n",
    "                                     'county':'County'})\n",
    "\n",
    "\n",
    "census_df['fips']=census_df['State']+census_df['County']\n",
    "state_census=census_df.groupby(\"State\")[\"Population\",'Poverty Count'].sum()\n",
    "state_census=state_census.reset_index()\n",
    "state_census=state_census.rename(columns={'State':'fips'})\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9507721999999994\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_area={}\n",
    "with open('stateborders.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "data=data['features']\n",
    "k=0\n",
    "for state in data:\n",
    "    state_area[k] = {\"state\":data[k]['properties']['NAME'],\"fips\": data[k]['properties']['STATE'],\n",
    "                     \"area\": data[k]['properties']['CENSUSAREA']}\n",
    "    k=k+1\n",
    "state_area = pd.DataFrame.from_dict(state_area, \"index\")\n",
    "\n",
    "county_area={}\n",
    "with open('countyborders.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "data=data['features']\n",
    "k=0\n",
    "for county in data:\n",
    "    county_area[k] = {\"fips\": (data[k]['properties']['STATE'])+(data[k]['properties']['COUNTY']),\n",
    "                      \"area\": data[k]['properties']['CENSUSAREA']}\n",
    "    k=k+1\n",
    "county_area = pd.DataFrame.from_dict(county_area, \"index\")\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011291599999999846\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_census=state_census.merge(state_area, on='fips')\n",
    "state_census.iloc[8,3]='District Of Columbia'\n",
    "county_census=census_df.merge(county_area, on='fips')\n",
    "county_census.iloc[291,1]=10300\n",
    "state_census['Poverty Rate'] = 100 * \\\n",
    "    state_census['Poverty Count'].astype(\n",
    "        int) / state_census['Population'].astype(int)\n",
    "state_census['Population Density'] = 1 * \\\n",
    "    state_census['Population'].astype(\n",
    "        int) / state_census['area'].astype(int)\n",
    "state_census=state_census.drop(['Poverty Count','Population','area'], axis=1)\n",
    "# Convert Poverty Copunt to Poverty Rate (Poverty Count / Population)\n",
    "county_census['Poverty Rate'] = 100 * \\\n",
    "    county_census['Poverty Count'].astype(\n",
    "        int) / county_census['Population'].astype(int)\n",
    "county_census['Population Density'] = 1 * \\\n",
    "    county_census['Population'].astype(\n",
    "        int) / county_census['area'].astype(int)\n",
    "county_census=county_census.drop(['Poverty Count','Population','area','State','County'], axis=1)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_heatmap=county_heatmap.merge(county_census,on='fips')\n",
    "state_heatmap=state_heatmap.merge(state_census,on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latdata_url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "latdata=pd.read_csv(latdata_url, error_bad_lines=False)\n",
    "latdata=latdata.rename(columns={'Province_State': 'State'})\n",
    "latdata=latdata.reset_index()\n",
    "latdata=latdata.drop(columns=['index'])\n",
    "latdata.dropna(subset = [\"Admin2\"], inplace=True)\n",
    "latdata=latdata[latdata.Admin2 != 'Unassigned']\n",
    "latdata=latdata.dropna()\n",
    "latdata=latdata[~latdata['Admin2'].astype(str).str.startswith('Out of')]\n",
    "latdata=latdata[latdata.Admin2 != 'Out of*']\n",
    "latdata=latdata.reset_index()\n",
    "latdata['FIPS']=latdata.FIPS.map('{0:0>5.0f}'.format)\n",
    "latdata=latdata[['State','FIPS','Lat','Long_']]\n",
    "state_latdata=latdata.groupby('State').mean()\n",
    "latdata=latdata.drop(columns=['State'])\n",
    "state_latdata=state_latdata.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.623744099999996\n",
      "9.969637499999997\n"
     ]
    }
   ],
   "source": [
    "#Find daily totals - county cases\n",
    "start = timer()\n",
    "county_cases_daily=county_cases.copy()\n",
    "[r,c]=county_cases_daily.shape\n",
    "for j in range (0,r):\n",
    "    last=0\n",
    "    for i in range (3,c):\n",
    "        current=county_cases_daily.iloc[j,i]-last\n",
    "        last=county_cases_daily.iloc[j,i]\n",
    "        county_cases_daily.iat[j,i]=current\n",
    "end = timer()\n",
    "print(end - start)        \n",
    "\n",
    "start = timer()\n",
    "#Find daily totals - county deaths\n",
    "county_deaths_daily=county_deaths.copy()\n",
    "[r,c]=county_deaths_daily.shape\n",
    "for j in range (0,r):\n",
    "    last=0\n",
    "    for i in range (3,c):\n",
    "        current=county_deaths_daily.iloc[j,i]-last\n",
    "        last=county_deaths_daily.iloc[j,i]\n",
    "        county_deaths_daily.iat[j,i]=current\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16332540000000506\n",
      "0.1655350999999996\n"
     ]
    }
   ],
   "source": [
    "#Find daily totals - state cases\n",
    "start = timer()\n",
    "state_cases_daily=state_cases.copy()\n",
    "[r,c]=state_cases_daily.shape\n",
    "for j in range (0,r):\n",
    "    last=0\n",
    "    for i in range (2,c):\n",
    "        current=state_cases_daily.iloc[j,i]-last\n",
    "        last=state_cases_daily.iloc[j,i]\n",
    "        state_cases_daily.iat[j,i]=current\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "#Find daily totals - state deaths\n",
    "start = timer()\n",
    "state_deaths_daily=state_deaths.copy()\n",
    "[r,c]=state_deaths_daily.shape\n",
    "for j in range (0,r):\n",
    "    last=0\n",
    "    for i in range (2,c):\n",
    "        current=state_deaths_daily.iloc[j,i]-last\n",
    "        last=state_deaths_daily.iloc[j,i]\n",
    "        state_deaths_daily.iat[j,i]=current\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.0308085\n",
      "176.3043653\n"
     ]
    }
   ],
   "source": [
    "#Find 7day totals - county cases\n",
    "start = timer()\n",
    "county_cases_7day=county_cases_daily.copy()\n",
    "[r,c]=county_cases_7day.shape\n",
    "for j in range (0,r):\n",
    "    for i in range (9,c):\n",
    "        county_cases_7day.iloc[j,i]=statistics.mean([county_cases_daily.iloc[j,i-6],county_cases_daily.iloc[j,i-5],\n",
    "                county_cases_daily.iloc[j,i-4],county_cases_daily.iloc[j,i-3],county_cases_daily.iloc[j,i-3],\n",
    "                county_cases_daily.iloc[j,i-1],county_cases_daily.iloc[j,i]])\n",
    "county_cases_7day = county_cases_7day.drop([county_cases_7day.columns[3],county_cases_7day.columns[4],\n",
    "                                         county_cases_7day.columns[5],county_cases_7day.columns[6],\n",
    "                                         county_cases_7day.columns[7],county_cases_7day.columns[8]],axis=1)\n",
    "end = timer()\n",
    "print(end - start)        \n",
    "\n",
    "start = timer()\n",
    "#Find 7day totals - county deaths\n",
    "county_deaths_7day=county_deaths_daily.copy()\n",
    "[r,c]=county_deaths_7day.shape\n",
    "for j in range (0,r):\n",
    "    last=0\n",
    "    for i in range (9,c):\n",
    "        county_deaths_7day.iloc[j,i]=statistics.mean([county_deaths_daily.iloc[j,i-6],county_deaths_daily.iloc[j,i-5],\n",
    "                county_deaths_daily.iloc[j,i-4],county_deaths_daily.iloc[j,i-3],county_deaths_daily.iloc[j,i-3],\n",
    "                county_deaths_daily.iloc[j,i-1],county_deaths_daily.iloc[j,i]])\n",
    "county_deaths_7day = county_deaths_7day.drop([county_deaths_7day.columns[1],county_deaths_7day.columns[2],\n",
    "                                         county_deaths_7day.columns[3],county_deaths_7day.columns[4],\n",
    "                                         county_deaths_7day.columns[5],county_deaths_7day.columns[6]],axis=1)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7941308999999706\n",
      "2.7158294000000183\n"
     ]
    }
   ],
   "source": [
    "#Find 7day totals - state cases\n",
    "start = timer()\n",
    "state_cases_7day=state_cases_daily.copy()\n",
    "[r,c]=state_cases_7day.shape\n",
    "for j in range (0,r):\n",
    "    for i in range (7,c):\n",
    "        state_cases_7day.iloc[j,i]=statistics.mean([state_cases_daily.iloc[j,i-6],state_cases_daily.iloc[j,i-5],\n",
    "                state_cases_daily.iloc[j,i-4],state_cases_daily.iloc[j,i-3],state_cases_daily.iloc[j,i-3],\n",
    "                state_cases_daily.iloc[j,i-1],state_cases_daily.iloc[j,i]])\n",
    "state_cases_7day = state_cases_7day.drop([state_cases_7day.columns[1],state_cases_7day.columns[2],\n",
    "                                         state_cases_7day.columns[3],state_cases_7day.columns[4],\n",
    "                                         state_cases_7day.columns[5],state_cases_7day.columns[6]],axis=1)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "start = timer()\n",
    "#Find 7day totals - county deaths\n",
    "state_deaths_7day=state_deaths_daily.copy()\n",
    "[r,c]=state_deaths_7day.shape\n",
    "for j in range (0,r):\n",
    "    last=0\n",
    "    for i in range (7,c):\n",
    "        state_deaths_7day.iloc[j,i]=statistics.mean([state_deaths_daily.iloc[j,i-6],state_deaths_daily.iloc[j,i-5],\n",
    "                state_deaths_daily.iloc[j,i-4],state_deaths_daily.iloc[j,i-3],state_deaths_daily.iloc[j,i-3],\n",
    "                state_deaths_daily.iloc[j,i-1],state_deaths_daily.iloc[j,i]])\n",
    "state_deaths_7day = state_deaths_7day.drop([state_deaths_7day.columns[1],state_deaths_7day.columns[2],\n",
    "                                         state_deaths_7day.columns[3],state_deaths_7day.columns[4],\n",
    "                                         state_deaths_7day.columns[5],state_deaths_7day.columns[6]],axis=1)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625742999999943\n"
     ]
    }
   ],
   "source": [
    "# Proximity Cases - State\n",
    "start = timer()\n",
    "rad2_state_7day={}\n",
    "rad5_state_7day={}\n",
    "rad10_state_7day={}\n",
    "[r,c]=state_cases_7day.shape\n",
    "for j in range (0,r):\n",
    "    lat=state_latdata.iloc[j,1]\n",
    "    lon=state_latdata.iloc[j,2]\n",
    "    index2=[]\n",
    "    index5=[]\n",
    "    index10=[]\n",
    "    for k in range (0,r):\n",
    "        dist=math.sqrt(((state_latdata.iloc[k,1]-lat)**2)+((state_latdata.iloc[k,2]-lon)**2))\n",
    "        if dist<2:\n",
    "            index2.append(k)\n",
    "        if dist<5:\n",
    "            index5.append(k)\n",
    "        if dist<10:\n",
    "            index10.append(k)\n",
    "    rad2_state_7day[j]=((((state_cases_7day.iloc[index2,:]).sum())[1:])/(((state_heatmap.iloc[index2,:]).sum())['population']))*100000\n",
    "    rad5_state_7day[j]=((((state_cases_7day.iloc[index5,:]).sum())[1:])/(((state_heatmap.iloc[index5,:]).sum())['population']))*100000\n",
    "    rad10_state_7day[j]=((((state_cases_7day.iloc[index10,:]).sum())[1:])/(((state_heatmap.iloc[index10,:]).sum())['population']))*100000\n",
    "rad2_state_7day = pd.DataFrame.from_dict(rad2_state_7day, \"index\")\n",
    "rad2_state_7day.insert(0, 'State', state_cases_7day['State'])\n",
    "rad5_state_7day = pd.DataFrame.from_dict(rad5_state_7day, \"index\")\n",
    "rad5_state_7day.insert(0, 'State', state_cases_7day['State'])\n",
    "rad10_state_7day = pd.DataFrame.from_dict(rad10_state_7day, \"index\")\n",
    "rad10_state_7day.insert(0, 'State', state_cases_7day['State'])\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.96999450000004\n"
     ]
    }
   ],
   "source": [
    "# Proximity Cases - County\n",
    "start = timer()\n",
    "rad2_county_7day={}\n",
    "rad5_county_7day={}\n",
    "rad10_county_7day={}\n",
    "[r,c]=county_cases_7day.shape\n",
    "for j in range (0,r):\n",
    "    lat=latdata.iloc[j,1]\n",
    "    lon=latdata.iloc[j,2]\n",
    "    index2=[]\n",
    "    index5=[]\n",
    "    index10=[]\n",
    "    for k in range (0,r):\n",
    "        dist=math.sqrt(((latdata.iloc[k,1]-lat)**2)+((latdata.iloc[k,2]-lon)**2))\n",
    "        if dist<2:\n",
    "            index2.append(k)\n",
    "        if dist<5:\n",
    "            index5.append(k)\n",
    "        if dist<10:\n",
    "            index10.append(k)\n",
    "    rad2_county_7day[j]=((((county_cases_7day.iloc[index2,:]).sum())[3:])/(((county_heatmap.iloc[index2,:]).sum())['population']))*100000\n",
    "    rad5_county_7day[j]=((((county_cases_7day.iloc[index5,:]).sum())[3:])/(((county_heatmap.iloc[index5,:]).sum())['population']))*100000\n",
    "    rad10_county_7day[j]=((((county_cases_7day.iloc[index10,:]).sum())[3:])/(((county_heatmap.iloc[index10,:]).sum())['population']))*100000\n",
    "rad2_county_7day = pd.DataFrame.from_dict(rad2_county_7day, \"index\")\n",
    "rad2_county_7day.insert(0, 'FIPS', county_cases_7day['FIPS'])\n",
    "rad2_county_7day.insert(1, 'County', county_cases_7day['County'])\n",
    "rad2_county_7day.insert(2, 'State', county_cases_7day['State'])\n",
    "rad5_county_7day = pd.DataFrame.from_dict(rad5_county_7day, \"index\")\n",
    "rad5_county_7day.insert(0, 'FIPS', county_cases_7day['FIPS'])\n",
    "rad5_county_7day.insert(1, 'County', county_cases_7day['County'])\n",
    "rad5_county_7day.insert(2, 'State', county_cases_7day['State'])\n",
    "rad10_county_7day = pd.DataFrame.from_dict(rad10_county_7day, \"index\")\n",
    "rad10_county_7day.insert(0, 'FIPS', county_cases_7day['FIPS'])\n",
    "rad10_county_7day.insert(1, 'County', county_cases_7day['County'])\n",
    "rad10_county_7day.insert(2, 'State', county_cases_7day['State'])\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7242737999999918\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_cases_popcorrected={}\n",
    "k=0\n",
    "[r,c]=state_cases.shape\n",
    "for j in range (0,r):\n",
    "    pop=state_heatmap.iloc[j,3]\n",
    "    pov=state_heatmap.iloc[j,13]\n",
    "    popden=state_heatmap.iloc[j,14]\n",
    "    for i in range (7,c-7):\n",
    "        if state_cases.iloc[j,i+1]>0:\n",
    "            state_cases_popcorrected[k] = {\"pov\": pov,\"popden\": popden,\"day1\": (state_cases.iloc[j,i]*100000)/pop,\n",
    "\"day2\":(state_cases.iloc[j,i+1]*100000)/pop,\"day3\":(state_cases.iloc[j,i+2]*100000)/pop,\n",
    "\"day4\":(state_cases.iloc[j,i+3]*100000)/pop,\"day5\":(state_cases.iloc[j,i+4]*100000)/pop,\n",
    "\"day6\":(state_cases.iloc[j,i+5]*100000)/pop,\"day7\":(state_cases.iloc[j,i+6]*100000)/pop,                      \n",
    "\"rad27day1\": (rad2_state_7day.iloc[j,i-6]),\"rad27day2\":(rad2_state_7day.iloc[j,i-5]),\n",
    "\"rad27day3\":(rad2_state_7day.iloc[j,i-4]),\"rad27day4\":(rad2_state_7day.iloc[j,i-3]),\n",
    "\"rad27day5\":(rad2_state_7day.iloc[j,i-2]),\"rad27day6\":(rad2_state_7day.iloc[j,i-1]),\n",
    "\"rad27day7\":(rad2_state_7day.iloc[j,i]),\"rad57day1\": (rad5_state_7day.iloc[j,i-6]),\n",
    "\"rad57day2\":(rad5_state_7day.iloc[j,i-5]),\"rad57day3\":(rad5_state_7day.iloc[j,i-4]),\n",
    "\"rad57day4\":(rad5_state_7day.iloc[j,i-3]),\"rad57day5\":(rad5_state_7day.iloc[j,i-2]),\n",
    "\"rad57day6\":(rad5_state_7day.iloc[j,i-1]),\"rad57day7\":(rad5_state_7day.iloc[j,i]),                                \n",
    "\"rad107day1\": (rad10_state_7day.iloc[j,i-6]),\"rad107day2\":(rad10_state_7day.iloc[j,i-5]),\n",
    "\"rad107day3\":(rad10_state_7day.iloc[j,i-4]),\"rad107day4\":(rad10_state_7day.iloc[j,i-3]),\n",
    "\"rad107day5\":(rad10_state_7day.iloc[j,i-2]),\"rad107day6\":(rad10_state_7day.iloc[j,i-1]),\n",
    "\"rad107day7\":(rad10_state_7day.iloc[j,i]),\"7day1\": (state_cases_7day.iloc[j,i-6]*100000)/pop,\n",
    "\"7day2\":(state_cases_7day.iloc[j,i-5]*100000)/pop,\"7day3\":(state_cases_7day.iloc[j,i-4]*100000)/pop,\n",
    "\"7day4\":(state_cases_7day.iloc[j,i-3]*100000)/pop,\"7day5\":(state_cases_7day.iloc[j,i-2]*100000)/pop,\n",
    "\"7day6\":(state_cases_7day.iloc[j,i-1]*100000)/pop,\"7day7\":(state_cases_7day.iloc[j,i]*100000)/pop,\n",
    "\"7day8\":(state_cases_7day.iloc[j,i+1]*100000)/pop}\n",
    "            k=k+1\n",
    "state_cases_popcorrected = pd.DataFrame.from_dict(state_cases_popcorrected, \"index\")\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2937795999999935\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_deaths_popcorrected={}\n",
    "k=0\n",
    "[r,c]=state_deaths.shape\n",
    "for j in range (0,r):\n",
    "    pop=state_heatmap.iloc[j,3]\n",
    "    pov=state_heatmap.iloc[j,13]\n",
    "    popden=state_heatmap.iloc[j,14]\n",
    "    for i in range (7,c-7):\n",
    "        if state_deaths.iloc[j,i+1]>0:\n",
    "            state_deaths_popcorrected[k] = {\"pov\":pov,\"popden\":popden,\"casesday1\":(state_cases.iloc[j,i]*100000)/pop,\n",
    "\"casesday2\":(state_cases.iloc[j,i+1]*100000)/pop,\"casesday3\":(state_cases.iloc[j,i+2]*100000)/pop,\n",
    "\"casesday4\":(state_cases.iloc[j,i+3]*100000)/pop,\"casesday5\":(state_cases.iloc[j,i+4]*100000)/pop,\n",
    "\"casesday6\":(state_cases.iloc[j,i+5]*100000)/pop,\"casesday7\":(state_cases.iloc[j,i+6]*100000)/pop,\n",
    "\"7caseday1\": (state_cases_7day.iloc[j,i-6]*100000)/pop,\"7caseday2\":(state_cases_7day.iloc[j,i-5]*100000)/pop,\n",
    "\"7caseday3\":(state_cases_7day.iloc[j,i-4]*100000)/pop,\"7caseday4\":(state_cases_7day.iloc[j,i-3]*100000)/pop,\n",
    "\"7caseday5\":(state_cases_7day.iloc[j,i-2]*100000)/pop,\"7caseday6\":(state_cases_7day.iloc[j,i-1]*100000)/pop,\n",
    "\"7caseday7\":(state_cases_7day.iloc[j,i]*100000)/pop,\"7caseday8\":(state_cases_7day.iloc[j,i+1]*100000)/pop,\n",
    "\"day1\":(state_deaths.iloc[j,i]*100000)/pop,\"day2\":(state_deaths.iloc[j,i+1]*100000)/pop,\n",
    "\"day3\":(state_deaths.iloc[j,i+2]*100000)/pop,\"day4\":(state_deaths.iloc[j,i+3]*100000)/pop,\n",
    "\"day5\":(state_deaths.iloc[j,i+4]*100000)/pop,\"day6\":(state_deaths.iloc[j,i+5]*100000)/pop,\n",
    "\"day7\":(state_deaths.iloc[j,i+6]*100000)/pop,\"7day1\": (state_deaths_7day.iloc[j,i-6]*100000)/pop,\n",
    "\"7day2\":(state_deaths_7day.iloc[j,i-5]*100000)/pop,\"7day3\":(state_deaths_7day.iloc[j,i-4]*100000)/pop,\n",
    "\"7day4\":(state_deaths_7day.iloc[j,i-3]*100000)/pop,\"7day5\":(state_deaths_7day.iloc[j,i-2]*100000)/pop,\n",
    "\"7day6\":(state_deaths_7day.iloc[j,i-1]*100000)/pop,\"7day7\":(state_deaths_7day.iloc[j,i]*100000)/pop,\n",
    "\"7day8\":(state_deaths_7day.iloc[j,i+1]*100000)/pop}\n",
    "            k=k+1\n",
    "state_deaths_popcorrected = pd.DataFrame.from_dict(state_deaths_popcorrected, \"index\")\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.02632960000005\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "county_cases_popcorrected={}\n",
    "k=0\n",
    "[r,c]=county_cases.shape\n",
    "for j in range (0,r):\n",
    "    pop=county_heatmap.iloc[j,9]\n",
    "    pov=county_heatmap.iloc[j,11]\n",
    "    popden=county_heatmap.iloc[j,12]\n",
    "    for i in range (9,c-7):\n",
    "        if county_cases.iloc[j,i+1]>0:\n",
    "            county_cases_popcorrected[k] = {\"pov\":pov,\"popden\":popden,\"day1\":(county_cases.iloc[j,i]*100000)/pop,\n",
    "\"day2\":(county_cases.iloc[j,i+1]*100000)/pop,\"day3\":(county_cases.iloc[j,i+2]*100000)/pop,\n",
    "\"day4\":(county_cases.iloc[j,i+3]*100000)/pop,\"day5\":(county_cases.iloc[j,i+4]*100000)/pop,\n",
    "\"day6\":(county_cases.iloc[j,i+5]*100000)/pop,\"day7\":(county_cases.iloc[j,i+6]*100000)/pop,\n",
    "\"rad27day1\": (rad2_county_7day.iloc[j,i-6]),\"rad27day2\":(rad2_county_7day.iloc[j,i-5]),\n",
    "\"rad27day3\":(rad2_county_7day.iloc[j,i-4]),\"rad27day4\":(rad2_county_7day.iloc[j,i-3]),\n",
    "\"rad27day5\":(rad2_county_7day.iloc[j,i-2]),\"rad27day6\":(rad2_county_7day.iloc[j,i-1]),\n",
    "\"rad27day7\":(rad2_county_7day.iloc[j,i]),\"rad57day1\": (rad5_county_7day.iloc[j,i-6]),\n",
    "\"rad57day2\":(rad5_county_7day.iloc[j,i-5]),\"rad57day3\":(rad5_county_7day.iloc[j,i-4]),\n",
    "\"rad57day4\":(rad5_county_7day.iloc[j,i-3]),\"rad57day5\":(rad5_county_7day.iloc[j,i-2]),\n",
    "\"rad57day6\":(rad5_county_7day.iloc[j,i-1]),\"rad57day7\":(rad5_county_7day.iloc[j,i]),                                \n",
    "\"rad107day1\": (rad10_county_7day.iloc[j,i-6]),\"rad107day2\":(rad10_county_7day.iloc[j,i-5]),\n",
    "\"rad107day3\":(rad10_county_7day.iloc[j,i-4]),\"rad107day4\":(rad10_county_7day.iloc[j,i-3]),\n",
    "\"rad107day5\":(rad10_county_7day.iloc[j,i-2]),\"rad107day6\":(rad10_county_7day.iloc[j,i-1]),\n",
    "\"rad107day7\":(rad10_county_7day.iloc[j,i]),\"7day1\": (county_cases_7day.iloc[j,i-6]*100000)/pop,\n",
    "\"7day2\":(county_cases_7day.iloc[j,i-5]*100000)/pop,\"7day3\":(county_cases_7day.iloc[j,i-4]*100000)/pop,\n",
    "\"7day4\":(county_cases_7day.iloc[j,i-3]*100000)/pop,\"7day5\":(county_cases_7day.iloc[j,i-2]*100000)/pop,\n",
    "\"7day6\":(county_cases_7day.iloc[j,i-1]*100000)/pop,\"7day7\":(county_cases_7day.iloc[j,i]*100000)/pop,\n",
    "\"7day8\":(county_cases_7day.iloc[j,i+1]*100000)/pop}\n",
    "            k=k+1\n",
    "county_cases_popcorrected = pd.DataFrame.from_dict(county_cases_popcorrected, \"index\")\n",
    "cases_popcorrected=pd.concat([state_cases_popcorrected,county_cases_popcorrected])\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.65492759999995\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "county_deaths_popcorrected={}\n",
    "k=0\n",
    "[r,c]=county_deaths.shape\n",
    "for j in range (0,r):\n",
    "    pop=county_heatmap.iloc[j,9]\n",
    "    pov=county_heatmap.iloc[j,11]\n",
    "    popden=county_heatmap.iloc[j,12]\n",
    "    for i in range (9,c-7):\n",
    "        if county_deaths.iloc[j,i+1]>0:\n",
    "            county_deaths_popcorrected[k] = {\"pov\":pov,\"popden\":popden,\"casesday1\":(county_cases.iloc[j,i]*100000)/pop,\n",
    "\"casesday2\":(county_cases.iloc[j,i+1]*100000)/pop,\"casesday3\":(county_cases.iloc[j,i+2]*100000)/pop,\n",
    "\"casesday4\":(county_cases.iloc[j,i+3]*100000)/pop,\"casesday5\":(county_cases.iloc[j,i+4]*100000)/pop,\n",
    "\"casesday6\":(county_cases.iloc[j,i+5]*100000)/pop,\"casesday7\":(county_cases.iloc[j,i+6]*100000)/pop,\n",
    "\"7caseday1\": (county_cases_7day.iloc[j,i-6]*100000)/pop,\"7caseday2\":(county_cases_7day.iloc[j,i-5]*100000)/pop,\n",
    "\"7caseday3\":(county_cases_7day.iloc[j,i-4]*100000)/pop,\"7caseday4\":(county_cases_7day.iloc[j,i-3]*100000)/pop,\n",
    "\"7caseday5\":(county_cases_7day.iloc[j,i-2]*100000)/pop,\"7caseday6\":(county_cases_7day.iloc[j,i-1]*100000)/pop,\n",
    "\"7caseday7\":(county_cases_7day.iloc[j,i]*100000)/pop,\"7caseday8\":(county_cases_7day.iloc[j,i+1]*100000)/pop,\n",
    "\"day1\":(county_deaths.iloc[j,i]*100000)/pop,\"day2\":(county_deaths.iloc[j,i+1]*100000)/pop,\n",
    "\"day3\":(county_deaths.iloc[j,i+2]*100000)/pop,\"day4\":(county_deaths.iloc[j,i+3]*100000)/pop,\n",
    "\"day5\":(county_deaths.iloc[j,i+4]*100000)/pop,\"day6\":(county_deaths.iloc[j,i+5]*100000)/pop,\n",
    "\"day7\":(county_deaths.iloc[j,i+6]*100000)/pop,\"7day1\": (county_deaths_7day.iloc[j,i-6]*100000)/pop,\n",
    "\"7day2\":(county_deaths_7day.iloc[j,i-5]*100000)/pop,\"7day3\":(county_deaths_7day.iloc[j,i-4]*100000)/pop,\n",
    "\"7day4\":(county_deaths_7day.iloc[j,i-3]*100000)/pop,\"7day5\":(county_deaths_7day.iloc[j,i-2]*100000)/pop,\n",
    "\"7day6\":(county_deaths_7day.iloc[j,i-1]*100000)/pop,\"7day7\":(county_deaths_7day.iloc[j,i]*100000)/pop,\n",
    "\"7day8\":(county_deaths_7day.iloc[j,i+1]*100000)/pop}\n",
    "            k=k+1\n",
    "county_deaths_popcorrected = pd.DataFrame.from_dict(county_deaths_popcorrected, \"index\")\n",
    "deaths_popcorrected=pd.concat([state_deaths_popcorrected,county_deaths_popcorrected])\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_mat = cases_popcorrected.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAANBCAYAAADqZI8yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde7hdZXnv/e8vIYAChhcEW6AVSjhYECikVFRQEHnxgHjkUBUpm8ayVYoo7npR3agbEbFaQLu3gSoBPIJVUZQgSNkQDm8CAQKIgEIr0GpTKxRjMMm63z/mWHY6mYvMGebMOn0/1zUu5nrGM57xjLlm1uJe9z2ekapCkiRJktS7GeM9AUmSJEmabAykJEmSJKlPBlKSJEmS1CcDKUmSJEnqk4GUJEmSJPXJQEqSJEmS+mQgJUmSJGlKS3Jokh8muT/JX3XZ//tJrkmyNMkdSV651jF9jpQkSZKkqSrJTOBe4OXAQ8Bi4Oiqurutz3xgaVX97yR/CHynqrZ/qnHNSEmSJEmayvYF7q+qH1fVr4EvA4d39CngWc3r2cAjaxt0g4FOUZIkSdKUsmr5jyd8CduGW+34dmBeW9P8qprfvN4W+EnbvoeAP+kY4jTgyiTvAjYBDl7bOQ2kJEmSJE1qTdA0f4zd6XZIx9dHAxdU1d8k2Q+4KMnuVTUy1jkt7ZMkSZI0lT0E/F7b19vx5NK9/wZ8FaCqbgQ2Bp79VIMaSEmSJEmayhYDOyXZIcmGwFHAZR19/hl4GUCS59EKpP7tqQa1tE+SJEnS2EbWjPcMnpaqWp3kncBCYCbwuaq6K8mHgSVVdRnwHuC8JO+mVfZ3bK1leXOXP5ckSZI0plU/u2/CBwyztt6p231QQ2VpnyRJkiT1ydI+SZIkSWMbe+G6ac2MlCRJkiT1yUBKkiRJkvpkaZ8kSZKksY1Y2teNGSlJkiRJ6pOBlCRJkiT1yUBKkiRJkvrkPVKSJEmSxlQuf96VGSlJkiRJ6pOBlCRJkiT1ydI+SZIkSWNz+fOuzEhJkiRJUp8MpCRJkiSpT5b2SZIkSRqbq/Z1ZUZKkiRJkvpkICVJkiRJfbK0T5IkSdLYRtaM9wwmJDNSkiRJktQnAylJkiRJ6pOlfZIkSZLG5qp9XZmRkiRJkqQ+GUhJkiRJUp8MpCRJkiSpT94jJUmSJGlsI94j1Y0ZKUmSJEnqk4GUJEmSJPXJ0j5JkiRJYyqXP+/KjJQkSZIk9clASpIkSZL6ZGmfJEmSpLG5al9XZqQkSZIkqU8GUpIkSZLUJ0v7JEmSJI3NVfu6MiMlSZIkSX0ykJIkSZKkPlnaJ0mSJGlsI2vGewYTkhkpSZIkSeqTgZQkSZIk9cnSPkmSJEljc9W+rsxISZIkSVKfDKQkSZIkqU8GUpIkSZLUJ++RkiRJkjS2Ee+R6saMlCRJkiT1yUBKkiRJkvpkaZ8kSZKksbn8eVdmpCRJkiSpTwZSkiRJktQnS/skSZIkjc1V+7oyIyVJkiRJfTKQkiRJkqQ+WdonSZIkaUxVa8Z7ChOSGSlJkiRJ6pOBlCRJkiT1ydI+SZIkSWPzgbxdmZGSJEmSpD4ZSEmSJElSnwykJEmSJKlP3iMlSZIkaWwj3iPVjRkpSZIkSeqTgZQkSZIk9cnSPkmSJEljc/nzrsxISZIkSVKfDKQkSZIkqU+W9kmSJEka28ia8Z7BhGRGSpIkSZL6ZEaqw6rlP65Bj/mMbfYf9JC8eZsXDHzMyRBVhwx8zGFc92SZ52O1auBjDufaBz/m4EeEGZkc3/fJ8vlcUYP9C+hk+RwNw2T5bA7DPyy/beBjDuOzNAwZwvd9GIbx+Zwslj927/S9+CnAQEqSJEnS2Fy1r6vJ8gclSZIkSZowDKQkSZIkqU+W9kmSJEka24ilfd2YkZIkSZKkPhlISZIkSVKfDKQkSZIkqU/eIyVJkiRpbC5/3pUZKUmSJEnq06QLpJJsn+SeJAuS3JHk0iTPTPKyJEuTLEvyuSQbJXlFkq+2HfvSJN8az/lLkiRJmvwmXSDV2AWYX1V7AI8BJwMXAEdW1fNplSyeAHwPeEGSTZrjjgS+0jlYknlJliRZcv6FX1of85ckSZImh5GRib+Ng8kaSP2kqhY1ry8GXgY8UFX3Nm0LgAOqajVwBXBYkg2AVwHf7BysquZX1dyqmnv8MUevh+lLkiRJmswm62IT1UffrwDvAH4OLK6q/xzOlCRJkiRNF5M1I/X7SfZrXh8NXAVsn2RO0/ZW4Nrm9T8CewN/TpeyPkmSJElPYbzL9iztG6gfAG9LcgewBfAp4M+AS5IsA0aA/wNQVWuAbwOvaP4rSZIkSU/LZC3tG6mqv+houxr4o26dq+qdwDuHPitJkiRJ08JkDaQkSZIkrQetAi91mnSBVFU9COw+3vOQJEmSNH1N1nukJEmSJGncTLqMlCRJkqT1aJxWxZvoDKQ6PGOb/Qc+5q8euW7gY+6/x3EDH1ODM9LXo87Gz7898YuBjzlZrl0T3+GbPW+8pzBlhIz3FMbNa5+913hPYdysKX8eS6OSHAqcDcwEzq+qj3Xs/xRwYPPlM4Gtq2rzpxrTQEqSJEnSlJVkJvAZ4OXAQ8DiJJdV1d2jfarq3W3938UYq4G3M5CSJEmSNLaa9KV9+wL3V9WPAZJ8GTgcuHuM/kcD/3Ntg7rYhCRJkqRJLcm8JEvatnltu7cFftL29UNNW7dxngvsAHx/bec0IyVJkiRpUquq+cD8MXZ3u1F0rJsIjwIurR4enmVGSpIkSdJU9hDwe21fbwc8Mkbfo4Av9TKoGSlJkiRJY5v8y58vBnZKsgPwMK1g6U87OyXZBfh/gBt7GXRSZ6SSPD7ec5AkSZI0cVXVauCdwELgB8BXq+quJB9O8pq2rkcDX67q7dkBZqQkSZIkTWlV9R3gOx1tH+z4+rR+xlwvgVSS7YErgJtprcl+L3AMsB/wiWYei4ETquqJJA8CX+G/Hor1p1V1f5OO+2LT/4qOc5wCHAFsBHy9qv5nc97vAtcDL6SVyju8qn41pEuVJEmSppbJv/z5UKzP0r5dgPlVtQfwGHAycAFwZFU9n1ZwdEJb/8eqal/g08DfNm1nA/+7qv4Y+NfRjkkOAXaitUb8XsA+SQ5odu8EfKaqdgN+AbxhOJcnSZIkabpYn4HUT6pqUfP6YuBlwANVdW/TtgA4oK3/l9r+u1/z+kVt7Re19T2k2ZYCtwK70gqgaM5xW/P6FmD7zom1rzs/MvLLdbg0SZIkSdPJ+rxHqqebtsboP9brUQHOqKrP/lZjq7TvibamNcAznnSitnXnN9hw237nKUmSJE1dk3/VvqFYnxmp308ymlk6GrgK2D7JnKbtrcC1bf2PbPvv6BKEi2gtVwjw5ra+C4HjkmwKkGTbJFsPeP6SJEmSBKzfjNQPgLcl+SxwH/CXwE3AJUlGF5v4P239N0pyM61g7+im7S+BLyb5S+Brox2r6sokzwNuTALwOPAWWhkoSZIkSRqo9RlIjVTVX3S0XU1rFb9uPlNVH2pvqKoH+K/7pQA+1rbvbFqLUXTava3PJ/qasSRJkjTduWpfV5P6gbySJEmSNB7WS0aqqh6kLTPUQ//thzYZSZIkSXqa1mdpnyRJkqTJxlX7urK0T5IkSZL6ZCAlSZIkSX2ytK/Dm7d5wcDH3H+P4wY+5nV3fG7gY2r6+ddX/PnAx1y1cubAx/z1E4P/UbVq1eDnueKJWQMf81drBj/PlQxhzAz+73IHv/7xgY85cDMy3jPozRC+P5PFvK8OfsyiBj7mMAqn1gxh1MlS4LVmCKvMTZZr1/pjICVJkiRpbN4j1dX0/ROVJEmSJK0jAylJkiRJ6pOlfZIkSZLGNoR7zqYCM1KSJEmS1CcDKUmSJEnq04QPpJK8NMm31/HYXZPcmOSJJO8d9NwkSZKkKW9kZOJv42Cq3yP1c+BE4LXjPRFJkiRJU0fPGakkxyS5I8ntSS5KcliSm5MsTXJVkuc0/V6S5LZmW5pks6b9lCSLmzE+1LRtkuTyZsw7kxzZtB+a5J4k1wOvb5vDvkluaMa9IckuTft1SfZq67coyR5V9bOqWgysGsSbJUmSJEnQY0YqyW7AqcCLqmp5ki2AAl5QVZXkeOB9wHuA9wLvqKpFSTYFViY5BNgJ2BcIcFmSA4CtgEeq6lXNeWYn2Rg4DzgIuB/4SttU7gEOqKrVSQ4GPgq8ATgfOBY4KcnOwEZVdce6vy2SJEmSAFftG0OvGamDgEurajlAVf0c2A5YmGQZcAqwW9N3EfDJJCcCm1fVauCQZlsK3ArsSiuwWgYcnOTMJPtX1aPNvgeq6r6qKuDitnnMBi5JcifwqbZzXgK8Osks4Djggn7ehCTzkixJsuTe/3ygn0MlSZIkTUO9BlKhlYFqdy7w6ap6PvB2YGOAqvoYcDzwDOCmJLs2x59RVXs125yq+vuquhfYh1ZAdUaSDzZjd55r1EeAa6pqd+CwtnOuAL4HHA4cAXyxx+uiOX5+Vc2tqrk7b7ZDP4dKkiRJmoZ6DaSuBo5IsiVAU9o3G3i42f+20Y5JdqyqZVV1JrCEVoZpIXBcU+pHkm2TbJ1kG2BFVV0MfALYm1b53g5JdmyGPLptHu3nPLZjjucD5wCLm4yZJEmSpKdrvFfkm8yr9lXVXUlOB65NsoZWid5ptMrsHgZuAkZTOSclORBYA9wNfLeqnkjyPODGJACPA28B5gBnJRmhtSDECVW1Msk84PIky4Hrgd2bsT8OLEhyMvD9jjnekuQx4POjbUl+h1Yw9yxgJMlJwB9W1WO9v0WSJEmS9Nt6Xv68qhYACzqav9ml37vGOP5s4OyO5h/RylZ19r2CViars/1GYOe2pg+MvmiyWzOAK9v6/yute7kkSZIkaWCmxHOkkhwDnA6cXOWyIpIkSdLA+L/XXU2JQKqqLgQuHO95SJIkSZoeen4gryRJkiSpxUBKkiRJkvo0JUr7JEmSJA3JOC0vPtEZSHUwRafpZOaswf9gzIyxnqc9DcbM4Mdk5YYDH3LGMH4fDuHSa2QIgw5YhjHojCGMOlluFI+/hQcpQ/iEzhjCP/ZhfDpnDOVf58T/maT1y59YkiRJktQnM1KSJEmSxmZpX1dmpCRJkiSpTwZSkiRJktQnS/skSZIkja1caKMbM1KSJEmS1KcJH0gleWmSb6/jsW9Ockez3ZBkz0HPT5IkSdL0M9VL+x4AXlJV/5HkFcB84E/GeU6SJEnS5OGqfV31nJFKckyT2bk9yUVJDktyc5KlSa5K8pym30uS3NZsS5Ns1rSfkmRxM8aHmrZNklzejHlnkiOb9kOT3JPkeuD1bXPYt8ksLW3+u0vTfl2Svdr6LUqyR1XdUFX/0TTfBGz3NN8vSZIkSeotI5VkN+BU4EVVtTzJFrQe7/yCqqokxwPvA94DvBd4R1UtSrIpsDLJIcBOwL60HgR/WZIDgK2AR6rqVc15ZifZGDgPOAi4H/hK21TuAQ6oqtVJDgY+CrwBOB84Fjgpyc7ARlV1R8dl/Dfgu/28OZIkSZLUTa8ZqYOAS6tqOUBV/ZxWdmdhkmXAKcBuTd9FwCeTnAhsXlWrgUOabSlwK7ArrcBqGXBwkjOT7F9Vjzb7Hqiq+6qqgIvb5jEbuCTJncCn2s55CfDqJLOA44AL2ief5EBagdT/6HZxSeYlWZJkyQ//84Ee3xJJkiRpGhgZmfjbOOg1kAqtDFS7c4FPV9XzgbcDGwNU1ceA44FnADcl2bU5/oyq2qvZ5lTV31fVvcA+tAKqM5J8sBl7rDUWPwJcU1W7A4e1nXMF8D3gcOAI4Iu/mXiyB62M1eFV9e/dBq2q+VU1t6rm7rLZDj2+JZIkSZKmq14DqauBI5JsCdCU9s0GHm72v220Y5Idq2pZVZ0JLKGVYVoIHNeU+pFk2yRbJ9kGWFFVFwOfAPamVb63Q5IdmyGPbptH+zmP7Zjj+cA5wOImY0aS3wf+AXhrE7RJkiRJ0tPW0z1SVXVXktOBa5OsoVWidxqtMruHaS3kMJrKOakppVsD3A18t6qeSPI84MYkAI8DbwHmAGclGQFWASdU1cok84DLkywHrgd2b8b+OLAgycnA9zvmeEuSx4DPtzV/ENgS+LvmvKuram6P740kSZIkddXz8udVtQBY0NH8zS793jXG8WcDZ3c0/4hWtqqz7xW0Mlmd7TcCO7c1fWD0RZPdmgFc2db/eFplhpIkSZLWRbn8eTcT/oG8vUhyDHAzcGqV32lJkiRJwzUlHshbVRcCF473PCRJkiRND1MikJIkSZI0JOO0vPhENyVK+yRJkiRpfTKQkiRJkqQ+WdonTWMzNxzr2dfrLqsHPiStpylMT5vw64GPOeOJWQMfM2sG/1liZMBjzshgxwNq0HOk9QT7SWEI7+cwVgabwcyBjzmMIqcZDP6zNFmKsYbxV/2RDP7zOWMIP+YmjZrOFz82M1KSJEmS1CcDKUmSJEnqk6V9kiRJksbmqn1dmZGSJEmSpD4ZSEmSJElSnyztkyRJkjQ2S/u6mvAZqSQvTfLtdTz28CR3JLktyZIkLx70/CRJkiRNP1M9I3U1cFlVVZI9gK8Cu47znCRJkiRNcj1npJIc02R3bk9yUZLDktycZGmSq5I8p+n3kiYDdFuzb7Om/ZQki5sxPtS0bZLk8mbMO5Mc2bQfmuSeJNcDr2+bw75JbmjGvSHJLk37dUn2auu3KMkeVfV41W+eILYJDOFpd5IkSZKmnZ4yUkl2A04FXlRVy5NsQSsoeUGT7TkeeB/wHuC9wDuqalGSTYGVSQ4BdgL2pfXQ9suSHABsBTxSVa9qzjM7ycbAecBBwP3AV9qmcg9wQFWtTnIw8FHgDcD5wLHASUl2BjaqqjuaMV8HnAFsDbxqjOubB8wD2G+LP2KXzXbo5W2RJEmSpr7yHqlues1IHQRcWlXLAarq58B2wMIky4BTgN2avouATyY5Edi8qlYDhzTbUuBWWuV1OwHLgIOTnJlk/6p6tNn3QFXd12STLm6bx2zgkiR3Ap9qO+clwKuTzAKOAy4YPaCqvl5VuwKvBT7S7eKqan5Vza2quQZRkiRJktam10AqPLks7lzg01X1fODtwMYAVfUx4HjgGcBNSXZtjj+jqvZqtjlV9fdVdS+wD62A6owkH2zGHqsE7yPANVW1O3BY2zlXAN8DDgeOAL7YeWBV/V9gxyTP7vGaJUmSJKmrXgOpq4EjkmwJ0JT2zQYebva/bbRjkh2rallVnQksoZVhWggc15T6kWTbJFsn2QZYUVUXA58A9qZVvrdDkh2bIY9um0f7OY/tmOP5wDnA4iZjRpI5SdK83hvYEPj3Hq9ZkiRJmvZqpCb8Nh56ukeqqu5KcjpwbZI1tEr0TqNVZvcwcBMwWhN3UpIDgTXA3cB3q+qJJM8DbmzimseBtwBzgLOSjACrgBOqamVzz9LlSZYD1wO7N2N/HFiQ5GTg+x1zvCXJY8Dn25rfAByTZBXwK+DItsUnJEmSJGmd9Lz8eVUtABZ0NH+zS793jXH82cDZHc0/opWt6ux7BV2WKa+qG4Gd25o+MPqiyW7NAK5s638mcGa3+UiSJEnSupoSz5FKcgxwOnBylcuKSJIkSQMz4v9edzMlAqmquhC4cLznIUmSJGl66PmBvJIkSZKklimRkZIkSZI0JN4505WBVIeQ8Z6CtN7MmDWdF7FcM94T6Eky+O/RjCGMmSdmDXzMgdfkjwAzBlyIMWPwvzOGsYxvhjBPhrHc8DDmOY3NGML/00yW/52eMeYjSdfdSPx86rdZ2idJmh4GHURJkqY1M1KSJEmSxjZOD7yd6PzznCRJkiT1yUBKkiRJkvpkaZ8kSZKksflA3q7MSEmSJElSnwykJEmSJKlPEz6QSvLSJN9+mmP8cZI1Sd44qHlJkiRJmr6m/D1SSWYCZwILx3sukiRJ0qTjPVJd9ZyRSnJMkjuS3J7koiSHJbk5ydIkVyV5TtPvJUlua7alSTZr2k9JsrgZ40NN2yZJLm/GvDPJkU37oUnuSXI98Pq2Oeyb5IZm3BuS7NK0X5dkr7Z+i5Ls0Xz5LuBrwM+e3lslSZIkSS09ZaSS7AacCryoqpYn2QIo4AVVVUmOB94HvAd4L/COqlqUZFNgZZJDgJ2AfYEAlyU5ANgKeKSqXtWcZ3aSjYHzgIOA+4GvtE3lHuCAqlqd5GDgo8AbgPOBY4GTkuwMbFRVdyTZFnhdM9YfP8X1zQPmAbxwiz9il83+oJe3RZIkSdI01WtG6iDg0qpaDlBVPwe2AxYmWQacAuzW9F0EfDLJicDmVbUaOKTZlgK3ArvSCqyWAQcnOTPJ/lX1aLPvgaq6r6oKuLhtHrOBS5LcCXyq7ZyXAK9OMgs4Drigaf9b4H9U1Zqnuriqml9Vc6tqrkGUJEmS1KZq4m/joNd7pEIrA9XuXOCTVXVZkpcCpwFU1ceSXA68EripyRwFOKOqPvukgZN9mr5nJLkSuKzLuUZ9BLimql6XZHvgH5tzrkjyPeBw4AhgbtN/LvDlJADPBl6ZZHVVfaPH65YkSZKkJ+k1I3U1cESSLQGa0r7ZwMPN/reNdkyyY1Utq6ozgSW0MkwLgeOaUj+SbJtk6yTbACuq6mLgE8DetMr3dkiyYzPk0W3zaD/nsR1zPB84B1jcZMyoqh2qavuq2h64FPjvBlGSJEnS9NKswfDDJPcn+asx+hyR5O4kdyX54trG7CkjVVV3JTkduDbJGloleqfRKrN7GLgJ2KHpflKSA4E1wN3Ad6vqiSTPA25sskOPA28B5gBnJRkBVgEnVNXK5p6ly5MsB64Hdm/G/jiwIMnJwPc75nhLkseAz/dyTZIkSZJ6MMlX7WtW8f4M8HLgIWBxksuq6u62PjsB76e1JsR/JNl6beP2vPx5VS0AFnQ0f7NLv3eNcfzZwNkdzT+iy7LkVXUFrUxWZ/uNwM5tTR8YfdFkt2YAV45x/mO7tUuSJEma0vYF7q+qHwMk+TKtW4Lubuvz58Bnquo/AKpqrSt+T/gH8vYiyTHAzcCpVTW5Q2ZJkiRJfUkyL8mStm1e2+5tgZ+0ff1Q09ZuZ2Dn5jFKNyU5dG3nnBIP5K2qC4ELx3sekiRJ0pQzMj6r4vWjquYD88fYnW6HdHy9Aa1VxV9Ka3Xy65LsXlW/GOucUyIjJUmSJEljeAj4vbavtwMe6dLnm1W1qqoeAH5IK7Aak4GUJEmSpKlsMbBTkh2SbAgcReuRS+2+ARwIkOTZtEr9fvxUg06J0r5BMrLUdJIh/ASYMeZj4J6GDKOkYPD/2jPjKZ/9vW5jditGmIA2mTHxyz6Gs+rU5PitMYzvTmYM4cM5CcqHAGZ0rRJ6eoZzg/fkeD8ni8nxr31IJvkSBFW1Osk7aS1yNxP4XLMq+YeBJVV1WbPvkCR301p9/JSq+venGtdASpIkSdKUVlXfAb7T0fbBttcFnNxsPZnWwbUkSZIkrQsDKUmSJEnqk6V9kiRJksY2Se5fXN/MSEmSJElSnwykJEmSJKlPlvZJkiRJGlMN5fERk9+Ez0gleWmSbz+NYx9NcluzfXDtR0mSJEnSU5sOGanrqurV4z0JSZIkSVNHzxmpJMckuSPJ7UkuSnJYkpuTLE1yVZLnNP1e0pYBWppks6b9lCSLmzE+1LRtkuTyZsw7kxzZtB+a5J4k1wOvb5vDvkluaMa9IckuTft1SfZq67coyR4DeYckSZKk6WykJv42DnoKpJLsBpwKHFRVewJ/CVwPvKCq/gj4MvC+pvt7gXdU1V7A/sCvkhwC7ATsC+wF7JPkAOBQ4JGq2rOqdgeuSLIxcB5wWHP877RN5R7ggOacHwQ+2rSfDxzbzHVnYKOquqPZt18TqH23uY5u1zcvyZIkS+75zx/38pZIkiRJmsZ6zUgdBFxaVcsBqurnwHbAwiTLgFOA0SBlEfDJJCcCm1fVauCQZlsK3ArsSiuwWgYcnOTMJPtX1aPNvgeq6r6qKuDitnnMBi5JcifwqbZzXgK8Osks4Djggqb9VuC5TfB3LvCNbhdXVfOram5Vzd11sz/o8S2RJEmSNF31GkgF6MyZnQt8uqqeD7wd2Bigqj4GHA88A7gpya7N8WdU1V7NNqeq/r6q7gX2oRVQndG2GMRY+bmPANc02avD2s65AvgecDhwBPDFpv2xqnq8ef0dYFaSZ/d4zZIkSZJqZOJv46DXQOpq4IgkWwIk2YJWdujhZv/bRjsm2bGqllXVmcASWhmmhcBxSTZt+mybZOsk2wArqupi4BPA3rTK93ZIsmMz5NFt82g/57EdczwfOAdY3GTMSPI7SdK83re53n/v8ZolSZIkqaueVu2rqruSnA5cm2QNrRK902iV2T0M3ATs0HQ/KcmBwBrgbuC7VfVEkucBNzZxzePAW4A5wFlJRoBVwAlVtTLJPODyJMtp3Yu1ezP2x4EFSU4Gvt8xx1uSPAZ8vq35jcAJSVYDvwKOasoFJUmSJGmd9bz8eVUtABZ0NH+zS793jXH82cDZHc0/opWt6ux7Ba1MVmf7jcDObU0fGH3RZLdmAFe29f808Olu85EkSZLUg3FaFW+im/AP5O1FkmOAm4FTq8apSFKSJEnStDElHshbVRcCF473PCRJkiRND1MikJIkSZI0JCMWfHUzJUr7JEmSJGl9MiPVIWTgY46M+VgsaXxlkvwEGM5ffAb/17XMGPzPj2HIjMH/TFq1cubAx2RkMvytbwh/pZ0xhOsewo3i/mab+IbzL2hy/JwbRv6k/NSrw2T4LSVJkiRJE8ok+Xu0JEmSpHHh8uddmZGSJEmSpD4ZSEmSJElSnyztkyRJkjS2cvnzbsxISZIkSVKfDKQkSZIkqU8TPpBK8tIk336ax9+W5K4k1w5ybpIkSdKUN1ITfxsHU/oeqSSbA38HHFpV/5xk6/GekyRJkqTJr+eMVJJjktyR5PYkFyU5LMnNSZYmuSrJc5p+L2kyQLc1+zZr2k9JsrgZ40NN2yZJLm/GvDPJkU37oUnuSXI98Pq2Oeyb5IZm3BuS7NK0X5dkr7Z+i5LsAfwp8A9V9c8AVfWzp/2OSZIkSZr2espIJdkNOBV4UVUtT7IFUMALqqqSHA+8Dx9wjscAACAASURBVHgP8F7gHVW1KMmmwMokhwA7AfsCAS5LcgCwFfBIVb2qOc/sJBsD5wEHAfcDX2mbyj3AAVW1OsnBwEeBNwDnA8cCJyXZGdioqu5IchwwK8k/ApsBZ1fVhV2ubx4wD+DFW+zNrpv9QU9vniRJkjTV1Yir9nXTa0bqIODSqloOUFU/B7YDFiZZBpwC7Nb0XQR8MsmJwOZVtRo4pNmWArcCu9IKrJYBByc5M8n+VfVos++Bqrqvqgq4uG0es4FLktwJfKrtnJcAr04yCzgOuKBp3wDYB3gV8P8CH2gCrd9SVfOram5VzTWIkiRJkrQ2vQZSoZWBancu8Omqej7wdmBjgKr6GHA88AzgpiS7NsefUVV7Nducqvr7qrqXVqCzDDgjyQebsce6Y+wjwDVVtTtwWNs5VwDfAw4HjgC+2PR/CLiiqn7ZBIH/F9izx2uWJEmSpK56DaSuBo5IsiVAU9o3G3i42f+20Y5JdqyqZVV1JrCEVoZpIXBcU+pHkm2TbJ1kG2BFVV0MfALYm1b53g5JdmyGPLptHu3nPLZjjucD5wCLm4wZwDeB/ZNskOSZwJ8AP+jxmiVJkiSN94p8k3nVvqq6K8npwLVJ1tAq0TuNVpndw8BNwA5N95OSHAisAe4GvltVTyR5HnBjEoDHgbcAc4CzkowAq4ATqmplc8/S5UmWA9cDuzdjfxxYkORk4Psdc7wlyWPA59vafpDkCuAOYAQ4v6ru7OP9kSRJkqQn6Xn586paACzoaP5ml37vGuP4s4GzO5p/RCtb1dn3ClqZrM72G4H2e5w+MPqiyW7NAK7sOOYs4Kxuc5IkSZKkdTHhH8jbiyTHADcDp1aVy4pIkiRJGqop8UDeZknzJy1rLkmSJOlpGqd7kCa6KZGRkiRJkqT1yUBKkiRJkvo0JUr7BsnIUtNJpvFPgGH8Wx8Z8xF4624mg7/tM5kkJRojGex4MwY8Hgyp3GUIt/rOGMInfhjXPoTv0RC+60P4l67JIEP5NE0SLkHQlXGDJEmSJPXJQEqSJEmS+jSNC3skSZIkrZWr9nVlRkqSJEmS+mQgJUmSJEl9srRPkiRJ0pjK0r6uzEhJkiRJUp8mfCCV5KVJvr2Ox56S5LZmuzPJmiRbDHqOkiRJkqaXKV3aV1VnAWcBJDkMeHdV/Xx8ZyVJkiRNIpb2ddVzRirJMUnuSHJ7kouSHJbk5iRLk1yV5DlNv5e0ZYGWJtmsaT8lyeJmjA81bZskubwZ884kRzbthya5J8n1wOvb5rBvkhuacW9IskvTfl2Svdr6LUqyR8clHA18aR3fJ0mSJEn6jZ4yUkl2A04FXlRVy5vyuAJeUFWV5HjgfcB7gPcC76iqRUk2BVYmOQTYCdgXCHBZkgOArYBHqupVzXlmJ9kYOA84CLgf+ErbVO4BDqiq1UkOBj4KvAE4HzgWOCnJzsBGVXVH2/yfCRwKvHOM65sHzAPYf4u9ed5mf9DL2yJJkiRpmuo1I3UQcGlVLQdoyuO2AxYmWQacAuzW9F0EfDLJicDmVbUaOKTZlgK3ArvSCqyWAQcnOTPJ/lX1aLPvgaq6r6oKuLhtHrOBS5LcCXyq7ZyXAK9OMgs4DrigY/6HAYvGKuurqvlVNbeq5hpESZIkSVqbXu+RCq0MVLtzgU9W1WVJXgqcBlBVH0tyOfBK4KYmcxTgjKr67JMGTvZp+p6R5Ergsi7nGvUR4Jqqel2S7YF/bM65Isn3gMOBI4C5HccdhWV9kiRJUv9GRsZ7BhNSrxmpq4EjkmwJ0JT2zQYebva/bbRjkh2rallVnQksoZVhWggc15T6kWTbJFsn2QZYUVUXA58A9qZVvrdDkh2bIY9um0f7OY/tmOP5wDnA4vbMU5LZwEuAb/Z4rZIkSZL0lHrKSFXVXUlOB65NsoZWid5ptMrsHgZuAnZoup+U5EBgDXA38N2qeiLJ84AbkwA8DrwFmAOclWQEWAWcUFUrm3uWLk+yHLge2L0Z++PAgiQnA9/vmOMtSR4DPt8x/dcBV1bVL3t7SyRJkiTpqfW8/HlVLQAWdDQ/KctTVe8a4/izgbM7mn9EK1vV2fcKWpmszvYbgZ3bmj4w+qLJbs0Aruw45gKefM+UJEmSpF64/HlXE/6BvL1IcgxwM3BqVVnEKUmSJGmopsQDeavqQuDC8Z6HJEmSpOlhSgRSkiRJkobE0r6upkRpnyRJkiStT2akOjxWqwY+5r898YuBj/mvr/jzgY85c9bgby+bueFg/4IxY9bg/yKSIfwrmCxjbnZe5yKXejpWX/fVgY9Z//bTgY858sA/D3zM1Q92fd7503LE5bMGOt7MDP5vhyEDH3ODIYw5M0MYcwh/ix3GX3dnDmHMYZg5jM/SED7zw7DBpPksDf57pMnNQEqSJEnSmKos7etmcvypQpIkSZImEAMpSZIkSeqTpX2SJEmSxuaqfV2ZkZIkSZKkPhlISZIkSVKfLO2TJEmSNDZL+7paa0YqyS5JbmvbHkty0vqYXHP+7ZPcuY7HbpnkmiSPJ/n0oOcmSZIkaXpaa0aqqn4I7AWQZCbwMPD1Ic9rUFYCHwB2bzZJkiRJetr6vUfqZcCPquqfksxJclWS25PcmmTHJJsmubr5elmSwwGSbJLk8qbvnUmObNr3SXJtkluSLEzyu23ttye5EXjH6Mmb7NR1zfi3Jnlh037R6Lmar7+Q5DVV9cuqup5WQCVJkiRJA9FvIHUU8KXm9ReAz1TVnsALgX+hFbC8rqr2Bg4E/iZJgEOBR6pqz6raHbgiySzgXOCNVbUP8Dng9GbszwMnVtV+Hef/GfDyZvwjgXOa9vOBPwNIMruZz3d6vagk85IsSbLk/scf7PUwSZIkacqrkZrw23joOZBKsiHwGuCSJJsB21bV1wGqamVVrQACfDTJHcBVwLbAc4BlwMFJzkyyf1U9CuxCq9zue0luA/4a2K4JhDavqmubU1/UNo1ZwHlJlgGXAH/YnP9aYE6SrYGjga9V1eper62q5lfV3KqaO2fT7Xs9TJIkSdI01c+qfa8Abq2qnyZ51hh93gxsBexTVauSPAhsXFX3JtkHeCVwRpIrad1ndVdn1inJ5sBYYeW7gZ8Ce9IKAttL9i5qzn8UcFwf1yVJkiRJfemntO9omrK+qnoMeCjJawGSbJTkmcBs4GdNEHUg8Nxm/zbAiqq6GPgEsDfwQ2CrJPs1fWYl2a2qfgE8muTFzXnf3DaH2cC/VNUI8FZgZtu+C4CTmvnd1cd1SZIkSRrLSE38bRz0lJFqgqSXA29va34r8NkkHwZWAW+idd/Ut5IsAW4D7mn6Ph84K8lI0/eEqvp1kjcC5zTlfBsAfwvcRet+p88lWQEsbDvn3wFfS/Im4Brgl6M7mkzZD4BvdMz9QeBZwIZN4HdIVd3dy3VLkiRJUjc9BVLN/U9bdrTdBxzUpXvnAhEAD/LbAdHoGLcBB3Rpv4VW+d6o09rOuUdb+/tHXzTB3k7812IYo2Nt32U+kiRJkrTO+rlHasJKcjCtVf8+2SxkIUmSJGkQRsZ7AhPTlAikquoq4PfHex6SJEmSpod+nyMlSZIkSdPelMhISZIkSRqO8Xrg7URnINUhZOBjjoz5WKx1t2rlzLV36lNmDH6e6fmxyONnxhC+P5qeNtj/iIGPuXrRpQMfcxilCMP4ZTJy/YqBjpch/Fsfxns5lFsRhvFjLsOY6eDf0ZEhvKOzhjDPYXyLVtfgR52VwV/7muF8QAc+omVc6uRnQpIkSZL6ZEZKkiRJ0tgs7evKjJQkSZIk9clASpIkSZL6ZCAlSZIkSX0ykJIkSZI0tpFJsK1FkkOT/DDJ/Un+qsv+Y5P8W5Lbmu34tY3pYhOSJEmSpqwkM4HPAC8HHgIWJ7msqu7u6PqVqnpnr+OuNSOVZJe2yOy2JI8lOamv2T8NSbZPcuc6HvvyJLckWdb896BBz0+SJEnShLYvcH9V/biqfg18GTj86Q661oxUVf0Q2At+E809DHz96Z54PVkOHFZVjyTZHVgIbDvOc5IkSZImjZoEy58nmQfMa2uaX1Xzm9fbAj9p2/cQ8CddhnlDkgOAe4F3V9VPuvT5jX7vkXoZ8KOq+qckc5JcleT2JLcm2THJpkmubr5eluTw5sI2SXJ50/fOJEc27fskubbJFi1M8rtt7bcnuRF4x+jJm+zUdc34tyZ5YdN+0ei5mq+/kOQ1VbW0qh5pmu8CNk6yUZ/XLEmSJGkCq6r5VTW3bZvftjvdDun4+lvA9lW1B3AVsGBt5+w3kDoK+FLz+gvAZ6pqT+CFwL8AK4HXVdXewIHA3yQJcCjwSFXtWVW7A1ckmQWcC7yxqvYBPgec3oz9eeDEqtqv4/w/A17ejH8kcE7Tfj7wZwBJZjfz+U7HsW8AllbVE50XlWRekiVJltz/+IN9viWSJEmSJrCHgN9r+3o74JH2DlX1721xwnnAPmsbtOdAKsmGwGuAS5JsBmxbVV9vTryyqlbQivY+muQOWpHctsBzgGXAwUnOTLJ/VT0K7ALsDnwvyW3AXwPbNYHQ5lV1bXPqi9qmMQs4L8ky4BLgD5vzXwvMSbI1cDTwtapa3Tb33YAzgbd3u7b2CHbOptv3+pZIkiRJU994r8j39FftWwzslGSHJqY5CrisvcNoZVzjNcAP1jZoP6v2vQK4tap+muRZY/R5M7AVsE9VrUryILBxVd2bZB/glcAZSa6kdZ/VXZ1ZpySb8+RU26h3Az8F9qQVBK5s23dRc/6jgOPaxtuuOdcxVfWjPq5XkiRJ0iRXVauTvJPWegkzgc9V1V1JPgwsqarLgBOTvAZYDfwcOHZt4/YTSB1NU9ZXVY8leSjJa6vqG819RzOB2cDPmiDqQOC5AEm2AX5eVRcnebyZ2MeArZLsV1U3NqV+OzcX9WiSF1fV9bSCo1GzgYeqaiTJ25pzjroA+P+Af62qu5rzbg5cDry/qhb1ca2SJEmSpoiq+g4dt/5U1QfbXr8feH8/Y/YUSCV5Jq1119tL494KfLaJ5FYBb6J139S3kiwBbgPuafo+HzgryUjT94Sq+nWSNwLnNOV8GwB/S2tRiD8DPpdkBa3IcdTfAV9L8ibgGuCXbRf/0yQ/AL7R1v+dwBzgA0k+0LQdUlU/6+W6JUmSpOluMqzaNx56CqSa+5+27Gi7D+j2XKbOBSIAHuS3A6LRMW4DDujSfgut8r1Rp7Wdc4+29t9EjU2wtxP/tRgGVfW/gP/VZT6SJEmStM76XbVvQkpyMK3s17nNQhaSJEmSNDT93CM1YVXVVcDvj/c8JEmSpCln7aviTUtTIiMlSZIkSeuTgZQkSZIk9WlKlPYN0gwy3lPoya+fGPy3LjOGsSLLmiGMOWAZ/HX7FwoNygYveuPAx1y96NKBjzlzxuB/dhZ3D3S8NcP4ETc5fmUMRYZy8dO3fmjWEH5zrBnzsZxPQw3+ezQrk+Pap/Pv9iF826eE6fyZkCRJkqR1YiAlSZIkSX0ykJIkSZKkPnmPlCRJkqSxeY9UV2akJEmSJKlPBlKSJEmS1CdL+yRJkiSNyeXPu1trRirJLklua9seS3LS+phcc/7tk9y5jsfu2zbv25O8btDzkyRJkjT9rDUjVVU/BPYCSDITeBj4+pDnNSh3AnOranWS3wVuT/Ktqlo93hOTJEmSNHn1e4/Uy4AfVdU/JZmT5Kom03Nrkh2TbJrk6ubrZUkOB0iySZLLm753Jjmyad8nybVJbkmysAl2RttvT3Ij8I7RkzfZqeua8W9N8sKm/aLRczVffyHJa6pqRVvQtDEM4xHfkiRJ0hQ2Mgm2cdBvIHUU8KXm9ReAz1TVnsALgX8BVgKvq6q9gQOBv0kS4FDgkaras6p2B65IMgs4F3hjVe0DfA44vRn788CJVbVfx/l/Bry8Gf9I4Jym/XzgzwCSzG7m853m6z9JchewDPiLbtmoJPOSLEmy5L7HH+jzLZEkSZI03fQcSCXZEHgNcEmSzYBtq+rrAFW1sqpWAAE+muQO4CpgW+A5tIKYg5OcmWT/qnoU2AXYHfhektuAvwa2awKhzavq2ubUF7VNYxZwXpJlwCXAHzbnvxaYk2Rr4Gjga6MBU1XdXFW7AX8MvD/Jxp3XVlXzq2puVc3dadMden1LJEmSJE1T/aza9wrg1qr6aZJnjdHnzcBWwD5VtSrJg8DGVXVvkn2AVwJnJLmS1n1Wd3VmnZJsztgleO8GfgrsSSsIXNm276Lm/EcBx3UeWFU/SPJLWsHbkl4uWJIkSZruXLWvu35K+46mKeurqseAh5K8FiDJRkmeCcwGftYEUQcCz232bwOsqKqLgU8AewM/BLZKsl/TZ1aS3arqF8CjSV7cnPfNbXOYDfxLVY0AbwVmtu27ADipmd9dzZg7JNmgef1cWlmwB/u4ZkmSJEl6kp4yUk2Q9HLg7W3NbwU+m+TDwCrgTbTum/pWkiXAbcA9Td/nA2clGWn6nlBVv07yRuCcppxvA+Bvgbto3e/0uSQrgIVt5/w74GtJ3gRcA/xydEeTKfsB8I22/i8G/irJKlq3of33qlreyzVLkiRJ0lh6CqSa+5+2/P/Zu/9ou+v6zvfPV0IAgRB6rXYUf4QWzLqAgCTYwkCtCrMERxAHh9AMV6NXbK8/Ls54p3VRXdQpbf3R2pGiLbCEMabUYkjHjrRoXIrUqjWkiUkKERWcokyYTgcCpIGE875/7O+p29NzSDb5frP32ef5yNore3++n+/78/nuvc8++30+n+/nO6XsHuAV01SfukAE9EaBbptaWFUbgZ+fpvxOetP3Jl3Z1+ZJfeXvmbzTJHvH8aPFMKiqVfz4OVaSJEmSBuDUvukNumrfSEpyNr3Rr6ubhSwkSZIkqTODLDYxsqpqHfCCYfdDkiRJ0twwFiNSkiRJknQgjcWIlCRJkqRueI7U9EykpsiwO7CPdu+ev/dKA8q8mS7fNUqe7CBmFwOz7X/iOHysthz0Ly9qPeaev7ql9ZgTbG01Xhc/Q9XBx+ZEB7+I0sVvty6+WaX9V6m6eJEyO75VLujgXf/kjJf6fPrmdRBzfgfv+S6OXbOb380kSZIkaUCOSEmSJEmaWc2WOVsHliNSkiRJkjQgEylJkiRJGpBT+yRJkiTNyFX7pueIlCRJkiQNyERKkiRJkga010QqyZIkG/tuO5JcfiA617S/OMmW/YzxgiSPJnl3W/2SJEmS5oKayMjfhmGv50hV1TbgFIAk84EfAGs77lfbPgL8+bA7IUmSJGk8DDq175XAd6vq+0mOTbIuyaYkG5L8TJIjknyxebw5yQUASQ5P8rmm7pYkFzflS5PcnuTOJLcleU5f+aYkXwPeNtl4Mzp1RxN/Q5IzmvJVk201j1cnOb+5/1rge8DW/XieJEmSJOmfDJpILQduau6vBq6pqpOBM4AHgF3AhVV1KvBy4HeSBHgV8MOqOrmqTgT+IskC4GrgoqpaCnwCuKqJfQPwzqo6fUr7DwLnNPEvBj7alF8PrARIsqjpz61JDgd+Bfj1pzqoJJclWZ9k/T2P3jvgUyJJkiSNr5oY/dsw7HMileRg4Hzg5iQLgaOrai1AVe2qqp1AgN9M8i1gHXA08FPAZuDsJB9IclZVPQwsAU4EvpBkI/BrwPOaROioqrq9aXpVXzcWANcl2QzcDBzftH87cGySZwOXAGuqag+9BOojVfXoUx1bVV1bVcuqatlxRxyzr0+JJEmSpDlqkOtInQtsqKrtSY6coc4K4FnA0qraneQ+4NCq+naSpcB5wG8l+Ty986y2Th11SnIUUDPEfxewHTiZXhK4q2/bqqb95cCbmrKfBS5K8kHgKGAiya6q+v0BjluSJEmSfswgU/suoZnWV1U7gPub849IckiSw4BFwINNEvVy4IXN9ucCO6vqU8CHgVOBbcCzkpze1FmQ5ISqegh4OMmZTbsr+vqwCHigqiaAS4H5fdtuBC5v+re1+f+sqlpcVYuB3wN+0yRKkiRJ0v7apxGpJkk6B3hrX/GlwB8meT+wG3g9vfOm/izJemAjcHdT98XAh5JMNHV/uaqeSHIR8NFmOt9B9JKdrfTOd/pEkp3AbX1tfgxYk+T1wJeAxyY3NCNldwF/OsgTIEmSJGlmVcNZXnzU7VMi1Zz/9MwpZfcAr5im+tQFIgDu48cToskYG4Gfn6b8TnrT9yZd2dfmSX3l75m80yR7x/GjxTCmxrxyunJJkiRJGtSgq/aNpCRn0xv9urpZyEKSJEmSOjPIYhMjq6rWAS8Ydj8kSZKkcTOs5cVH3ViMSEmSJEnSgWQiJUmSJEkDGoupfW2al9mxKsnOxxe0HjOZ6fJd4y3znuwgZvvvo4kZL6/29O25409aj3nQWf+29ZgafQed8brWY1Z9vtV4E7Pj4535HXwUVwef7xO0/4TOqw4+5zr47EwHxw7tz53q4vfGIT925Zl2PNnB697FSzSvk9d9dqjZ8gF6gDkiJUmSJEkDMpGSJEmSpAE5tU+SJEnSjLqYfTkOHJGSJEmSpAGZSEmSJEnSgJzaJ0mSJGlGrto3PUekJEmSJGlAe02kkixJsrHvtiPJ5Qeic037i5Ns2Y99/7Gv73/Qdv8kSZIkzT17ndpXVduAUwCSzAd+AKztuF9t+m5VnTLsTkiSJEmzkVP7pjfo1L5X0ktMvp/k2CTrkmxKsiHJzyQ5IskXm8ebk1wAkOTwJJ9r6m5JcnFTvjTJ7UnuTHJbkuf0lW9K8jXgbZONNyNMdzTxNyQ5oylfNdlW83h1kvP387mRJEmSpGkNmkgtB25q7q8Grqmqk4EzgAeAXcCFVXUq8HLgd5IEeBXww6o6uapOBP4iyQLgauCiqloKfAK4qol9A/DOqjp9SvsPAuc08S8GPtqUXw+sBEiyqOnPrc22Y5L8TZOwnTXdQSW5LMn6JOu//ci9Az4lkiRJkuaafU6kkhwMnA/cnGQhcHRVrQWoql1VtRMI8JtJvgWsA44GfgrYDJyd5ANJzqqqh4ElwInAF5JsBH4NeF6TCB1VVbc3Ta/q68YC4Lokm4GbgeOb9m8Hjk3ybOASYE1V7aGX3L2gql4C/Hvgj5IcOfXYquraqlpWVctetPCYfX1KJEmSJM1Rgyx/fi6woaq2T5eMNFYAzwKWVtXuJPcBh1bVt5MsBc4DfivJ5+mdZ7V16qhTkqOAma6f/C5gO3AyvSRwV9+2VU37y4E3AVTV48Djzf07k3wXeBGwfoDjliRJkuasmumb+Rw3yNS+S2im9VXVDuD+JK8FSHJIksOARcCDTRL1cuCFzfbnAjur6lPAh4FTgW3As5Kc3tRZkOSEqnoIeDjJmU27K/r6sAh4oKomgEuB+X3bbgQub/q3tYn5rGaBDJL8NHAc8L0BjlmSJEmS/pl9GpFqkqRzgLf2FV8K/GGS9wO7gdfTO2/qz5KsBzYCdzd1Xwx8KMlEU/eXq+qJJBcBH22m8x0E/B6wld75Tp9IshO4ra/NjwFrkrwe+BLw2OSGZqTsLuBP++r/PPD+JHuAJ4Ffqqp/2JdjliRJkqSZ7FMi1Zz/9MwpZfcAr5im+tQFIgDu48cToskYG+klO1PL76Q3fW/SlX1tntRX/p7JO02ydxw/WgyDqloDrJmmP5IkSZL2gcufT2/QVftGUpKz6Y1+Xd0sZCFJkiRJnRlksYmRVVXrgBcMux+SJEmS5oaxSKQkSZIkdaPKqX3TGYupfZIkSZJ0IDkiNcVsySz/8cn5e680qF0Htx7ycJ5oNV7S/oUMMkv+yDKfidZj1v/c3nrMPV/9TOsxD/qXF7UeU6PvyZbf8/Or/U/4Ls6/Dh0ErfY/P+an/edzT+sRYU892UHU9i3o4PmcN+NlOZ++3R38LlrQwbeviQ4ufPTkLPm+oAPHREqSJEnSjDr4W8xYmC0DMJIkSZI0MkykJEmSJGlATu2TJEmSNKMJV+2bliNSkiRJkjQgEylJkiRJGpCJlCRJkiQNaK+JVJIlSTb23XYkufxAdK5pf3GSLfux/0lJvpZka5LNSQ5ts3+SJEnSOKvKyN+GYa+LTVTVNuAUgCTzgR8AazvuVyuSHAR8Cri0qjYleSawe8jdkiRJkjTLDTq175XAd6vq+0mOTbIuyaYkG5L8TJIjknyxebw5yQUASQ5P8rmm7pYkFzflS5PcnuTOJLcleU5f+aYkXwPeNtl4Mzp1RxN/Q5IzmvJVk201j1cnOR/4V8C3qmoTQFX9r6pZcolzSZIkSSNr0ERqOXBTc381cE1VnQycATwA7AIurKpTgZcDv5MkwKuAH1bVyVV1IvAXSRYAVwMXVdVS4BPAVU3sG4B3VtXpU9p/EDiniX8x8NGm/HpgJUCSRU1/bgVeBFSTpG1I8h+nO6gklyVZn2T9tkfuHfApkSRJksZXTWTkb8Owz4lUkoOB84GbkywEjq6qtQBVtauqdgIBfjPJt4B1wNHATwGbgbOTfCDJWVX1MLAEOBH4QpKNwK8Bz2sSoaOq6vam6VV93VgAXJdkM3AzcHzT/u3AsUmeDVwCrKmqPfSmLp4JrGj+vzDJK6ceW1VdW1XLqmrZkoXH7OtTIkmSJGmOGuSCvOcCG6pqe5IjZ6izAngWsLSqdie5Dzi0qr6dZClwHvBbST5P7zyrrVNHnZIcBdQM8d8FbAdOppcE7urbtqppfznwpqbsfuD2qvr7JvatwKnAF/f9sCVJkiTpxw0yte8Smml9VbUDuD/JawGSHJLkMGAR8GCTRL0ceGGz/bnAzqr6FPBhesnMNuBZSU5v6ixIckJVPQQ8nOTMpt0VfX1YBDxQVRPApcD8vm03Apc3/dvalN0GnJTksGbhiZcBfzvAMUuSJElzWtXo34Zhn0akmiTpHOCtfcWXAn+Y5P30VsJ7Pb3zpv4syXpgI3B3U/fFwIeSTDR1f7mqnkhyEfDRZjrfQcDvAVvpne/0iSQ76SVDkz4GrEnyWJF1NgAAIABJREFUeuBLwGOTG5qRsruAP+0r+99Jfhf4Jr1Rrlur6nP7csySJEmSNJN9SqSa85+eOaXsHuAV01SfukAEwH38eEI0GWMj8PPTlN9Jb/repCv72jypr/w9k3eaZO84frQYxmSsT9FbAl2SJEmSWjHIOVIjK8nZ9Fb9+91mIQtJkiRJLRjWqnijbtDlz0dSVa2rqhdU1e8Nuy+SJEmSRkuSVyXZluQ7SX71KepdlKSSLNtbzLFIpCRJkiRpOknmA9fQW4X8eOCSJMdPU28h8E7gG/sSdyym9kmSJEnqxkTN+ql9LwW+U1XfA0jyx8AF/PPVvP8T8EHg3fsS1ERqijA73ii7fmzl93bMm2g9JPMeX9BuvAxpfcsBZV77/UwHxz5x739vPWYXw9x7vvqZ1mMe9C8vaj2mRtvEjJcofPo6+FGnuvhZ7+B3W7p4PluPCE920E/qyfZjduCgLr7TpIMvCx1Y0MG7ac+w1thWG44G/q7v8f3Az/ZXSPIS4PlV9d+S7FMi5dQ+SZIkSbNaksuSrO+7Xda/eZpdqm/fecBHgP8wSJuOSEmSJEmaUc2CqX1VdS1w7Qyb7wee3/f4ecAP+x4vBE4EvpwE4F8An01yflWtn6lNR6QkSZIkjbNvAsclOSbJwcBy4LOTG6vq4ar6yapaXFWLga8DT5lEgYmUJEmSpDFWVXuAtwO3AXcBf1JVW5O8P8n5TzeuU/skSZIkjbWquhW4dUrZ+2ao+wv7EtNESpIkSdKMXLBwenud2pdkSZKNfbcdSS4/EJ1r2l+cZMvT3HfFlL5PJDml7T5KkiRJmlv2OiJVVduAU+Cfrgr8A2Btx/1qRVWtBlYDJHkx8F+rauNweyVJkiRptht0sYlXAt+tqu8nOTbJuiSbkmxI8jNJjkjyxebx5iQXACQ5PMnnmrpbklzclC9NcnuSO5PcluQ5feWbknwNeNtk483o1B1N/A1JzmjKV0221TxePc2JY5cANw38DEmSJElz2ERl5G/DMGgitZwfJSOrgWuq6mTgDOABYBdwYVWdCrwc+J30FmN/FfDDqjq5qk4E/iLJAuBq4KKqWgp8AriqiX0D8M6qOn1K+w8C5zTxLwY+2pRfD6wESLKo6c+tU/a9GBMpSZIkSS3Y50SqWXP9fODmJAuBo6tqLUBV7aqqnfSuGvybSb4FrAOOBn4K2AycneQDSc6qqoeBJfQufPWFJBuBXwOe1yRCR1XV7U3Tq/q6sQC4Lslm4Gbg+Kb924Fjkzyb3sjTmmaZw8m+/yyws6qmPdeq/0rI2x753r4+JZIkSZLmqEFW7TsX2FBV25McOUOdFcCzgKVVtTvJfcChVfXtJEuB84DfSvJ5eudZbZ066pTkKGCmtUHeBWwHTqaXBO7q27aqaX858KYp+/WPpP0z/VdCftPii1yXRJIkSWrUkKbOjbpBpvb90zlGVbUDuD/JawGSHJLkMGAR8GCTRL0ceGGz/bn0RoQ+BXwYOBXYBjwryelNnQVJTqiqh4CHk5zZtLuirw+LgAeqagK4FJjft+1G4PKmf1snC5PMA14P/PEAxypJkiRJM9qnRKpJks4BbukrvhR4ZzON76+Af0HvvKllSdbTS4Dubuq+GPjrZgrfFcBvVNUTwEXAB5JsAjbSO7cJeuc7XdMsNvGPfW1+DHhDkq8DLwIem9xQVdvpXan4hind/3ng/qpyzp4kSZKkVuzT1L7m/KdnTim7B3jFNNWnLhABcB9w2zRxN9JLdKaW30lv+t6kK/vaPKmv/D2Td5pk7zimTOGrqi8DPzdNnyRJkiTthRfknd6gq/aNpCRn0xv9urpZyEKSJEmSOjPIYhMjq6rWAS8Ydj8kSZIkzQ1jkUhJkiRJ6sawLng76sZiap8kSZIkHUgmUpIkSZI0IKf2TTFbMstd6aCnHazIkifbDZrHF7QaD+Dwee0f+O5d8/deaQTsue8fWo/ZxYfK/HntTynY81e37L3SgA4643Wtx5zLJlpeJqqDtxET7YckHXwYd/G7rYtVvCY6eY1mx3Jj6eTdNDu+K5Aujr19B8+ab4k6UEykJEmSJM2oPEdqWqbWkiRJkjQgEylJkiRJGpBT+yRJkiTNyOXPp+eIlCRJkiQNyERKkiRJkga010QqyZIkG/tuO5JcfiA617S/OMmWp7nvgiT/JcnmJHcleU/b/ZMkSZLGWc2C2zDs9RypqtoGnAKQZD7wA2Btx/1qy+uBQ6rqxUkOA/42yU1Vdd+Q+yVJkiRpFht0at8rge9W1feTHJtkXZJNSTYk+ZkkRyT5YvN4c5ILAJIcnuRzTd0tSS5uypcmuT3JnUluS/KcvvJNSb4GvG2y8WZ06o4m/oYkZzTlqybbah6vTnI+vQT18CQHAc8AngB2PP2nS5IkSZIGX7VvOXBTc3818NtVtTbJofSSsieAC6tqR5KfBL6e5LPAq4AfVtWrAZIsSrIAuBq4oKr+Z5NcXQW8CbgBeEdV3Z7kQ33tPwicU1W7khzX9GUZcD3wLuC/JlkEnAG8AQhwAfAAcBjwrqr6hwGPWZIkSZqzXLVvevs8IpXkYOB84OYkC4Gjq2otQFXtqqqd9BKX30zyLWAdcDTwU8Bm4OwkH0hyVlU9DCwBTgS+kGQj8GvA85pE6Kiqur1pelVfNxYA1yXZDNwMHN+0fztwbJJnA5cAa6pqD/BS4EngucAxwH9I8tPTHNtlSdYnWX/3I9/b16dEkiRJ0hw1yIjUucCGqtqe5MgZ6qwAngUsrardSe4DDq2qbydZCpwH/FaSz9M7z2prVZ3eHyDJUcx8zti7gO3AyfSSwF1921Y17S+nN6oF8IvAX1TVbuDBJF+lN4L1Y9lSVV0LXAvwfy++aFjnq0mSJEmaJQY5R+oSmml9VbUDuD/JawGSHNIs5rAIeLBJol4OvLDZ/lxgZ1V9CvgwcCqwDXhWktObOguSnFBVDwEPJzmzaXdFXx8WAQ9U1QRwKTC/b9uNwOVN/7Y2Zf8deEV6Dgd+Drh7gGOWJEmS5rSqjPxtGPYpkWqSpHOAW/qKLwXe2Uzj+yvgX9A7b2pZkvX0EqDJpOXFwF83U/iuAH6jqp4ALgI+kGQTsJHeuU0AK4FrmsUm/rGvzY8Bb0jydeBFwGOTG6pqO3AXvfOrJl0DHAFsAb4J3FBV39qXY5YkSZKkmezT1L7m/KdnTim7B3jFNNVPn6bsPuC2aeJuBH5+mvI76U3fm3RlX5sn9ZX/03WhmmRvcgGKyTiP0lsCXZIkSZJaM+jy5yMpydn0Rr+ubhaykCRJkqTODLr8+UiqqnXAC4bdD0mSJGncTAy7AyNqLEakJEmSJOlAMpGSJEmSpAGNxdQ+SZIkSd0ohrO8+KgzkZpiZz3ZeswLFv6frcc8+3WPth6zJjq4FnHbMSdmySzdiQ4Geyfa/xD7t59b0HrMib/c2XrM4m9bjznB1r1XGlDV51uP+eQsmZk+Ue1/fnxx03Wtx9Tc859PfV/rMXem/ff7413EpP2YD7On9Zh7Ovic29XB97lHa3frMTW7ObVPkiRJkgbkiJQkSZKkGXUxaWkcOCIlSZIkSQMykZIkSZKkATm1T5IkSdKMJly1b1qOSEmSJEnSgGZFIpXkyiTvfhr7vT7J1iQTSZZ10TdJkiRJc8+4T+3bArwO+MNhd0SSJEmajbwg7/RGdkQqyRVJtiVZByxpyt6S5JtJNiVZk+SwJAuT3JtkQVPnyCT3JVlQVXdV1bahHogkSZKksTOSiVSSpcBy4CX0RpROazbdUlWnVdXJwF3Am6vqEeDLwKubOsuBNVX7fvnpJJclWZ9k/Xceva+lo5AkSZI0rkYykQLOAtZW1c6q2gF8tik/MckdSTYDK4ATmvLrgZXN/ZXADYM0VlXXVtWyqlp27BGL97/3kiRJ0piYmAW3YRjVRApgumso3wi8vapeDPw6cChAVX0VWJzkZcD8qtpywHopSZIkac4Z1UTqK8CFSZ6RZCHwmqZ8IfBAcz7Uiin7fBK4iQFHoyRJkiRpUCOZSFXVBuDTwEZgDXBHs+m9wDeALwB3T9ltNfAT9JIpAJJcmOR+4HTgc0lu67jrkiRJkuaAkV3+vKquAq6aZtPHZ9jlTOAzVfVQX4y1wNoOuidJkiTNCS5/Pr2RTaQGkeRq4FzgvGH3RZIkSdL4G4tEqqreMew+SJIkSZo7xiKRkiRJktSNYS0vPupGcrEJSZIkSRpljkhNMc+T6do1r+Xnc958mJjuEmP7YWKW/J2l7ecSmJ/2/5aSaS8Bt3+ebD9kJ39Fmujg42N+td/TiQ5eow7enlIrunhrHtxF1A4+5/ak/aALmd96zMdaj9jN5/Es+bagA8hESrNL20mUJEmSnpJJ5PSc2idJkiRJAzKRkiRJkqQBObVPkiRJ0oy8IO/0HJGSJEmSpAGZSEmSJEnSgJzaJ0mSJGlGXSwnPw5mxYhUkiuTvPtp7PehJHcn+VaStUmO6qJ/kiRJkuaWWZFI7YcvACdW1UnAt4H3DLk/kiRJksbAyCZSSa5Isi3JOmBJU/aWJN9MsinJmiSHJVmY5N4kC5o6Rya5L8mCqvp8Ve1pQn4deN6QDkeSJEnSGBnJRCrJUmA58BLgdcBpzaZbquq0qjoZuAt4c1U9AnwZeHVTZzmwpqp2Twn7JuDPZ2jvsiTrk6y/59F72z0YSZIkaRabICN/G4aRTKSAs4C1VbWzqnYAn23KT0xyR5LNwArghKb8emBlc38lcEN/sCRXAHuA1dM1VlXXVtWyqlp23BHHtHwokiRJksbNKK/aV9OU3Qi8tqo2JXkj8AsAVfXVJIuTvAyYX1VbJndI8gbgXwOvrKrpYkqSJEnSQEZ1ROorwIVJnpFkIfCapnwh8EBzPtSKKft8EriJvtGoJK8CfgU4v6p2dt9tSZIkabzULLgNw0gmUlW1Afg0sBFYA9zRbHov8A16q/HdPWW31cBP0EumJv0+veTrC0k2JvmDLvstSZIkaW4Y2al9VXUVcNU0mz4+wy5nAp+pqof6YhzbRd8kSZIkzW0jm0gNIsnVwLnAecPuiyRJkjROJobdgRE1FolUVb1j2H2QJEmSNHeM5DlSkiRJkjTKxmJESpIkSVI3JjKcC96OOhOpKWbN22Re+z3t4throuUFKTs47m4GZjuYTdz2cwmkg1e9k2HuDl722XJVuYkOjn1eB8fu/HmNqi6+6HTy+dHBF9UnOvjwfLL1iHA481uP2cln0qz5kqgDxal9kiRJkjQgR6QkSZIkzWiWTOI44ByRkiRJkqQBmUhJkiRJ0oCc2idJkiRpRi4oND1HpCRJkiRpQCZSkiRJkjSgWZFIJbkyybufxn7/Kcm3kmxM8vkkz+2if5IkSZLmllmRSO2HD1XVSVV1CvDfgPcNu0OSJEnSbDKR0b8Nw8gmUkmuSLItyTpgSVP2liTfTLIpyZokhyVZmOTeJAuaOkcmuS/Jgqra0RfycFwGX5IkSVILRjKRSrIUWA68BHgdcFqz6ZaqOq2qTgbuAt5cVY8AXwZe3dRZDqypqt1NrKuS/B2wghlGpJJclmR9kvX3PHpvV4clSZIkaQiSvKoZpPlOkl+dZvsvJdncnBL0l0mO31vMkUykgLOAtVW1sxlV+mxTfmKSO5JsppcYndCUXw+sbO6vBG6YDFRVV1TV84HVwNuna6yqrq2qZVW17LgjjungcCRJkqTZaYKM/O2pJJkPXAOcCxwPXDJNovRHVfXi5pSgDwK/u7fnZVQTKZh+Gt6NwNur6sXArwOHAlTVV4HFSV4GzK+qLdPs+0fAv+mor5IkSZJG00uB71TV96rqCeCPgQv6KzydU4JGNZH6CnBhkmckWQi8pilfCDzQnA+1Yso+nwRuom80KslxfdvPB+7ursuSJEmShqH/VJ3mdlnf5qOBv+t7fH9TNjXG25J8l96I1Dv31uZB+9vpLlTVhiSfBjYC3wfuaDa9F/hGU7aZXmI1aTXwG/SSqUm/nWQJvQsyfx/4pY67LkmSJI2V2bBaW1VdC1w7w+bp5v79s8OqqmuAa5L8IvBrwBueqs2RTKQAquoq4KppNn18hl3OBD5TVQ/1xXAqnyRJkjS33Q88v+/x84AfPkX9P2bmnOOfjGwiNYgkV9M7eey8YfdFkiRJ0kj5JnBckmOAH9Bb5fsX+yskOa6q7mkevhq4h70Yi0Sqqt4x7D5IkiRJ42hYF7xtS1XtSfJ24DZgPvCJqtqa5P3A+qr6LPD2JGcDu4H/zV6m9cGYJFKSJEmSNJOquhW4dUrZ+/ru/7+DxhzVVfskSZIkaWQ5IqUfmdf+uG3bEWtiNqwbA8zr4m8UE61HPKj1V6iLXnaji2kK8zt4e6aD16jSfkczK9Z00lzUxc9lJ9OcOujnIZ18frQeksfbD8kRzG895qOtR5w9Zsvv9gPNESlJkiRJGpCJlCRJkiQNyERKkiRJkgbkOVKSJEmSZuRZsNNzREqSJEmSBmQiJUmSJEkDcmqfJEmSpBl1suT/GJgVI1JJrkzy7v3Y/91JKslPttkvSZIkSXPTrEik9keS5wPnAP992H2RJEmSNB5GNpFKckWSbUnWAUuasrck+WaSTUnWJDksycIk9yZZ0NQ5Msl9k4+BjwD/ERcckSRJkgY2MQtuwzCSiVSSpcBy4CXA64DTmk23VNVpVXUycBfw5qp6BPgy8OqmznJgTVXtTnI+8IOq2rSX9i5Lsj7J+nsevbeDI5IkSZI0TkYykQLOAtZW1c6q2gF8tik/MckdSTYDK4ATmvLrgZXN/ZXADUkOA64A3re3xqrq2qpaVlXLjjvimFYPRJIkSdL4GeVV+6abincj8Nqq2pTkjcAvAFTVV5MsTvIyYH5VbUnyYuAYYFMSgOcBG5K8tKr+x4E4AEmSJGm2G9bUuVE3qiNSXwEuTPKMJAuB1zTlC4EHmvOfVkzZ55PATcANAFW1uaqeXVWLq2oxcD9wqkmUJEmSpP01kolUVW0APg1sBNYAdzSb3gt8A/gCcPeU3VYDP0EvmZIkSZKkzozs1L6qugq4appNH59hlzOBz1TVQzPEW9xS1yRJkqQ5o7wg77RGNpEaRJKrgXOB84bdF0mSJEnjbywSqap6x7D7IEmSJGnuGMlzpCRJkiRplI3FiJQkSZKkbrj8+fRMpKaYl/bPpgsdnKGXDgYTa/R/TDKv/edyuguW7beJDqLOa/81n9/B+72bJ7R9XfxcVjo4+A5+Lic6OHanN2hUdfFFpzr4UZ/o4OP4oA5+1g/p4jO+g2N/vP2QHMb8DqJqNvN3nyRJkiQNyBEpSZIkSTMa/TlLw+GIlCRJkiQNyERKkiRJkgbk1D5JkiRJM5ol60gdcI5ISZIkSdKATKQkSZIkaUCzIpFKcmWSdz/N/X6QZGNzO6+L/kmSJEnjaiKjfxuGuXCO1Eeq6sPD7oQkSZKk8TGyI1JJrkiyLck6YElT9pYk30yyKcmaJIclWZjk3iQLmjpHJrlv8rEkSZIktW0kE6kkS4HlwEuA1wGnNZtuqarTqupk4C7gzVX1CPBl4NVNneXAmqra3Tx+e5JvJflEkp+Yob3LkqxPsv7bj9zb0VFJkiRJs8/ELLgNw0gmUsBZwNqq2llVO4DPNuUnJrkjyWZgBXBCU349sLK5vxK4obn/ceBngFOAB4Dfma6xqrq2qpZV1bIXLTym/aORJEmSNFZGNZGC6ZesvxF4e1W9GPh14FCAqvoqsDjJy4D5VbWlKd9eVU9W1QRwHfDSA9JzSZIkSWNtVBOprwAXJnlGkoXAa5ryhcADzflPK6bs80ngJn40GkWS5/RtvxDY0l2XJUmSpPEz7Gl7ozq1byRX7auqDUk+DWwEvg/c0Wx6L/CNpmwzvcRq0mrgN+glU5M+mOQUeqNb9wFv7bbnkiRJkuaCkUykAKrqKuCqaTZ9fIZdzgQ+U1UP9cW4tIu+SZIkSZrbRjaRGkSSq4FzAS+4K0mSJKlzY5FIVdU7ht0HSZIkaRxNtwKcRnexCUmSJEkaWSZSkiRJkjSgsZja1yYzy5bNS7vxJtofXE7bfaSjIfAOjn1+F+/4tL8IaWj/NaLa7+dEB/2cn/Zfo3TwDi3nfWhEpYP3Zjr4SOriC9mTHcTsYpnpQ6r9J3Sig9doYg5PcOvi+RwH5g2SJEmSNCATKUmSJEkakFP7JEmSJM2oiymd48ARKUmSJEkakImUJEmSJA3IqX2SJEmSZjR31yt8ao5ISZIkSdKAZkUileTKJO9+mvu+I8m2JFuTfLDtvkmSJEmae8Z6al+SlwMXACdV1eNJnj3sPkmSJEmzyVy+GPFTGdkRqSRXNCNJ64AlTdlbknwzyaYka5IclmRhknuTLGjqHJnkvubxLwO/XVWPA1TVg0M7IEmSJEljYyQTqSRLgeXAS4DXAac1m26pqtOq6mTgLuDNVfUI8GXg1U2d5cCaqtoNvAg4K8k3ktye5DSmkeSyJOuTrN/2yL3dHZgkSZKksTCSiRRwFrC2qnZW1Q7gs035iUnuSLIZWAGc0JRfD6xs7q8EbmjuHwT8BPBzwP8H/EmSTG2sqq6tqmVVtWzJwmO6OSJJkiRJY2OUz5GabjLmjcBrq2pTkjcCvwBQVV9NsjjJy4D5VbWlqX8/vVGsAv46yQTwk8D/7LrzkiRJ0jiYGHYHRtSojkh9BbgwyTOSLARe05QvBB5ozn9aMWWfTwI38aPRKIA/BV4BkORFwMHA33fZcUmSJEnjbyQTqaraAHwa2AisAe5oNr0X+AbwBeDuKbutpjeN76a+sk8AP51kC/DHwBua0SlJkiRJetpGdmpfVV0FXDXNpo/PsMuZwGeq6qG+GE8A/66D7kmSJElzgqMQ0xvZRGoQSa4GzgXOG3ZfJEmSJI2/sUikquodw+6DJEmSpLljLBIpSZIkSd1w1b7pjeRiE5IkSZI0yhyR0o+kg7y6Wv4bxrx/dj3l/TcxS06h7ODYu/lLShdRO/hbWAfv93kdLAq6p/WIHb1CHfxoSm3o4v3eyZenDn4VdXHs89LFD3v7B39IddDPLr4naVYzkZIkSZI0I/9YNj1Ta0mSJEkakImUJEmSJA3IqX2SJEmSZjThJXmn5YiUJEmSJA3IREqSJEmSBuTUPkmSJEkzcmLf9GZFIpXkSuDRqvrwgPt9GljSPDwKeKiqTmm5e5IkSZLmmFmRSD1dVXXx5P0kvwM8PMTuSJIkSRoTI3uOVJIrkmxLso5mVCnJW5J8M8mmJGuSHJZkYZJ7kyxo6hyZ5L7Jx01ZgH8L3DSUg5EkSZI0VkYykUqyFFgOvAR4HXBas+mWqjqtqk4G7gLeXFWPAF8GXt3UWQ6sqardfSHPArZX1T0ztHdZkvVJ1m975N72D0iSJEmapSZmwW0YRjKRopf4rK2qnVW1A/hsU35ikjuSbAZWACc05dcDK5v7K4EbpsS7hKcYjaqqa6tqWVUtW7LwmNYOQpIkSdJ4GuVzpKZbIORG4LVVtSnJG4FfAKiqryZZnORlwPyq2jK5Q5KD6I1qLe28x5IkSZLmhFEdkfoKcGGSZyRZCLymKV8IPNCc/7Riyj6fpDfqNHU06mzg7qq6v8sOS5IkSeNoghr52zCMZCJVVRuATwMbgTXAHc2m9wLfAL4A3D1lt9XAT/DPp/Atn6ZMkiRJkp62kZ3aV1VXAVdNs+njM+xyJvCZqnpoSpw3ttw1SZIkSXPcyCZSg0hyNXAucN6w+yJJkiSNk+FMnBt9Y5FIVdU7ht0HSZIkSXPHSJ4jJUmSJEmjbCxGpCRJkiR1Y1gXvB11JlJT3PL3G1uP+dqfPKX1mJf9SeshOzGP+cPuwthIBzG7eHUmZsnHbVX7M773dDCLfE892XrMJzvoZxdLz/7nU9/Xarwufoa6+CU6v4OTEbroZzroZxfTZN648f2tx9xz63Wtx6zHHm09Zg59Rusxd/yXv249ZhdvpoceOKz1mP/r4fZjanZzap8kSZIkDcgRKUmSJEkzGtYFb0edI1KSJEmSxlqSVyXZluQ7SX51mu3/PsnfJvlWki8meeHeYppISZIkSRpbSeYD19C77uzxwCVJjp9S7W+AZVV1EvAZ4IN7i2siJUmSJGmcvRT4TlV9r6qeAP4YuKC/QlV9qap2Ng+/Djxvb0FNpCRJkiTNqGbBLcllSdb33S7rO4Sjgb/re3x/UzaTNwN/vrfnxcUmJEmSJM1qVXUtcO0Mm6e7Asa0K2gk+XfAMuBle2tzqCNSSZYk2dh325Hk8il1FifZ8jTjPzPJl5I8muT32+m1JEmSpFnkfuD5fY+fB/xwaqUkZwNXAOdX1eN7CzrUEamq2gacAv90EtgPgLUtNrELeC9wYnOTJEmSNICJYXdg/30TOC7JMfTyjeXAL/ZXSPIS4A+BV1XVg/sSdJTOkXol8N2q+n6SpUk2Jfka8LbJCs3o1B1JNjS3M5ryVUku6Ku3Osn5VfVYVf0lvYRKkiRJ0hxTVXuAtwO3AXcBf1JVW5O8P8n5TbUPAUcANzcz5T67t7ijdI7UcuCm5v4NwDuq6vYkH+qr8yBwTlXtSnJcU38ZcD3wLuC/JlkEnAG8YV8bbk5Guwzg0IN/koMXHLnfByNJkiRpNFTVrcCtU8re13f/7EFjjsSIVJKDgfPpZYCLgKOq6vZm86q+qguA65JsBm6mtw48Td1jkzwbuARY02Se+6Sqrq2qZVW1zCRKkiRJ+pGaBf+GYVRGpM4FNlTV9iRHMcMqGvRGnbYDJ9NLAvun7K0CVtAb2XpTh32VJEmSNMeNxIgUvVGkmwCq6iHg4SRnNttW9NVbBDxQVRPApcD8vm03Apc3MbZ23WFJkiRJc9fQR6SSHAacA7y1r3gl8IkkO+mdFDbpY8CaJK8HvgQ8NrmhGc26C/jTKfHvA44EDk7yWuBfVdXfdnEskiRJ0rgZg1X7OjH0RKqqdgLPnFJ2J73pe5MbGwiMAAAgAElEQVSubMrvAU7qK3/P5J0mIZtcgKI/1uJWOyxJkiRpzhuVqX37pbl41t3A1VX18LD7I0mSJGm8DX1Eqg1VtQ54wbD7IUmSJI2biSGtijfqxmJESpIkSZIOJBMpSZIkSRrQWEzta9M8Muwu7JNhXXhsULNhlZfZ85rPDgtmy99n0v67M7PkvUQ9Oewe7JOdafddf3AHr0918IM50cHbqIt+poN+dvGlZM+t17Ue86Dz3tJ6zD1/9getx6zHH2895pErf671mI/90ddaj/l/PH9n6zGrix9OzWomUpIkSZJmNFv+mHugzZI/HUuSJEnS6DCRkiRJkqQBObVPkiRJ0oxc/nx6jkhJkiRJ0oBMpCRJkiRpQE7tkyRJkjSj2XA5m2EY6ohUkiVJNvbddiS5fEqdxUm2PM345yS5M8nm5v9XtNNzSZIkSXPZUEekqmobcApAkvnAD4C1LTbx98BrquqHSU4EbgOObjG+JEmSpDlolM6ReiXw3ar6fpKlSTYl+RrwtskKzejUHUk2NLczmvJVSS7oq7c6yflV9TdV9cOmeCtwaJJDDuRBSZIkSbNZzYJ/wzBKidRy4Kbm/g3AO6vq9Cl1HgTOqapTgYuBjzbl1wMrAZIsAs4Abp2y778B/qaqHp/acJLLkqxPsv7x3TtaORhJkiRJ42skEqkkBwPnAzc3idBRVXV7s3lVX9UFwHVJNgM3A8cDNHWPTfJs4BJgTVXt6Yt/AvAB4K3TtV9V11bVsqpadsiCI1s+OkmSJEnjZlRW7TsX2FBV25McBTOOz70L2A6cTC8J3NW3bRWwgt7I1psmC5M8j955V/9XVX23g75LkiRJY8tV+6Y3EiNS9EaRbgKoqoeAh5Oc2Wxb0VdvEfBAVU0AlwLz+7bdCFzexNgK0CRlnwPeU1Vf7fIAJEmSJM0dQ0+kkhwGnAPc0le8ErimWWziH/vKPwa8IcnXgRcBj01uqKrtwF30zq+a9HbgWOC9fUusP7ubI5EkSZI0Vwx9al9V7QSeOaXsTnrT9yZd2ZTfA5zUV/6eyTtNQnYcP1qwgqr6DeA3Wu+0JEmSNEcMa1W8UTf0Eak2JDkbuBu4uqoeHnZ/JEmSJI23oY9ItaGq1gEvGHY/JEmSJM0NYzEiJUmSJEkH0liMSEmSJEnqhsufT89EapaaLW/oebPg5MTZ8lx2YT5pPWYXr/iCWTN43v67aUFmx7Gng2N/PC2/m7p4c6b9n6Eu+jnRQTc7+QLRwbHXY4+2HnPPn/1B6zEPes0vtR5z980faT1m7Xxs75UGdPilZ+690oAeW/WXrcd85gvbP3bNbrPjN7QkSZIkjRBHpCRJkiTNaKJGf4bRMDgiJUmSJEkDMpGSJEmSpAE5tU+SJEnSjJzYNz1HpCRJkiRpQCZSkiRJkjSgoSZSSZYk2dh325Hk8il1FifZ8jTjv7Qv9qYkF7bTc0mSJGlumKBG/jYMQz1Hqqq2AacAJJkP/ABY22ITW4BlVbUnyXOATUn+rKr2tNiGJEmSpDlmlKb2vRL4blV9P8nSZgTpa8DbJis0o1N3JNnQ3M5oylcluaCv3uok51fVzr6k6VA8V06SJElSC0YpkVoO3NTcvwF4Z1WdPqXOg8A5VXUqcDHw0ab8emAlQJJFwBnArc3jn02yFdgM/NJ0o1FJLkuyPsn6x3fvaPmwJEmSpNmrZsG/YRiJRCrJwcD5wM1NInRUVd3ebF7VV3UBcF2SzcDNwPEATd1jkzwbuARYM5kwVdU3quoE4DTgPUkOndp+VV1bVcuqatkhC47s6CglSZIkjYuRSKSAc4ENVbUdCDNPwXsXsB04GVgGHNy3bRWwgt7I1A1Td6yqu4DHgBPb67YkSZKkuWhUEqlLaKb1VdVDwMNJzmy2reirtwh4oKomgEuB+X3bbgQub2JsBUhyTJKDmvsvBJYA93V2FJIkSZLmhKGu2geQ5DDgHOCtfcUrgU8k2Qnc1lf+MWBNktcDX6I3wgRAVW1Pchfwp331zwR+NcluYAL4f6rq77s5EkmSJGn8TAy7AyNq6IlUVe0Enjml7E560/cmXdmU3wOc1Ff+nsk7TUJ2HD9asIKqWsWPn2MlSZIkSfttVKb27ZckZwN3A1dX1cPD7o8kSZKk8Tb0Eak2VNU64AXD7ockSZI0bia8FOu0xmJESpIkSZIOJBMpSZIkSRrQWEzta1OS1mM+We0Phz7Zwfopof1jb7uX8zro48yXLXv6ZstfKA5K+z3d08n7vf2YCzp4lbqY+jCvg5gHdfJz1P7z+XjLx74n7T+XT3TwXB7SQcwuXvMnW4/YzWdnDn1G6zHr8cdbj7n75o+0HnPB69/Veszdn/nPrcekg+fz8Df+Qusxd/zh7a3HnC3KqX3Tmi3f9yRJkiRpZJhISZIkSdKAnNonSZIkaUZekHd6jkhJkiRJ0oBMpCRJkiRpQE7tkyRJkjSj6mBF3nHgiJQkSZIkDWioiVSSJUk29t12JLl8Sp3FSbbsZzsvSPJoknfvX48lSZIkachT+6pqG3AKQJL5wA+AtR009RHgzzuIK0mSJI21Li44Pw5GaWrfK4HvVtX3kyxNsinJ14C3TVZoRqfuSLKhuZ3RlK9KckFfvdVJzm/uvxb4HrD1wB6OJEmSpHE1SonUcuCm5v4NwDur6vQpdR4EzqmqU4GLgY825dcDKwGSLALOAG5NcjjwK8CvP1XDSS5Lsj7J+sd3P9zKwUiSJEkaXyORSCU5GDgfuLlJhI6qqtubzav6qi4ArkuyGbgZOB6gqXtskmcDlwBrqmoPvQTqI1X16FO1X1XXVtWyqlp2yIJFrR6bJEmSpPEzKsufnwtsqKrtSY6CGSdivgvYDpxMLwnc1bdtFbCC3sjWm5qynwUuSvJB4ChgIsmuqvr9Do5BkiRJGjsTw+7AiBqVROoSmml9VfVQkoeTnFlVf0kvOZq0CLi/qiaSvAGY37ftRuCvgf9RVVubWGdNbkxyJfCoSZQkSZKk/TX0qX1JDgPOAW7pK14JXNMsNvGPfeUfA96Q5OvAi/7/9u493I6qMP/49yWEuwkXwQuKASFYVERAuYjYClSpNd5AQB4eGkHa/rQIalV+1orys7UWaysFNV4AI6JcRLEiN6URFOQSuYeLINdiUAqJJARI8v7+mDlmczwnyZ49O3vm7PfzPPvJ3mvmvHvtnDmzZ81aswZYNLLA9nxgHsX1VREREREREX0z8B4p24uBzUaVXUcxfG/E8WX5ncCOHeXHjTwpG2TbsWLCitHvc3wtFY6IiIiIGCLO9OdjGniPVB0k7QvcBpxkO9PuRUREREREXw28R6oOti8Fthp0PSIiIiIiYjhMiIZURERERET0x/IM7RvThBjaFxERERERsSalR6ql+jGf/1otONvQnvsYaNAVGJjJ6sP5Gdf/m1/Wh+193WfckaEeT/djq1cfMvuw+1jA0lrzntWH38+y2hPBfdh9rNuH309fvodU/4dfePrVtWdOmbl77ZlevGjVK3Xp6XP+o/bMyQe8v/bMpT+cVXsmTz1Ze+SUI19Te2a0WxpSERERERExLrv5J9sHIUP7IiIiIiIiupSGVERERERERJcytC8iIiIiIsbVnmvU16z0SEVERERERHQpDamIiIiIiIguDbQhJWl7Sdd3PBZKOmbUOtMk3Vwxf5qkJzryv1RPzSMiIiIiYpgN9Bop27cDOwFImgQ8CJxX89vcZXunmjMjIiIiIoaCW3Cv0UFo0tC+fSgaPfdK2kXSDZKuBN47skLZw3S5pLnlY8+yfLakt3Ssd4akGWv+I0RERERExDBoUkPqYODM8vmpwNG29xi1zsPAfrZ3Bg4CvlCWfxWYCSBpKrAncEG5bGtJv5Q0R9Jr+/kBIiIiIiJiODRi+nNJ6wAzgOPKhtDGtueUi2cD+5fPJwP/KWknYBkwHcD2HEknS9oCeDtwru2lkh4CtrL9iKRdgO9JeqnthaPe/yjgKIAN1t2cdSdP7e8HjoiIiIhoieUZ2jempvRI7Q/MtT0fEIz72zoWmA+8AtgVWKdj2WzgUIqeqVMBbD9p+5Hy+XXAXZSNr062Z9ne1fauaURFRERERMSqNKUhdQjlsD7bjwELJO1VLju0Y72pwEO2lwOHAZM6lp0GHFNm3AIgafNyEgskbQNsB9zdv48RERERERHDYOBD+yRtAOwH/HVH8Uzg65IWAxd1lJ8CnCvpQOAyYNHIAtvzJc0Dvtex/t7ApyQtpRgK+De2/7c/nyQiIiIiYuKxM7RvLANvSNleDGw2quw6iuF7I44vy+8EduwoP27kSdkg244VE1Zg+1zg3NorHRERERERQ60pQ/t6Imlf4DbgJNsLBl2fiIiIiIhoDklvlHS7pF9J+ugYy/cub6+0VNIBq5M58B6pOti+FNhq0PWIiIiIiJho2j5rXzlnwskUlxM9AFwj6Xzbt3asdh/wV8CHVjd3QjSkIiIiIiIixvFq4Fe27waQ9G3gLcAfGlK27ymXLV/d0AkxtC8iIiIiIoaXpKMkXdvxOKpj8ZbA/R2vHyjLepIeqYiIiIiIGJdbMLTP9ixg1jiLNdaP9PqeaUiNspbG+n8eDqvdj9mFdHk229p9+A0t68POdrLqr+dafajnsj5MDzu5LX9Fqz8SYrUtrXmvtGjVq3Rtw2fczrAeT9aeyNiHED1a1/34vuzDwZrqz1z0rStrz9zwsL1WvVK3nqx/a1r6w/GOU6tb+01HrXqlLi298Gu1Z0arPQC8sOP1C4D/6TW0Jd/QERERERERlVwDbCdpa0nrAAcD5/camoZURERERERMWLaXAu8DLgLmAWfZvkXSpyTNAJD0KkkPAAcCX5Z0y6pyM7QvIiIiIiLGtbwPQ9fXNNsXABeMKvvHjufXUAz5W23pkYqIiIiIiOhSGlIRERERERFdytC+iIiIiIgYV/sH9vXHQHukJG0v6fqOx0JJx4xaZ5qkm3t4jx0lXSnpFkk3SVqv95pHRERERMQwG2iPlO3bgZ0AJE0CHgTOqytf0trAN4HDbN8gaTPg6bryIyIiIiJiODVpaN8+wF2275W0C/B1YDFwxcgKkqYBs4ENy6L32f65pNnAOba/X653BvAdYClwo+0bAGw/soY+S0RERETEhLA8g/vG1KTJJg4GziyfnwocbXuPUes8DOxne2fgIOALZflXgZkAkqYCe1JMbzgdsKSLJM2V9OE+f4aIiIiIiBgCjWhIlXcYngGcXTaENrY9p1w8u2PVycBXJN0EnA3sAFCuu62kLYBDgHPLG2+tDewFHFr++zZJ+4zx/kdJulbStUueWtCfDxkRERERERNGU4b27Q/MtT1f0saMPznIscB84BUUjcAlHctmUzSYDgbeXZY9AMyx/TsASRcAOwM/7gy1PQuYBfDsKdPTdxkRERERUcrQvrE1okeKohfpTADbjwELJO1VLju0Y72pwEO2lwOHAZM6lp0GHFNm3FKWXQTsKGmDcuKJ1wG39utDRERERETEcBh4Q0rSBsB+wHc7imcCJ0u6Eniio/wU4HBJV1Fc/7RoZIHt+cA8iuurRsoeBf4NuAa4nqLX64d9+igRERERETEkBj60z/ZiYLNRZddRDN8bcXxZfiewY0f5cSNPygbZdqyYsGIk65sUU6BHRERERESX7AztG8vAe6TqIGlf4DbgJNuZLSIiIiIiIvpq4D1SdbB9KbDVoOsRERERERHDYUI0pCIiIiIioj8ya9/YJsTQvoiIiIiIiDUpDamIiIiIiIguZWhfSy3z8toz10K1Zy5XvZlrtaRruf7fTn/050xK/dvRsj783if1oZ79iFzeh5mSJrfkHNoSL6s1b3k/fj/1R7LRM26RWI8na0/sz//nuq4/9LGHNqg9c9MXLq49c9HsK2rP3PCv/rT2TJ6qf2taeuHXas9c+41H1J659IKv1J4Z7ZaGVEREREREjMstOZG9prXjtGRERERERESDpCEVERERERHRpQzti4iIiIiIcbkP1+tOBOmRioiIiIiI6FIaUhEREREREV0aaENK0vaSru94LJR0zKh1pkm6uWL+oaPyl0vaqZ7aR0RERERMfMtx4x+DMNBrpGzfDuwEIGkS8CBwXo35ZwBnlPkvB75v+/q68iMiIiIiYjg1aWjfPsBdtu+VtIukGyRdCbx3ZIWyd+pySXPLx55l+WxJb+lY7wxJM0blHwKcuSY+SERERERETGxNakgdzIqGzqnA0bb3GLXOw8B+tncGDgK+UJZ/FZgJIGkqsCdwwaifPYg0pCIiIiIiumK78Y9BaERDStI6wAzg7LIhtLHtOeXi2R2rTga+Iukm4GxgB4By3W0lbUHR83Su7aUd+bsBi22Pea2VpKMkXSvp2iVPLaj740VERERExATTlPtI7Q/MtT1f0sYw7hVjxwLzgVdQNAKXdCybDRxK0bP17lE/19nb9UdszwJmATx7yvRMlB8RERERESvVlIbUH65fsv2YpAWS9rJ9BUXjaMRU4AHbyyUdDkzqWHYacDXwG9u3jBRKWgs4ENi7z58hIiIiImLCGdSseE038KF9kjYA9gO+21E8Ezi5nGziiY7yU4DDJV0FTAcWjSywPR+YR3F9Vae9KRpfd/eh+hERERERMYQG3iNlezGw2aiy6yiG7404viy/E9ixo/y4kSdlg2w7Rg3hs/3fwO511jkiIiIiIobbwHuk6iBpX+A24CTbmS0iIiIiIiL6auA9UnWwfSmw1aDrEREREREx0TjXSI1pQvRIRURERERErElpSEVERERERHRpQgztG0bL+5Jaf7ftWjVHLgMk1RtK/WcU+tEFLur/3JP6kNmPszP9yFzWj+29D/+fy+qPZGkf7gC/Th9+S4/76VrzlngZ62jSqlfsJpNlrFdz5uO1phU2oN46Qp+mQ1b929EjCzaoPdPL6//D3OxFi1a9UpcWfnlO7ZlTjnxN7Zn9sPSCr9SeufZfvKf2zLZY3ofvjYkgPVLRKm1oREVEM9XdiAJqb0RFRER75BgyIiIiIiKiSxnaFxERERER48qsfWNLj1RERERERESX0pCKiIiIiIjoUob2RURERETEuDJr39jSIxUREREREdGlgTakJG0v6fqOx0JJx4xaZ5qkmyvmT5Z0uqSbJM2TdFw9NY+IiIiIiGE20KF9tm8HdgKQNAl4EDivxrc4EFjX9sslbQDcKulM2/fU+B4RERERERNWZu0bW5OG9u0D3GX7Xkm7SLpB0pXAe0dWKHunLpc0t3zsWZbPlvSWjvXOkDQDMLChpLWB9YGngIVr9FNFRERERMSE06SG1MHAmeXzU4Gjbe8xap2Hgf1s7wwcBHyhLP8qMBNA0lRgT+AC4BxgEfAQcB9wou3/Hf3Gko6SdK2ka5c8taDeTxURERERERNOI2btk7QOMAM4rmwIbWx7Trl4NrB/+Xwy8J+SdgKWAdMBbM+RdLKkLYC3A+faXirpNeV6zwc2AS6XdKntuzvf3/YsYBbAs6dMT99lREREREQps/aNrRENKYqG0lzb8yVtDOMOxDwWmA+8gqI3bUnHstnAoRQ9W+8uy94FXGj7aeBhST8DdgWe0ZCKiIiIiIjoRlOG9h1COazP9mPAAkl7lcsO7VhvKvCQ7eXAYcCkjmWnAceUGbeUZfcBr1dhQ2B34LZ+fYiIiIiIiBgOA29IlbPp7Qd8t6N4JnByOdnEEx3lpwCHS7qKYljfopEFtucD8yiurxpxMrARcDNwDXCq7Rv78TkiIiIiImJ4DHxon+3FwGajyq6jGL434viy/E5gx47yP9wXqmyQbceKCSuw/TjFFOgREREREVFBpj8f28B7pOogaV+KIXsn2c60exERERER0VcD75Gqg+1Lga0GXY+IiIiIiBgOE6IhFRERERER/ZHpz8c2IYb2RURERERErElpSEVERERERHQpQ/tG+d3CO7S660o6yvasOt9/WDPbUMdkJjOZw5PZhjomM5nJbGZmP+o4aJm1b2zpkerNUclsbF4yk5nMZDYpL5nJTObwZPajjtFAaUhFRERERER0KUP7IiIiIiJiXPbyQVehkdIj1Zt+jH8d1sw21DGZyUzm8GS2oY7JTGYym5k5oa6PivHJmRc+IiIiIiLGsfVmr2h8g+HXj9yw2hPG1SVD+yIiIiIiYlzLM2vfmDK0LyIiIiIioktpSEVERERERHQpDamIiIiWkrTFoOuwOiRtNug6RETULQ2pLkk6X9K7JG1YY+a6Zeb/lfSPI4+68sv32KjOvLpJ2rQPmTP6kFlrPSVtK+kdknboIWPjOuu0Gu/3kh5/fvIYZc/uIW8tSWuVz9eRtHMffk//p+a8jcp6Vv7dlZ9VHa//TNIHJe1fMW/HqnVZRe5WI59T0jRJB0h6WZ/e60cVf26KpH+WNFvSu0YtO6Vi5nMlfVHSyZI2k3S8pJsknSXpeRUzNx312Ay4WtImVbd5SW/seD5V0tck3SjpW5KeUzHzMyN/05J2lXQ38AtJ90p6XcXMuZL+QdKLq/x8hffLfq73vJ72c3Xv48qM1u/nBsV24x+DkIZU9z4H7AXcKuns8o9lvR4zvw+8BVgKLOp41OnWKj8k6eWSrpJ0v6RZkjbpWHZ1xczXSJon6RZJu0m6BLi2fI89Kma+fdTjHcCskdcVM/+h4/kOku4ArpN0j6TdKmZe1nGAcRhwAbA/8B1Jf1clE/idpEslHbGGGlUXV/mh8kvwAeB/JF0saVoNmW8FHgIelPQW4HLgROBGSW+umPmBUY8PAp8aeV0x85SO53tR/D1+DrhJ0l9UyQSuAUa+uP8e+DSwPvABSf9cIe+Xkn4l6QT10LDvJOmjwBzgKklHAheyYnuv+n+58ziPXYCdKlb1VEDAucDBks6VtG65bPeKmadR/J7vBy4DngDeRLGNfqli5u+A6zoe1wJbAnPL51X8U8fzz1H8Pb2ZYvv6csXMN9n+Xfn8X4GDbG8L7Fe+RxWbUGzvl0m6WtKxkp5fMWt1ZD/XfWbd+7m693HQkv1ctEdm7euS7TnAHEmTgNcD7wG+DkzpIfYFtt+46tVWbiV/sAKq9kh9ETgeuAo4ErhC0gzbdwF/dMZtNX0eeGdZpx8Cb7V9haSdgZOA11TIPIti5/UwxecF2JDigMDAdytkvh34f+XzfwXeb/tHkl4N/DuwZ4XMzTsOMI4G9rD9iKQNKP6PT6qQOa+szyHAZyVdAZwJfN/2ExXykPSF8RZRfrFV8FngDbZvkXQAcImkw2xfxYrfWbc+AbyC4sv1BuBVtm+X9CKKg+IfVMj8JEUD95aOek0CnlWxjvDMg/ETKLb5uZK2odh2L6iQOcn2o+Xzg4DX2n5C0mcoDqyP6zLvRuAwiu3ofEmLKLajb9u+p0L9KPN2ADYA7gG2sf1bFT36vwD+rULmNRQHLWNtM1W3zRfbfkf5/HuSPgb8RL31aj/H9klQnOm3/S9l+UmSjqiY+WFgX+Dvbd9UZv/a9tY91LPTrrZHGqOfl3R4xZzJkta2vRRY3/Y1ALbv6GigdutR2x8CPiTptRTb6VxJ84AzbXd9357s5xq/n6t7Hwft2c9FS6QhVYGk9SkO0A8CdgZO7zHy55JePvLF2IN/ojjgXzrGsqq9jxvZvrB8fqKk64ALy96Uqv2okzsOAn5r+wqAcoe7fsXMPYDPUBxkfcm2Jf2p7ZkV80Z7vu0flfW8uod6Pi1pS9sPAo+zoufxSYovsUqZtv8L+K+ObfNg4GRJF9l+18p/fEwzgQ+W9RrtkIr1XMf2LQC2zykPgL5bns2r3Cdv+zcAku6zfXtZdq/KYTAVvJTii29D4JO2F0s63PYnq9ZxlCm255b1vLs8KVPFQkkvs30zRU/FehS9HmtT7e/dZdbHgI+VJwwOBi6XdL/tKicOlpUHPk+VdXukfKNFUuXbfcwD/tr2naMXSLq/Yua6ktayvbys36fLXoWfUv0kVOfv4BsrWbbabJ8o6dsUjZz7KQ6wex3PskV5Ek7AFEnyijEyVf+GTgYuKA94L5T07xQns/YBru+xvti+nGK7/DuKXq6DqHYD1Oznmr2fq3sfV1anFfu5xsn052NLQ6pLkr4D7EbR+3Ey8N8jX7492Av4K0m/ptihi+KPvduxvHOB79m+bvSCsru5CkmaansBRaUuUzFs7lyg6vjszh3g6DNK61QJtH2NpP2Av6M4k/wRej/A2EbS+RS/jxdI2sD24nJZ1d64Y4GLJZ1LcSbwJ5IuBF5LMbyoij/sqcseqLOAsyRNBd5aMfMa4GbbP/+jN5OOr5j5tKTnjhwQlGds9wH+C6h83UPHAfC7O8omUX1bug84oBxCc4mkz1etW4eXSLqR4nc1TdImth8tD4Kqbkt/A5wh6QaKnthrJc0BduSZw7VW1zO+8W1fTXH9zQeBvSvWca6kb1EcrP0YOL3c3l9PxeHGFD3k4x1EVR0e+wOKOl06UmD7dEnzqdZLDPB9SRvZftx25zDhbYE7KmZi+wHgQBVDui6hOAvei6+wohfidODZwG8lPZeKjR7bJ0m6CfhbYDrFscZ04Hus6OXv1h/9n9leRvFdfOEfr75asp9r9n6u7n0ctGc/Fy2hQV2c1VYqLsy9pNyB15X5orHKbd/bZc72wCMdQ8c6lz3H9vwKdXsXcHc5LKGzfCvg47bfUyFzBnBpR6NkpPzFwDtsf7bbzFE5W1IMH9zV9jY95Iy+KPo624+ruAD7ANsnV8ydCryLFQcYD1AMw7utYt6HbJ9Y5WdXkrkpsGT076jHzH2B39q+YVT5VOB9tj9dIfNVwE22l4wqnwbsZfub1WsM5dCM44HdbFf9kh3rb/wh20+puF5ub9tVhp6OHEj9Oc/cli6y/ViFrHfZ/laVeqwkc23gQIqTGucAr6bY9u8DTrZd+VpQSZPq3A+3MbPsgX5xeYa9lswaqteazOzn/pDT2P1cnfu4MhQZiBsAAA62SURBVK9V+7kmecGmL2t8g+GB/715jXcBpiHVJRUz8fwtK85czKEYSvZ0j7l7AdvZPlXS5hRD6n5dMetldXyxJjOZkv4SuKCGXtdktiSzDXUsM39NcdByqu1azvq2MPPrtufVnDmM9WzLNj+UmW2oY78ym2TLTV7a+AbDg4/essYbUpm1r3tfBHYBTikfO5dllUn6BPARVgxzmwz0cobpSypmNfo/qm8Wt2QOZ+bBwJ2SPivpT5I5FJltqCMUw3vuAL6qYmbRoyT1MulPGzO/lnrWktmWbX5YM9tQx35lRsOlR6pLkm6w/YpVlXWZeT3wSmCu7VeWZTdWuEaqM3M7irHUBwJXU5y9u6Rq3jiZp9muNJ3rGs5s6mefTnGxcz/rWUfmFIoLr2dSDF04lWKWrN8nc2JmtqGOo7L3pph5a2OK3ooTbP8qmcnsIqsV2/ywZrahjv3KbIr0SI0tPVLdW6aOGwKqmNaz1/HaT7lo0brM7Plmvy5mtPoHip6u1wFfkHSbKt5TaZzM/2hJZlM/+x1roJ51ZC6kmFzk28DzgLdRXFxb9cL+ZDY8sw11lDRJ0gxJ5wH/QXG/mm0oJo6oMp18Moc0E9qxzQ9zZhvq2K/MplhuN/4xCJm1r3t/T3FDwLvL19Mozjz04ixJXwY2lvQeih6Fr1QNU3Hn7pkUN3+8BHizi6nFnw9cSYV7KiVzaDPfTLE9vhiYDbza9sMq7ns1jwozmiWz2ZltqGPpToob3f6rnznr2jllT0UVyRzCzLZs88Oa2YY69iszmi9D+7okaT2K+07sUxZdAnzeo2bTqZC7H8XMNKKYkabycCxJP6VoiJ3jUTdkVXFjwNnJTOZqZn4D+Krtn46xbB/bP07mxMpsQx3Ln9vI9uPd/lwykzlGZlu2+aHMbEMd+5XZJM/beIfGNxgeeuzWzNrXdJLOAhYCZ5RFhwCb2D5wcLWKiBgu5UmtIyhuLLreSLntd4/7Q8lMZkRU8tyN/6TxDYbfPDYv10i1wPa2j7R9Wfk4iuL+Bl2T9HtJC8d7VK2gpO0knSPpVkl3jzyq5iVzqDN3l3SNpMclPSVpWS/bZjKbn9mGOpZmA88F3kBxG4oXAL1e0J3MIcxsyzY/rJltqGO/MqP50pDq3i8l7T7yQtJuwM+qBNl+lu0pwL8DHwW2pPhS+AjV7/4OxSwxXwSWAn8GfIPiy6cXyRzOzP+k6HW9E1gfOJLex3kns9mZbagjwLa2Pw4ssn06xbWBL09mMitoyzY/rJltqGO/MqPh0pDq3m7AzyXdI+keiov4XyfpJkk3Vsx8g+1TbP/e9kLbXwTe0UMd1y/H4sr2vbaPB17fQ14yhzcTF9MJT7K9zPapFI20ZE7gzDbUERi5Cfpjkl4GTKWY/CeZyexaS7b5oc1sQx37lRnNlln7uvfGPmQuk3QoxXSZpjij0cuU6kskrUVxY7j3AQ8CW/RYx2QOZ+ZiSesA10v6LPAQ0Ov0/MlsdmYb6ggwS9ImFNP9nw9sBHw8mcmsoC3b/LBmtqGO/cpsjMypMLZMNtEAkqZR3A/jNWXRFcAxtu+pmPcqiqk2NwZOoDhj91nbV/VQx2QOZ+aLgIeBycCxZeYp7uFGmslsdmbT6yjpA2MVl//a9r8lM5ldZjd6mx/2zDbUsV+ZTfKcqS9pfINh/oLbMmtfRETEeCR9ony6PfAqil4JgDcDP7V9ZDKTGRH1SkNqbGlINYCkbSh6pHanGNp3JXCs7a5mXJP0g/Lnx2R7RoW6JXM4M29aReaOyZxYmW2o46jsi4F32P59+fpZwNm2Kw+/TuZwZbZlmx/WzDbUsV+ZTbT51O0b32D47YLbV9qQkvRGiuPtSRT3/PrMqOXrUkzUtQvwCHDQqkaH5RqpZvgWcDLwtvL1wcCZFBNbdOPE8t+3U0wP+83y9SHAPRXrlszhzPzL8t/3lv+OzP53KLA4mRMysw117LQV8FTH66fofdKBZA5XZlu2+WHNbEMd+5UZNZM0ieJYez/gAeAaSefbvrVjtSOAR21vK+lg4F+Ag1aamx6pwZP0C9u7jSq7yvbu4/3MKvJ+anvvVZUlM5mrkfkz269ZVVkyJ05mG+pY/vzHgHcC51GcDX4b8B3b/5zMZHaZ2ZZtfigz21DHfmU2Sdt7pCTtARxv+w3l6+MAOvcdki4q17lS0trAb4DNvZLGUqY/b4bLJH1U0jRJL5L0YeCHkjaVtGmFvM3L4YIASNoa2LzHOiZzODM3lLRXR+ae9D4LUTKbndmGOmL708BM4FHgMWBmLwfTyRzeTFqyzQ9xZhvq2K/MxrDd+IekoyRd2/E4quMjbAnc3/H6gbKMsdaxvRRYAGy2sv+XDO1rhpFuw78eVf5uijNu29CdY4H/ljRyjdW0MbK7lczhzDwC+LqkqRTb4gKK7TKZEzezDXUEwPZcYG6vOckc+sy2bPPDmtmGOvYrM7pgexYwa5zFY/VWje5pWp11nvkDGdo3Mam4YO4l5cvbbD+ZzGT2kDuFYn+xoI68ZDY/sw11jOiFpKOB82zfX77ueftMZn2ZbahjvzKb6NlTpje+wfC7hXdkaN8wkjRZ0tGSzikf75M0uYe8A4F1bN9AMTXsmZJ27rGOyRzOzOdI+hrFNQgLJO0g6YhkTtzMNtQxoiYnAL+QdLmkv6XYf/Z68JvM+jLbUMd+ZTbOcrvxj1W4BthO0tYqbpx8MCtuozDifODw8vkBwE9W1oiCNKSa4osUUy2eUj52Kcuq+rjt36sYq/sG4PQe85I5vJmnARcBzy9f3wEck8wJnVl3Xr8yI3p1N/ACigPhXYF5ki6UdLiKadWTOdjMNtSxX5lRs/Kap/dRfBfNA86yfYukT0kauU3M14DNJP0K+ADw0VXlpiHVDK+yfbjtn5SPmRQ3HKxqWfnvm4Av2v4+sE6PdUzmcGY+2/ZZwHL4w45o2cp/JJktz2xDHSPqYNvLbV9s+wiKhv4pwBspDo6TOdjMNtSxX5nRB7YvsD3d9otdTFyD7X+0fX75fIntA21va/vVXo37uWayiWZYJunFtu8CUDHzWi8HGQ9K+jKwL/AvKq6b6bXRnMzhzFwkaTPKiy0l7U5xAW0yJ25mG+oYUYdnXE9h+2mKoT3nS1o/mQPPbEMd+5XZOKsY4Ta0MtlEA0jaBziVFWcuplFM6XpZxbwNKM6E3GT7TknPA15u++Ie6pjM4czcGTgJeBlwM8V06gfYvjGZEzOzDXWMqIOk6bbvSGYzM9tQx35lNtEmG23b+AbDo4//atzJJvolDakGkLQe8EFgn7LoEuDztpf0kLkXsJ3tUyVtDmxk+9c91jOZw5m5NrA9xVm328uzbT1JZrMz21DHiIhYc9KQGluukWqGbwBbU1yoeEL5fHbVMEmfAD4CHFcWTQa+2UsFkzm0mQcC69u+BXgr8B3VM7tgMhua2YY6RkTEmrUcN/4xCGlINcP2to+0fVn5OAqY3kPe24AZwCIA2/8D9DpzTDKHM7Mtswsms77MNtQxIiJi4NKQaoZflhdfAyBpN+BnPeQ95WLM5siF3Rv2WL9kDm9mW2YXTGZ9mW2oY0RExMClIdUMuwE/l3SPpHuAK4HXSbpJUpWLsc8qZ2/bWNJ7gEuBr/RYx2QOZ+bITIDvBC5QvbMLJrOZmW2oY0RExMBlsokGkPSilS23fW+FzP2AP6e4sPsi25dUrF4yhzizRbMLJrOmzDbUMSIi1qwpG27T+AbDwkV3Z9a+6F05pGuJ7WWStqeYKetHvcySlczhzOzI3gJYb+S17fuSObEz21DHiIhYM9KQGluGVkxMPwXWlbQlxfCumcBpyUxmtyTNkHQn8GtgTvnvj5I5cTPbUMeIiIgmSENqYpLtxcDbgZNsvw3YIZnJrOAEYHfgDttbA/vS20QoyWx+ZhvqGBERa9Byu/GPQUhDamKSpD2AQ4EflmVrJzOZFTxt+xFgLUlr2b4M2CmZEzqzDXWMiIgYuF4PsqKZ3k9xU9bzbN8iaRvgsmQms4LHJG1EMWzwDEkPA0uTOaEz21DHiIiIgctkExExrnICiycoeq8PBaYCZ5S9C8mcgJltqGNERKxZG24wrfENhkWL78msfdE7SZsDHwZeyjNnyHp9MpPZZebWwEO2l5Sv1weeY/ueZE7MzDbUMSIi1qw0pMaWa6QmpjOA24CtgU8C9wDXJDOZFZwNLO94vawsS+bEzWxDHSMiIgYuDamJaTPbX6O4wHuO7XdTzJiVzGR2a23bT428KJ+vk8wJndmGOkZExBo06Bn5MmtfrEkjN2B9SNKbJL0SeEEyk1nBbyXNGHkh6S3A75I5oTPbUMeIiIiByzVSE5CkvwQuB14InARMAY63/YNkJrPLzG2BbwLPL4seAA6zfVcyJ2ZmG+oYERFr1vrrv6jxDYYnnrg3k01E7ySdDrzf9mPl602BE8uhXslM5upkHU0xjfr95euNKPYXv++hfslscGYb6hgREYOx3npbNb7BsGTJfWlIRe8k/dL2K1dVlsxkriRrAbAIuAv4FnC27Z6GYiWz2ZltqGNERAxGGlJjyzVSE9NakjYZeVH2TPR68+VkDlfm3RTXV50A7ArMk3ShpMMlPSuZEzKzDXWMiIhojF4P3KKZPgf8XNI5gIF3Ap9OZjK7YNvLgYuBiyVNBvYHDgFOBDZP5oTLbEMdIyIiGiND+yYoSTsArwcE/Nj2rclMZhc54w4JlLS+7SeSObEy21DHiIgYjHXXe2HjGwxPLrk/10hFxOBJmm77jmQOT2Yb6hgREYORhtTY0pCKiIiIiIhxpSE1tlwjFRERERER40rHy9gya19ERERERESX0pCKiIiIiIjoUob2RURERETEuDK0b2zpkYqIiIiIiOhSGlIRERERERFdytC+iIiIiIgYVwb2jS09UhEREREREV1KQyoiIiIiIqJLyiwcERERERER3UmPVERERERERJfSkIqIiIiIiOhSGlIRERERERFdSkMqIiIiIiKiS2lIRUREREREdCkNqYiIiIiIiC79f3ehmeshpl4mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_mat = deaths_popcorrected.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204455, 16) (204455, 1) (380111, 9) (380111, 1)\n"
     ]
    }
   ],
   "source": [
    "x= cases_popcorrected[['pov','popden','day1', 'day2', 'day3', 'day4', 'day5', 'day6', 'day7']]\n",
    "y= cases_popcorrected['7day8'].values.reshape(-1, 1)\n",
    "X = deaths_popcorrected[['pov','popden','casesday1', 'casesday2', 'casesday3', 'casesday4', 'casesday5', 'casesday6',\n",
    "                         'casesday7','day1', 'day2', 'day3', 'day4', 'day5', 'day6', 'day7']]\n",
    "Y = deaths_popcorrected['7day8'].values.reshape(-1, 1)\n",
    "print(X.shape, Y.shape, x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204455, 11) (204455, 1) (380111, 21) (380111, 1)\n"
     ]
    }
   ],
   "source": [
    "x= cases_popcorrected[['day1','day2','day3','day4','day5','day6','day7','rad27day1','rad27day2','rad27day3','rad27day4',\n",
    "                       'rad27day5','rad27day6','rad27day7','7day1','7day2','7day3','7day4','7day5','7day6','7day7']]\n",
    "y= cases_popcorrected['7day8'].values.reshape(-1, 1)\n",
    "X = deaths_popcorrected[['popden','day5','day6','day7','7day1','7day2','7day3','7day4','7day5','7day6','7day7']]\n",
    "Y = deaths_popcorrected['7day8'].values.reshape(-1, 1)\n",
    "print(X.shape, Y.shape, x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 33)                396       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 66)                2244      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 67        \n",
      "=================================================================\n",
      "Total params: 24,817\n",
      "Trainable params: 24,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(33, kernel_initializer='normal',activation='relu', input_dim=X_train.shape[1]))\n",
    "# Add a second hidden layer\n",
    "model.add(Dense(66, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(66, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(66, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(66, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(66, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(66, kernel_initializer='normal',activation='relu'))\n",
    "# Y_train = to_categorical(Y_train)\n",
    "# Add output layer\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"Adamax\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3797/3834 [============================>.] - ETA: 0s - loss: 0.2529 - accuracy: 0.8501 ETA: 0sWARNING:tensorflow:From C:\\Users\\Henry Randall\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Henry Randall\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 1ms/step - loss: 0.2515 - accuracy: 0.8501 - val_loss: 0.2087 - val_accuracy: 0.8455\n",
      "Epoch 2/500\n",
      "3820/3834 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.8453INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 935us/step - loss: 0.1863 - accuracy: 0.8454 - val_loss: 0.1895 - val_accuracy: 0.8441\n",
      "Epoch 3/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.1740 - accuracy: 0.8461 - val_loss: 0.2318 - val_accuracy: 0.8497\n",
      "Epoch 4/500\n",
      "3781/3834 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.8464INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 980us/step - loss: 0.1719 - accuracy: 0.8466 - val_loss: 0.1818 - val_accuracy: 0.8475\n",
      "Epoch 5/500\n",
      "3809/3834 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.8473INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 936us/step - loss: 0.1614 - accuracy: 0.8473 - val_loss: 0.1774 - val_accuracy: 0.8490\n",
      "Epoch 6/500\n",
      "3768/3834 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.8468INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 925us/step - loss: 0.1712 - accuracy: 0.8471 - val_loss: 0.1718 - val_accuracy: 0.8446\n",
      "Epoch 7/500\n",
      "3783/3834 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.8467INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 969us/step - loss: 0.1574 - accuracy: 0.8470 - val_loss: 0.1716 - val_accuracy: 0.8485\n",
      "Epoch 8/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.1649 - accuracy: 0.8474 - val_loss: 0.1897 - val_accuracy: 0.8459\n",
      "Epoch 9/500\n",
      "3813/3834 [============================>.] - ETA: 0s - loss: 0.1629 - accuracy: 0.8475INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 918us/step - loss: 0.1624 - accuracy: 0.8475 - val_loss: 0.1611 - val_accuracy: 0.8449\n",
      "Epoch 10/500\n",
      "3752/3834 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.8480INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 969us/step - loss: 0.1505 - accuracy: 0.8479 - val_loss: 0.1591 - val_accuracy: 0.8469\n",
      "Epoch 11/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1536 - accuracy: 0.8477 - val_loss: 0.1645 - val_accuracy: 0.8451\n",
      "Epoch 12/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.1516 - accuracy: 0.8480 - val_loss: 0.1614 - val_accuracy: 0.8467\n",
      "Epoch 13/500\n",
      "3757/3834 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.8481INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 926us/step - loss: 0.1467 - accuracy: 0.8482 - val_loss: 0.1569 - val_accuracy: 0.8458\n",
      "Epoch 14/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.1470 - accuracy: 0.8481 - val_loss: 0.1693 - val_accuracy: 0.8487\n",
      "Epoch 15/500\n",
      "3788/3834 [============================>.] - ETA: 0s - loss: 0.1455 - accuracy: 0.8480INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 974us/step - loss: 0.1447 - accuracy: 0.8482 - val_loss: 0.1536 - val_accuracy: 0.8472\n",
      "Epoch 16/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1413 - accuracy: 0.8480 - val_loss: 0.1620 - val_accuracy: 0.8481\n",
      "Epoch 17/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1406 - accuracy: 0.8483 - val_loss: 0.1648 - val_accuracy: 0.8499\n",
      "Epoch 18/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.1401 - accuracy: 0.8485 - val_loss: 0.1563 - val_accuracy: 0.8490\n",
      "Epoch 19/500\n",
      "3802/3834 [============================>.] - ETA: 0s - loss: 0.1464 - accuracy: 0.8488INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 937us/step - loss: 0.1456 - accuracy: 0.8487 - val_loss: 0.1535 - val_accuracy: 0.8478\n",
      "Epoch 20/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.1388 - accuracy: 0.8484 - val_loss: 0.1580 - val_accuracy: 0.8489\n",
      "Epoch 21/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.1355 - accuracy: 0.8485 - val_loss: 0.1603 - val_accuracy: 0.8431\n",
      "Epoch 22/500\n",
      "3834/3834 [==============================] - 2s 642us/step - loss: 0.1342 - accuracy: 0.8485 - val_loss: 0.1665 - val_accuracy: 0.8488\n",
      "Epoch 23/500\n",
      "3802/3834 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.8486INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 962us/step - loss: 0.1338 - accuracy: 0.8487 - val_loss: 0.1527 - val_accuracy: 0.8468\n",
      "Epoch 24/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.1328 - accuracy: 0.8488 - val_loss: 0.1558 - val_accuracy: 0.8465\n",
      "Epoch 25/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.1306 - accuracy: 0.8489 - val_loss: 0.1598 - val_accuracy: 0.8469\n",
      "Epoch 26/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.1335 - accuracy: 0.8487 - val_loss: 0.1615 - val_accuracy: 0.8476\n",
      "Epoch 27/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.1245 - accuracy: 0.8491 - val_loss: 0.1710 - val_accuracy: 0.8496\n",
      "Epoch 28/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.1288 - accuracy: 0.8491 - val_loss: 0.1729 - val_accuracy: 0.8475\n",
      "Epoch 29/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.1246 - accuracy: 0.8493 - val_loss: 0.1671 - val_accuracy: 0.8483\n",
      "Epoch 30/500\n",
      "3834/3834 [==============================] - 3s 671us/step - loss: 0.1279 - accuracy: 0.8492 - val_loss: 0.1911 - val_accuracy: 0.8496\n",
      "Epoch 31/500\n",
      "3834/3834 [==============================] - 3s 699us/step - loss: 0.1223 - accuracy: 0.8498 - val_loss: 0.1720 - val_accuracy: 0.8438\n",
      "Epoch 32/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.1286 - accuracy: 0.8492 - val_loss: 0.1698 - val_accuracy: 0.8483\n",
      "Epoch 33/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.1228 - accuracy: 0.8494 - val_loss: 0.1630 - val_accuracy: 0.8476\n",
      "Epoch 34/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.1273 - accuracy: 0.8493 - val_loss: 0.1663 - val_accuracy: 0.8468\n",
      "Epoch 35/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1231 - accuracy: 0.8495 - val_loss: 0.1718 - val_accuracy: 0.8486\n",
      "Epoch 36/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1239 - accuracy: 0.8498 - val_loss: 0.1628 - val_accuracy: 0.8490\n",
      "Epoch 37/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.1241 - accuracy: 0.8499 - val_loss: 0.1659 - val_accuracy: 0.8459\n",
      "Epoch 38/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1239 - accuracy: 0.8491 - val_loss: 0.1871 - val_accuracy: 0.8500\n",
      "Epoch 39/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.1241 - accuracy: 0.8493 - val_loss: 0.1853 - val_accuracy: 0.8482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.1250 - accuracy: 0.8495 - val_loss: 0.1724 - val_accuracy: 0.8468\n",
      "Epoch 41/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1227 - accuracy: 0.8498 - val_loss: 0.1812 - val_accuracy: 0.8474\n",
      "Epoch 42/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1242 - accuracy: 0.8495 - val_loss: 0.1783 - val_accuracy: 0.8512\n",
      "Epoch 43/500\n",
      "3834/3834 [==============================] - 3s 689us/step - loss: 0.1263 - accuracy: 0.8499 - val_loss: 0.1636 - val_accuracy: 0.8466\n",
      "Epoch 44/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1218 - accuracy: 0.8496 - val_loss: 0.1712 - val_accuracy: 0.8475\n",
      "Epoch 45/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1233 - accuracy: 0.8497 - val_loss: 0.1858 - val_accuracy: 0.8495\n",
      "Epoch 46/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.1219 - accuracy: 0.8496 - val_loss: 0.1639 - val_accuracy: 0.8470\n",
      "Epoch 47/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1215 - accuracy: 0.8497 - val_loss: 0.1625 - val_accuracy: 0.8470\n",
      "Epoch 48/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1212 - accuracy: 0.8498 - val_loss: 0.1776 - val_accuracy: 0.8496\n",
      "Epoch 49/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.1219 - accuracy: 0.8496 - val_loss: 0.1767 - val_accuracy: 0.8462\n",
      "Epoch 50/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1200 - accuracy: 0.8499 - val_loss: 0.1844 - val_accuracy: 0.8484\n",
      "Epoch 51/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.1200 - accuracy: 0.8496 - val_loss: 0.2066 - val_accuracy: 0.8402\n",
      "Epoch 52/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1206 - accuracy: 0.8502 - val_loss: 0.1718 - val_accuracy: 0.8481\n",
      "Epoch 53/500\n",
      "3834/3834 [==============================] - 3s 674us/step - loss: 0.1195 - accuracy: 0.8499 - val_loss: 0.2155 - val_accuracy: 0.8440\n",
      "Epoch 54/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.1196 - accuracy: 0.8500 - val_loss: 0.1820 - val_accuracy: 0.8486\n",
      "Epoch 55/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.1178 - accuracy: 0.8503 - val_loss: 0.1700 - val_accuracy: 0.8460\n",
      "Epoch 56/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1192 - accuracy: 0.8500 - val_loss: 0.1852 - val_accuracy: 0.8498\n",
      "Epoch 57/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.1191 - accuracy: 0.8497 - val_loss: 0.1706 - val_accuracy: 0.8495\n",
      "Epoch 58/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1203 - accuracy: 0.8499 - val_loss: 0.1743 - val_accuracy: 0.8482\n",
      "Epoch 59/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.1190 - accuracy: 0.8498 - val_loss: 0.1736 - val_accuracy: 0.8474\n",
      "Epoch 60/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1174 - accuracy: 0.8498 - val_loss: 0.1838 - val_accuracy: 0.8474\n",
      "Epoch 61/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1157 - accuracy: 0.8500 - val_loss: 0.1690 - val_accuracy: 0.8484\n",
      "Epoch 62/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.1197 - accuracy: 0.8501 - val_loss: 0.1752 - val_accuracy: 0.8453\n",
      "Epoch 63/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.1135 - accuracy: 0.8502 - val_loss: 0.1723 - val_accuracy: 0.8487\n",
      "Epoch 64/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1131 - accuracy: 0.8501 - val_loss: 0.1743 - val_accuracy: 0.8466\n",
      "Epoch 65/500\n",
      "3834/3834 [==============================] - 3s 696us/step - loss: 0.1168 - accuracy: 0.8501 - val_loss: 0.1674 - val_accuracy: 0.8467\n",
      "Epoch 66/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.1157 - accuracy: 0.8501 - val_loss: 0.1740 - val_accuracy: 0.8487\n",
      "Epoch 67/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.1172 - accuracy: 0.8498 - val_loss: 0.1761 - val_accuracy: 0.8480\n",
      "Epoch 68/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.1141 - accuracy: 0.8502 - val_loss: 0.1909 - val_accuracy: 0.8497\n",
      "Epoch 69/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.1152 - accuracy: 0.8501 - val_loss: 0.1959 - val_accuracy: 0.8432\n",
      "Epoch 70/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.1141 - accuracy: 0.8505 - val_loss: 0.1647 - val_accuracy: 0.8491\n",
      "Epoch 71/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.1163 - accuracy: 0.8502 - val_loss: 0.1586 - val_accuracy: 0.8486\n",
      "Epoch 72/500\n",
      "3834/3834 [==============================] - 3s 669us/step - loss: 0.1142 - accuracy: 0.8501 - val_loss: 0.1802 - val_accuracy: 0.8492\n",
      "Epoch 73/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.1172 - accuracy: 0.8503 - val_loss: 0.1741 - val_accuracy: 0.8492\n",
      "Epoch 74/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.1147 - accuracy: 0.8504 - val_loss: 0.1758 - val_accuracy: 0.8486\n",
      "Epoch 75/500\n",
      "3834/3834 [==============================] - 3s 668us/step - loss: 0.1124 - accuracy: 0.8502 - val_loss: 0.2029 - val_accuracy: 0.8515\n",
      "Epoch 76/500\n",
      "3834/3834 [==============================] - 3s 675us/step - loss: 0.1139 - accuracy: 0.8500 - val_loss: 0.1887 - val_accuracy: 0.8481\n",
      "Epoch 77/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.1142 - accuracy: 0.8501 - val_loss: 0.1655 - val_accuracy: 0.8477\n",
      "Epoch 78/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.1157 - accuracy: 0.8500 - val_loss: 0.1739 - val_accuracy: 0.8464\n",
      "Epoch 79/500\n",
      "3834/3834 [==============================] - 3s 664us/step - loss: 0.1126 - accuracy: 0.8503 - val_loss: 0.1770 - val_accuracy: 0.8480\n",
      "Epoch 80/500\n",
      "3834/3834 [==============================] - 2s 644us/step - loss: 0.1135 - accuracy: 0.8501 - val_loss: 0.1726 - val_accuracy: 0.8480\n",
      "Epoch 81/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.1127 - accuracy: 0.8502 - val_loss: 0.1920 - val_accuracy: 0.8492\n",
      "Epoch 82/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1118 - accuracy: 0.8503 - val_loss: 0.1644 - val_accuracy: 0.8494\n",
      "Epoch 83/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.1118 - accuracy: 0.8500 - val_loss: 0.1742 - val_accuracy: 0.8480\n",
      "Epoch 84/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.1128 - accuracy: 0.8500 - val_loss: 0.1592 - val_accuracy: 0.8483\n",
      "Epoch 85/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1126 - accuracy: 0.8504 - val_loss: 0.1779 - val_accuracy: 0.8486\n",
      "Epoch 86/500\n",
      "3834/3834 [==============================] - 3s 688us/step - loss: 0.1122 - accuracy: 0.8501 - val_loss: 0.1791 - val_accuracy: 0.8498\n",
      "Epoch 87/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.1107 - accuracy: 0.8501 - val_loss: 0.1586 - val_accuracy: 0.8490\n",
      "Epoch 88/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.1097 - accuracy: 0.8504 - val_loss: 0.1698 - val_accuracy: 0.8483\n",
      "Epoch 89/500\n",
      "3834/3834 [==============================] - 2s 643us/step - loss: 0.1118 - accuracy: 0.8504 - val_loss: 0.1645 - val_accuracy: 0.8493\n",
      "Epoch 90/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.1115 - accuracy: 0.8500 - val_loss: 0.1631 - val_accuracy: 0.8484\n",
      "Epoch 91/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1117 - accuracy: 0.8500 - val_loss: 0.1635 - val_accuracy: 0.8505\n",
      "Epoch 92/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1113 - accuracy: 0.8502 - val_loss: 0.1750 - val_accuracy: 0.8489\n",
      "Epoch 93/500\n",
      "3834/3834 [==============================] - 3s 666us/step - loss: 0.1106 - accuracy: 0.8504 - val_loss: 0.1612 - val_accuracy: 0.8484\n",
      "Epoch 94/500\n",
      "3834/3834 [==============================] - 3s 698us/step - loss: 0.1094 - accuracy: 0.8501 - val_loss: 0.1917 - val_accuracy: 0.8498\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 3s 668us/step - loss: 0.1085 - accuracy: 0.8503 - val_loss: 0.2092 - val_accuracy: 0.8515\n",
      "Epoch 96/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.1083 - accuracy: 0.8502 - val_loss: 0.1821 - val_accuracy: 0.8511\n",
      "Epoch 97/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.1111 - accuracy: 0.8505 - val_loss: 0.1562 - val_accuracy: 0.8492\n",
      "Epoch 98/500\n",
      "3834/3834 [==============================] - 3s 665us/step - loss: 0.1081 - accuracy: 0.8503 - val_loss: 0.1599 - val_accuracy: 0.8500\n",
      "Epoch 99/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1100 - accuracy: 0.8503 - val_loss: 0.1847 - val_accuracy: 0.8473\n",
      "Epoch 100/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.1076 - accuracy: 0.8501 - val_loss: 0.1587 - val_accuracy: 0.8480\n",
      "Epoch 101/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1099 - accuracy: 0.8504 - val_loss: 0.1591 - val_accuracy: 0.8481\n",
      "Epoch 102/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1090 - accuracy: 0.8503 - val_loss: 0.1908 - val_accuracy: 0.8491\n",
      "Epoch 103/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1070 - accuracy: 0.8504 - val_loss: 0.2100 - val_accuracy: 0.8482\n",
      "Epoch 104/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.1096 - accuracy: 0.8505 - val_loss: 0.1706 - val_accuracy: 0.8469\n",
      "Epoch 105/500\n",
      "3817/3834 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.8505INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 934us/step - loss: 0.1078 - accuracy: 0.8505 - val_loss: 0.1493 - val_accuracy: 0.8496\n",
      "Epoch 106/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.1078 - accuracy: 0.8506 - val_loss: 0.1771 - val_accuracy: 0.8481\n",
      "Epoch 107/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1069 - accuracy: 0.8504 - val_loss: 0.2132 - val_accuracy: 0.8473\n",
      "Epoch 108/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1119 - accuracy: 0.8500 - val_loss: 0.1685 - val_accuracy: 0.8485\n",
      "Epoch 109/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1057 - accuracy: 0.8505 - val_loss: 0.2113 - val_accuracy: 0.8484\n",
      "Epoch 110/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1090 - accuracy: 0.8501 - val_loss: 0.1953 - val_accuracy: 0.8483\n",
      "Epoch 111/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1079 - accuracy: 0.8501 - val_loss: 0.1710 - val_accuracy: 0.8505\n",
      "Epoch 112/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.1094 - accuracy: 0.8503 - val_loss: 0.1867 - val_accuracy: 0.8495\n",
      "Epoch 113/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.1052 - accuracy: 0.8505 - val_loss: 0.2016 - val_accuracy: 0.8485\n",
      "Epoch 114/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1071 - accuracy: 0.8502 - val_loss: 0.2028 - val_accuracy: 0.8482\n",
      "Epoch 115/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.1041 - accuracy: 0.8505 - val_loss: 0.2111 - val_accuracy: 0.8487\n",
      "Epoch 116/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.1092 - accuracy: 0.8506 - val_loss: 0.1615 - val_accuracy: 0.8508\n",
      "Epoch 117/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.1067 - accuracy: 0.8505 - val_loss: 0.1812 - val_accuracy: 0.8493\n",
      "Epoch 118/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.1043 - accuracy: 0.8506 - val_loss: 0.1810 - val_accuracy: 0.8483\n",
      "Epoch 119/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1075 - accuracy: 0.8507 - val_loss: 0.1510 - val_accuracy: 0.8492\n",
      "Epoch 120/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.1039 - accuracy: 0.8505 - val_loss: 0.1647 - val_accuracy: 0.8500\n",
      "Epoch 121/500\n",
      "3834/3834 [==============================] - 2s 643us/step - loss: 0.1054 - accuracy: 0.8506 - val_loss: 0.1547 - val_accuracy: 0.8486\n",
      "Epoch 122/500\n",
      "3834/3834 [==============================] - 2s 640us/step - loss: 0.1041 - accuracy: 0.8505 - val_loss: 0.1551 - val_accuracy: 0.8494\n",
      "Epoch 123/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.1041 - accuracy: 0.8508 - val_loss: 0.1849 - val_accuracy: 0.8491\n",
      "Epoch 124/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.1052 - accuracy: 0.8505 - val_loss: 0.1574 - val_accuracy: 0.8489\n",
      "Epoch 125/500\n",
      "3790/3834 [============================>.] - ETA: 0s - loss: 0.1026 - accuracy: 0.8505INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 967us/step - loss: 0.1034 - accuracy: 0.8504 - val_loss: 0.1419 - val_accuracy: 0.8487\n",
      "Epoch 126/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.1076 - accuracy: 0.8505 - val_loss: 0.1503 - val_accuracy: 0.8501\n",
      "Epoch 127/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1024 - accuracy: 0.8505 - val_loss: 0.1916 - val_accuracy: 0.8497\n",
      "Epoch 128/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.1015 - accuracy: 0.8504 - val_loss: 0.1536 - val_accuracy: 0.8495\n",
      "Epoch 129/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.1003 - accuracy: 0.8505 - val_loss: 0.2104 - val_accuracy: 0.8497\n",
      "Epoch 130/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.1045 - accuracy: 0.8503 - val_loss: 0.1648 - val_accuracy: 0.8499\n",
      "Epoch 131/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.1004 - accuracy: 0.8504 - val_loss: 0.1694 - val_accuracy: 0.8494\n",
      "Epoch 132/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.1017 - accuracy: 0.8504 - val_loss: 0.1939 - val_accuracy: 0.8496\n",
      "Epoch 133/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.1015 - accuracy: 0.8505 - val_loss: 0.1550 - val_accuracy: 0.8490\n",
      "Epoch 134/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1047 - accuracy: 0.8503 - val_loss: 0.1732 - val_accuracy: 0.8483\n",
      "Epoch 135/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.1018 - accuracy: 0.8502 - val_loss: 0.1437 - val_accuracy: 0.8482\n",
      "Epoch 136/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.1013 - accuracy: 0.8506 - val_loss: 0.1751 - val_accuracy: 0.8495\n",
      "Epoch 137/500\n",
      "3834/3834 [==============================] - 3s 697us/step - loss: 0.1031 - accuracy: 0.8506 - val_loss: 0.1554 - val_accuracy: 0.8486\n",
      "Epoch 138/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.1015 - accuracy: 0.8505 - val_loss: 0.1684 - val_accuracy: 0.8477\n",
      "Epoch 139/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.1019 - accuracy: 0.8504 - val_loss: 0.1600 - val_accuracy: 0.8500\n",
      "Epoch 140/500\n",
      "3834/3834 [==============================] - 3s 692us/step - loss: 0.1004 - accuracy: 0.8507 - val_loss: 0.1445 - val_accuracy: 0.8497\n",
      "Epoch 141/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0996 - accuracy: 0.8506 - val_loss: 0.1470 - val_accuracy: 0.8473\n",
      "Epoch 142/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0994 - accuracy: 0.8507 - val_loss: 0.1478 - val_accuracy: 0.8504\n",
      "Epoch 143/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0985 - accuracy: 0.8508 - val_loss: 0.1736 - val_accuracy: 0.8498\n",
      "Epoch 144/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.1008 - accuracy: 0.8502 - val_loss: 0.1967 - val_accuracy: 0.8484\n",
      "Epoch 145/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0992 - accuracy: 0.8503 - val_loss: 0.1433 - val_accuracy: 0.8491\n",
      "Epoch 146/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0998 - accuracy: 0.8507 - val_loss: 0.2040 - val_accuracy: 0.8419\n",
      "Epoch 147/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.1001 - accuracy: 0.8506 - val_loss: 0.1588 - val_accuracy: 0.8497\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0989 - accuracy: 0.8506 - val_loss: 0.1881 - val_accuracy: 0.8488\n",
      "Epoch 149/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0988 - accuracy: 0.8507 - val_loss: 0.1546 - val_accuracy: 0.8501\n",
      "Epoch 150/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0983 - accuracy: 0.8509 - val_loss: 0.1517 - val_accuracy: 0.8505\n",
      "Epoch 151/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0976 - accuracy: 0.8509 - val_loss: 0.1631 - val_accuracy: 0.8492\n",
      "Epoch 152/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0990 - accuracy: 0.8508 - val_loss: 0.1441 - val_accuracy: 0.8490\n",
      "Epoch 153/500\n",
      "3834/3834 [==============================] - 3s 683us/step - loss: 0.0959 - accuracy: 0.8506 - val_loss: 0.1908 - val_accuracy: 0.8496\n",
      "Epoch 154/500\n",
      "3834/3834 [==============================] - 2s 644us/step - loss: 0.0968 - accuracy: 0.8507 - val_loss: 0.1982 - val_accuracy: 0.8488\n",
      "Epoch 155/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0967 - accuracy: 0.8506 - val_loss: 0.1906 - val_accuracy: 0.8490\n",
      "Epoch 156/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0963 - accuracy: 0.8506 - val_loss: 0.1891 - val_accuracy: 0.8511\n",
      "Epoch 157/500\n",
      "3774/3834 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.8507INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 980us/step - loss: 0.0969 - accuracy: 0.8507 - val_loss: 0.1411 - val_accuracy: 0.8492\n",
      "Epoch 158/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0972 - accuracy: 0.8508 - val_loss: 0.1701 - val_accuracy: 0.8497\n",
      "Epoch 159/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0939 - accuracy: 0.8505 - val_loss: 0.1811 - val_accuracy: 0.8504\n",
      "Epoch 160/500\n",
      "3781/3834 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.8506INFO:tensorflow:Assets written to: models\\model1\\assets\n",
      "3834/3834 [==============================] - 4s 958us/step - loss: 0.0961 - accuracy: 0.8507 - val_loss: 0.1368 - val_accuracy: 0.8492\n",
      "Epoch 161/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0956 - accuracy: 0.8508 - val_loss: 0.2222 - val_accuracy: 0.8505\n",
      "Epoch 162/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0994 - accuracy: 0.8506 - val_loss: 0.1402 - val_accuracy: 0.8488\n",
      "Epoch 163/500\n",
      "3834/3834 [==============================] - 3s 695us/step - loss: 0.0942 - accuracy: 0.8506 - val_loss: 0.1692 - val_accuracy: 0.8485\n",
      "Epoch 164/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0937 - accuracy: 0.8507 - val_loss: 0.1894 - val_accuracy: 0.8487\n",
      "Epoch 165/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0922 - accuracy: 0.8507 - val_loss: 0.1388 - val_accuracy: 0.8479\n",
      "Epoch 166/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0967 - accuracy: 0.8506 - val_loss: 0.1881 - val_accuracy: 0.8497\n",
      "Epoch 167/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0947 - accuracy: 0.8506 - val_loss: 0.1883 - val_accuracy: 0.8511\n",
      "Epoch 168/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0950 - accuracy: 0.8506 - val_loss: 0.1613 - val_accuracy: 0.8500\n",
      "Epoch 169/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0929 - accuracy: 0.8504 - val_loss: 0.1435 - val_accuracy: 0.8490\n",
      "Epoch 170/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0932 - accuracy: 0.8508 - val_loss: 0.1641 - val_accuracy: 0.8476\n",
      "Epoch 171/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0929 - accuracy: 0.8510 - val_loss: 0.1689 - val_accuracy: 0.8505\n",
      "Epoch 172/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0910 - accuracy: 0.8508 - val_loss: 0.1494 - val_accuracy: 0.8494\n",
      "Epoch 173/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0938 - accuracy: 0.8507 - val_loss: 0.1931 - val_accuracy: 0.8494\n",
      "Epoch 174/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0913 - accuracy: 0.8507 - val_loss: 0.1734 - val_accuracy: 0.8502\n",
      "Epoch 175/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0904 - accuracy: 0.8508 - val_loss: 0.2017 - val_accuracy: 0.8496\n",
      "Epoch 176/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0905 - accuracy: 0.8508 - val_loss: 0.1437 - val_accuracy: 0.8490\n",
      "Epoch 177/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0932 - accuracy: 0.8508 - val_loss: 0.1537 - val_accuracy: 0.8485\n",
      "Epoch 178/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0914 - accuracy: 0.8508 - val_loss: 0.1765 - val_accuracy: 0.8491\n",
      "Epoch 179/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0908 - accuracy: 0.8505 - val_loss: 0.1439 - val_accuracy: 0.8478\n",
      "Epoch 180/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0903 - accuracy: 0.8507 - val_loss: 0.1731 - val_accuracy: 0.8494\n",
      "Epoch 181/500\n",
      "3834/3834 [==============================] - 3s 671us/step - loss: 0.0896 - accuracy: 0.8506 - val_loss: 0.1551 - val_accuracy: 0.8499\n",
      "Epoch 182/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0913 - accuracy: 0.8509 - val_loss: 0.1482 - val_accuracy: 0.8503\n",
      "Epoch 183/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0906 - accuracy: 0.8508 - val_loss: 0.1974 - val_accuracy: 0.8495\n",
      "Epoch 184/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0900 - accuracy: 0.8510 - val_loss: 0.1767 - val_accuracy: 0.8478\n",
      "Epoch 185/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0918 - accuracy: 0.8503 - val_loss: 0.1728 - val_accuracy: 0.8520\n",
      "Epoch 186/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0891 - accuracy: 0.8506 - val_loss: 0.1901 - val_accuracy: 0.8493\n",
      "Epoch 187/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0885 - accuracy: 0.8510 - val_loss: 0.1788 - val_accuracy: 0.8478\n",
      "Epoch 188/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0895 - accuracy: 0.8507 - val_loss: 0.1450 - val_accuracy: 0.8472\n",
      "Epoch 189/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0904 - accuracy: 0.8507 - val_loss: 0.1774 - val_accuracy: 0.8491\n",
      "Epoch 190/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0897 - accuracy: 0.8510 - val_loss: 0.1603 - val_accuracy: 0.8487\n",
      "Epoch 191/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0884 - accuracy: 0.8509 - val_loss: 0.1575 - val_accuracy: 0.8484\n",
      "Epoch 192/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0898 - accuracy: 0.8509 - val_loss: 0.1579 - val_accuracy: 0.8483\n",
      "Epoch 193/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0885 - accuracy: 0.8508 - val_loss: 0.1459 - val_accuracy: 0.8497\n",
      "Epoch 194/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0880 - accuracy: 0.8510 - val_loss: 0.1697 - val_accuracy: 0.8490\n",
      "Epoch 195/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0870 - accuracy: 0.8508 - val_loss: 0.2003 - val_accuracy: 0.8505\n",
      "Epoch 196/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0878 - accuracy: 0.8510 - val_loss: 0.1466 - val_accuracy: 0.8495\n",
      "Epoch 197/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0872 - accuracy: 0.8507 - val_loss: 0.1528 - val_accuracy: 0.8500\n",
      "Epoch 198/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0886 - accuracy: 0.8510 - val_loss: 0.1747 - val_accuracy: 0.8497\n",
      "Epoch 199/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0887 - accuracy: 0.8508 - val_loss: 0.1709 - val_accuracy: 0.8499\n",
      "Epoch 200/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0851 - accuracy: 0.8509 - val_loss: 0.1566 - val_accuracy: 0.8452\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0878 - accuracy: 0.8512 - val_loss: 0.1524 - val_accuracy: 0.8488\n",
      "Epoch 202/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0877 - accuracy: 0.8508 - val_loss: 0.1566 - val_accuracy: 0.8481\n",
      "Epoch 203/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0872 - accuracy: 0.8508 - val_loss: 0.1604 - val_accuracy: 0.8487\n",
      "Epoch 204/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0873 - accuracy: 0.8507 - val_loss: 0.1658 - val_accuracy: 0.8489\n",
      "Epoch 205/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0884 - accuracy: 0.8508 - val_loss: 0.1623 - val_accuracy: 0.8482\n",
      "Epoch 206/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0851 - accuracy: 0.8509 - val_loss: 0.1446 - val_accuracy: 0.8487\n",
      "Epoch 207/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0868 - accuracy: 0.8509 - val_loss: 0.1696 - val_accuracy: 0.8496\n",
      "Epoch 208/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0874 - accuracy: 0.8509 - val_loss: 0.1755 - val_accuracy: 0.8477\n",
      "Epoch 209/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0856 - accuracy: 0.8508 - val_loss: 0.1760 - val_accuracy: 0.8497\n",
      "Epoch 210/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0849 - accuracy: 0.8509 - val_loss: 0.1678 - val_accuracy: 0.8445\n",
      "Epoch 211/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0850 - accuracy: 0.8508 - val_loss: 0.2226 - val_accuracy: 0.8507\n",
      "Epoch 212/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0858 - accuracy: 0.8509 - val_loss: 0.1862 - val_accuracy: 0.8482\n",
      "Epoch 213/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0856 - accuracy: 0.8511 - val_loss: 0.2013 - val_accuracy: 0.8502\n",
      "Epoch 214/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0846 - accuracy: 0.8508 - val_loss: 0.2607 - val_accuracy: 0.8427\n",
      "Epoch 215/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0856 - accuracy: 0.8509 - val_loss: 0.1650 - val_accuracy: 0.8485\n",
      "Epoch 216/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0841 - accuracy: 0.8508 - val_loss: 0.1825 - val_accuracy: 0.8485\n",
      "Epoch 217/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0854 - accuracy: 0.8510 - val_loss: 0.1934 - val_accuracy: 0.8471\n",
      "Epoch 218/500\n",
      "3834/3834 [==============================] - 3s 672us/step - loss: 0.0832 - accuracy: 0.8509 - val_loss: 0.1808 - val_accuracy: 0.8502\n",
      "Epoch 219/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0848 - accuracy: 0.8508 - val_loss: 0.1759 - val_accuracy: 0.8477\n",
      "Epoch 220/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0841 - accuracy: 0.8511 - val_loss: 0.1545 - val_accuracy: 0.8490\n",
      "Epoch 221/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0835 - accuracy: 0.8507 - val_loss: 0.1822 - val_accuracy: 0.8501\n",
      "Epoch 222/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0858 - accuracy: 0.8510 - val_loss: 0.1677 - val_accuracy: 0.8493\n",
      "Epoch 223/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0834 - accuracy: 0.8511 - val_loss: 0.1912 - val_accuracy: 0.8493\n",
      "Epoch 224/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0830 - accuracy: 0.8509 - val_loss: 0.1449 - val_accuracy: 0.8488\n",
      "Epoch 225/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0848 - accuracy: 0.8510 - val_loss: 0.1612 - val_accuracy: 0.8491\n",
      "Epoch 226/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0850 - accuracy: 0.8509 - val_loss: 0.1542 - val_accuracy: 0.8490\n",
      "Epoch 227/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0829 - accuracy: 0.8511 - val_loss: 0.1648 - val_accuracy: 0.8483\n",
      "Epoch 228/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0826 - accuracy: 0.8509 - val_loss: 0.1962 - val_accuracy: 0.8491\n",
      "Epoch 229/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0832 - accuracy: 0.8508 - val_loss: 0.1609 - val_accuracy: 0.8493\n",
      "Epoch 230/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0819 - accuracy: 0.8509 - val_loss: 0.1696 - val_accuracy: 0.8498\n",
      "Epoch 231/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0819 - accuracy: 0.8511 - val_loss: 0.1689 - val_accuracy: 0.8491\n",
      "Epoch 232/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0827 - accuracy: 0.8509 - val_loss: 0.1605 - val_accuracy: 0.8482\n",
      "Epoch 233/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0812 - accuracy: 0.8509 - val_loss: 0.1514 - val_accuracy: 0.8495\n",
      "Epoch 234/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0824 - accuracy: 0.8511 - val_loss: 0.2064 - val_accuracy: 0.8478\n",
      "Epoch 235/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0814 - accuracy: 0.8512 - val_loss: 0.1713 - val_accuracy: 0.8476\n",
      "Epoch 236/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0830 - accuracy: 0.8513 - val_loss: 0.1937 - val_accuracy: 0.8485\n",
      "Epoch 237/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0823 - accuracy: 0.8508 - val_loss: 0.2042 - val_accuracy: 0.8490\n",
      "Epoch 238/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0797 - accuracy: 0.8511 - val_loss: 0.1813 - val_accuracy: 0.8485\n",
      "Epoch 239/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0831 - accuracy: 0.8511 - val_loss: 0.1825 - val_accuracy: 0.8485\n",
      "Epoch 240/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0810 - accuracy: 0.8511 - val_loss: 0.1818 - val_accuracy: 0.8492\n",
      "Epoch 241/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0812 - accuracy: 0.8512 - val_loss: 0.2003 - val_accuracy: 0.8492\n",
      "Epoch 242/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0802 - accuracy: 0.8512 - val_loss: 0.1847 - val_accuracy: 0.8435\n",
      "Epoch 243/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0810 - accuracy: 0.8508 - val_loss: 0.1628 - val_accuracy: 0.8475\n",
      "Epoch 244/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0789 - accuracy: 0.8509 - val_loss: 0.2077 - val_accuracy: 0.8497\n",
      "Epoch 245/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0810 - accuracy: 0.8510 - val_loss: 0.1713 - val_accuracy: 0.8485\n",
      "Epoch 246/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0807 - accuracy: 0.8512 - val_loss: 0.1546 - val_accuracy: 0.8497\n",
      "Epoch 247/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0792 - accuracy: 0.8510 - val_loss: 0.1660 - val_accuracy: 0.8481\n",
      "Epoch 248/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0786 - accuracy: 0.8511 - val_loss: 0.1595 - val_accuracy: 0.8464\n",
      "Epoch 249/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0787 - accuracy: 0.8510 - val_loss: 0.1787 - val_accuracy: 0.8491\n",
      "Epoch 250/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0785 - accuracy: 0.8512 - val_loss: 0.1520 - val_accuracy: 0.8493\n",
      "Epoch 251/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0799 - accuracy: 0.8510 - val_loss: 0.1934 - val_accuracy: 0.8499\n",
      "Epoch 252/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0785 - accuracy: 0.8513 - val_loss: 0.1793 - val_accuracy: 0.8495\n",
      "Epoch 253/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0790 - accuracy: 0.8511 - val_loss: 0.1619 - val_accuracy: 0.8490\n",
      "Epoch 254/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0807 - accuracy: 0.8511 - val_loss: 0.1620 - val_accuracy: 0.8483\n",
      "Epoch 255/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0780 - accuracy: 0.8513 - val_loss: 0.2014 - val_accuracy: 0.8507\n",
      "Epoch 256/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0792 - accuracy: 0.8509 - val_loss: 0.2186 - val_accuracy: 0.8497\n",
      "Epoch 257/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0773 - accuracy: 0.8511 - val_loss: 0.1801 - val_accuracy: 0.8489\n",
      "Epoch 258/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0806 - accuracy: 0.8509 - val_loss: 0.1603 - val_accuracy: 0.8498\n",
      "Epoch 259/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0795 - accuracy: 0.8515 - val_loss: 0.1619 - val_accuracy: 0.8494\n",
      "Epoch 260/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0773 - accuracy: 0.8514 - val_loss: 0.1797 - val_accuracy: 0.8501\n",
      "Epoch 261/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0790 - accuracy: 0.8513 - val_loss: 0.1648 - val_accuracy: 0.8469\n",
      "Epoch 262/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0790 - accuracy: 0.8510 - val_loss: 0.1604 - val_accuracy: 0.8490\n",
      "Epoch 263/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0790 - accuracy: 0.8513 - val_loss: 0.1751 - val_accuracy: 0.8508\n",
      "Epoch 264/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0770 - accuracy: 0.8515 - val_loss: 0.1651 - val_accuracy: 0.8484\n",
      "Epoch 265/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0783 - accuracy: 0.8515 - val_loss: 0.1806 - val_accuracy: 0.8502\n",
      "Epoch 266/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0797 - accuracy: 0.8516 - val_loss: 0.1654 - val_accuracy: 0.8482\n",
      "Epoch 267/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0768 - accuracy: 0.8513 - val_loss: 0.1661 - val_accuracy: 0.8495\n",
      "Epoch 268/500\n",
      "3834/3834 [==============================] - 3s 688us/step - loss: 0.0758 - accuracy: 0.8516 - val_loss: 0.1763 - val_accuracy: 0.8502\n",
      "Epoch 269/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0771 - accuracy: 0.8513 - val_loss: 0.1536 - val_accuracy: 0.8498\n",
      "Epoch 270/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0796 - accuracy: 0.8514 - val_loss: 0.1958 - val_accuracy: 0.8506\n",
      "Epoch 271/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0774 - accuracy: 0.8514 - val_loss: 0.1538 - val_accuracy: 0.8495\n",
      "Epoch 272/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0762 - accuracy: 0.8514 - val_loss: 0.1924 - val_accuracy: 0.8470\n",
      "Epoch 273/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0760 - accuracy: 0.8516 - val_loss: 0.1937 - val_accuracy: 0.8489\n",
      "Epoch 274/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0776 - accuracy: 0.8513 - val_loss: 0.1625 - val_accuracy: 0.8492\n",
      "Epoch 275/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0753 - accuracy: 0.8518 - val_loss: 0.1741 - val_accuracy: 0.8494\n",
      "Epoch 276/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0775 - accuracy: 0.8515 - val_loss: 0.1603 - val_accuracy: 0.8483\n",
      "Epoch 277/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0759 - accuracy: 0.8516 - val_loss: 0.1698 - val_accuracy: 0.8501\n",
      "Epoch 278/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0784 - accuracy: 0.8513 - val_loss: 0.1571 - val_accuracy: 0.8480\n",
      "Epoch 279/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0766 - accuracy: 0.8513 - val_loss: 0.1703 - val_accuracy: 0.8487\n",
      "Epoch 280/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0737 - accuracy: 0.8515 - val_loss: 0.1712 - val_accuracy: 0.8495\n",
      "Epoch 281/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0790 - accuracy: 0.8515 - val_loss: 0.1921 - val_accuracy: 0.8500\n",
      "Epoch 282/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0750 - accuracy: 0.8518 - val_loss: 0.1937 - val_accuracy: 0.8482\n",
      "Epoch 283/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0773 - accuracy: 0.8516 - val_loss: 0.1652 - val_accuracy: 0.8494\n",
      "Epoch 284/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0762 - accuracy: 0.8517 - val_loss: 0.1721 - val_accuracy: 0.8470\n",
      "Epoch 285/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0735 - accuracy: 0.8516 - val_loss: 0.1732 - val_accuracy: 0.8503\n",
      "Epoch 286/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0772 - accuracy: 0.8516 - val_loss: 0.2037 - val_accuracy: 0.8494\n",
      "Epoch 287/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0754 - accuracy: 0.8515 - val_loss: 0.1669 - val_accuracy: 0.8485\n",
      "Epoch 288/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0747 - accuracy: 0.8516 - val_loss: 0.1642 - val_accuracy: 0.8494\n",
      "Epoch 289/500\n",
      "3834/3834 [==============================] - 3s 692us/step - loss: 0.0750 - accuracy: 0.8516 - val_loss: 0.1887 - val_accuracy: 0.8486\n",
      "Epoch 290/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0763 - accuracy: 0.8515 - val_loss: 0.1682 - val_accuracy: 0.8492\n",
      "Epoch 291/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0746 - accuracy: 0.8514 - val_loss: 0.1697 - val_accuracy: 0.8493\n",
      "Epoch 292/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0753 - accuracy: 0.8517 - val_loss: 0.1622 - val_accuracy: 0.8496\n",
      "Epoch 293/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0732 - accuracy: 0.8519 - val_loss: 0.1731 - val_accuracy: 0.8502\n",
      "Epoch 294/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0750 - accuracy: 0.8519 - val_loss: 0.1729 - val_accuracy: 0.8499\n",
      "Epoch 295/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0742 - accuracy: 0.8518 - val_loss: 0.1741 - val_accuracy: 0.8458\n",
      "Epoch 296/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0745 - accuracy: 0.8520 - val_loss: 0.1588 - val_accuracy: 0.8497\n",
      "Epoch 297/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0737 - accuracy: 0.8519 - val_loss: 0.1705 - val_accuracy: 0.8479\n",
      "Epoch 298/500\n",
      "3834/3834 [==============================] - 3s 670us/step - loss: 0.0771 - accuracy: 0.8518 - val_loss: 0.1816 - val_accuracy: 0.8485\n",
      "Epoch 299/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0735 - accuracy: 0.8519 - val_loss: 0.1713 - val_accuracy: 0.8490\n",
      "Epoch 300/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0732 - accuracy: 0.8518 - val_loss: 0.1755 - val_accuracy: 0.8496\n",
      "Epoch 301/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0732 - accuracy: 0.8517 - val_loss: 0.1759 - val_accuracy: 0.8501\n",
      "Epoch 302/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.0739 - accuracy: 0.8519 - val_loss: 0.1654 - val_accuracy: 0.8513\n",
      "Epoch 303/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0730 - accuracy: 0.8518 - val_loss: 0.1579 - val_accuracy: 0.8507\n",
      "Epoch 304/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0731 - accuracy: 0.8520 - val_loss: 0.1589 - val_accuracy: 0.8488\n",
      "Epoch 305/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0743 - accuracy: 0.8520 - val_loss: 0.1849 - val_accuracy: 0.8504\n",
      "Epoch 306/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0726 - accuracy: 0.8518 - val_loss: 0.1614 - val_accuracy: 0.8500\n",
      "Epoch 307/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0730 - accuracy: 0.8518 - val_loss: 0.1659 - val_accuracy: 0.8488\n",
      "Epoch 308/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0737 - accuracy: 0.8519 - val_loss: 0.1649 - val_accuracy: 0.8500\n",
      "Epoch 309/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0754 - accuracy: 0.8519 - val_loss: 0.1964 - val_accuracy: 0.8499\n",
      "Epoch 310/500\n",
      "3834/3834 [==============================] - 3s 675us/step - loss: 0.0713 - accuracy: 0.8518 - val_loss: 0.2365 - val_accuracy: 0.8498\n",
      "Epoch 311/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0732 - accuracy: 0.8520 - val_loss: 0.1778 - val_accuracy: 0.8510\n",
      "Epoch 312/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0733 - accuracy: 0.8522 - val_loss: 0.1958 - val_accuracy: 0.8498\n",
      "Epoch 313/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0732 - accuracy: 0.8519 - val_loss: 0.1961 - val_accuracy: 0.8505\n",
      "Epoch 314/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0717 - accuracy: 0.8521 - val_loss: 0.1686 - val_accuracy: 0.8504\n",
      "Epoch 315/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0728 - accuracy: 0.8523 - val_loss: 0.1680 - val_accuracy: 0.8498\n",
      "Epoch 316/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0710 - accuracy: 0.8521 - val_loss: 0.1780 - val_accuracy: 0.8491\n",
      "Epoch 317/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0735 - accuracy: 0.8523 - val_loss: 0.2097 - val_accuracy: 0.8508\n",
      "Epoch 318/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0727 - accuracy: 0.8520 - val_loss: 0.1891 - val_accuracy: 0.8502\n",
      "Epoch 319/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0720 - accuracy: 0.8521 - val_loss: 0.1882 - val_accuracy: 0.8499\n",
      "Epoch 320/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0718 - accuracy: 0.8521 - val_loss: 0.1848 - val_accuracy: 0.8504\n",
      "Epoch 321/500\n",
      "3834/3834 [==============================] - 2s 644us/step - loss: 0.0703 - accuracy: 0.8518 - val_loss: 0.1917 - val_accuracy: 0.8507\n",
      "Epoch 322/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0716 - accuracy: 0.8519 - val_loss: 0.1888 - val_accuracy: 0.8489\n",
      "Epoch 323/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0724 - accuracy: 0.8518 - val_loss: 0.1682 - val_accuracy: 0.8504\n",
      "Epoch 324/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0699 - accuracy: 0.8521 - val_loss: 0.1760 - val_accuracy: 0.8495\n",
      "Epoch 325/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0720 - accuracy: 0.8521 - val_loss: 0.2110 - val_accuracy: 0.8484\n",
      "Epoch 326/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0723 - accuracy: 0.8521 - val_loss: 0.2073 - val_accuracy: 0.8502\n",
      "Epoch 327/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0718 - accuracy: 0.8519 - val_loss: 0.2265 - val_accuracy: 0.8500\n",
      "Epoch 328/500\n",
      "3834/3834 [==============================] - 3s 692us/step - loss: 0.0727 - accuracy: 0.8520 - val_loss: 0.2084 - val_accuracy: 0.8502\n",
      "Epoch 329/500\n",
      "3834/3834 [==============================] - 3s 694us/step - loss: 0.0709 - accuracy: 0.8520 - val_loss: 0.1754 - val_accuracy: 0.8501\n",
      "Epoch 330/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0711 - accuracy: 0.8521 - val_loss: 0.1931 - val_accuracy: 0.8469\n",
      "Epoch 331/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0697 - accuracy: 0.8522 - val_loss: 0.2258 - val_accuracy: 0.8425\n",
      "Epoch 332/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0740 - accuracy: 0.8521 - val_loss: 0.1767 - val_accuracy: 0.8491\n",
      "Epoch 333/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0711 - accuracy: 0.8520 - val_loss: 0.1915 - val_accuracy: 0.8505\n",
      "Epoch 334/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0714 - accuracy: 0.8521 - val_loss: 0.1834 - val_accuracy: 0.8501\n",
      "Epoch 335/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0702 - accuracy: 0.8524 - val_loss: 0.2065 - val_accuracy: 0.8499\n",
      "Epoch 336/500\n",
      "3834/3834 [==============================] - 2s 644us/step - loss: 0.0698 - accuracy: 0.8519 - val_loss: 0.1819 - val_accuracy: 0.8501\n",
      "Epoch 337/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0720 - accuracy: 0.8522 - val_loss: 0.1673 - val_accuracy: 0.8496\n",
      "Epoch 338/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0701 - accuracy: 0.8518 - val_loss: 0.1784 - val_accuracy: 0.8514\n",
      "Epoch 339/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0709 - accuracy: 0.8522 - val_loss: 0.2013 - val_accuracy: 0.8487\n",
      "Epoch 340/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0694 - accuracy: 0.8523 - val_loss: 0.2312 - val_accuracy: 0.8498\n",
      "Epoch 341/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0732 - accuracy: 0.8523 - val_loss: 0.2111 - val_accuracy: 0.8495\n",
      "Epoch 342/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0701 - accuracy: 0.8517 - val_loss: 0.1843 - val_accuracy: 0.8496\n",
      "Epoch 343/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0722 - accuracy: 0.8521 - val_loss: 0.1853 - val_accuracy: 0.8491\n",
      "Epoch 344/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0689 - accuracy: 0.8523 - val_loss: 0.1840 - val_accuracy: 0.8491\n",
      "Epoch 345/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0703 - accuracy: 0.8520 - val_loss: 0.2067 - val_accuracy: 0.8496\n",
      "Epoch 346/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0701 - accuracy: 0.8519 - val_loss: 0.1812 - val_accuracy: 0.8496\n",
      "Epoch 347/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0699 - accuracy: 0.8519 - val_loss: 0.1902 - val_accuracy: 0.8504\n",
      "Epoch 348/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0688 - accuracy: 0.8519 - val_loss: 0.1921 - val_accuracy: 0.8502\n",
      "Epoch 349/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0723 - accuracy: 0.8523 - val_loss: 0.1855 - val_accuracy: 0.8502\n",
      "Epoch 350/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0706 - accuracy: 0.8516 - val_loss: 0.1890 - val_accuracy: 0.8498\n",
      "Epoch 351/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0688 - accuracy: 0.8519 - val_loss: 0.1916 - val_accuracy: 0.8502\n",
      "Epoch 352/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0688 - accuracy: 0.8521 - val_loss: 0.1766 - val_accuracy: 0.8505\n",
      "Epoch 353/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0696 - accuracy: 0.8518 - val_loss: 0.1918 - val_accuracy: 0.8505\n",
      "Epoch 354/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0692 - accuracy: 0.8520 - val_loss: 0.2188 - val_accuracy: 0.8494\n",
      "Epoch 355/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0710 - accuracy: 0.8519 - val_loss: 0.2398 - val_accuracy: 0.8488\n",
      "Epoch 356/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0691 - accuracy: 0.8520 - val_loss: 0.1743 - val_accuracy: 0.8499\n",
      "Epoch 357/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0685 - accuracy: 0.8520 - val_loss: 0.1930 - val_accuracy: 0.8488\n",
      "Epoch 358/500\n",
      "3834/3834 [==============================] - 3s 686us/step - loss: 0.0681 - accuracy: 0.8521 - val_loss: 0.1829 - val_accuracy: 0.8510\n",
      "Epoch 359/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0681 - accuracy: 0.8522 - val_loss: 0.1937 - val_accuracy: 0.8502\n",
      "Epoch 360/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0689 - accuracy: 0.8516 - val_loss: 0.1870 - val_accuracy: 0.8503\n",
      "Epoch 361/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0694 - accuracy: 0.8519 - val_loss: 0.2011 - val_accuracy: 0.8492\n",
      "Epoch 362/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0687 - accuracy: 0.8518 - val_loss: 0.1887 - val_accuracy: 0.8495\n",
      "Epoch 363/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0709 - accuracy: 0.8518 - val_loss: 0.1727 - val_accuracy: 0.8495\n",
      "Epoch 364/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0690 - accuracy: 0.8524 - val_loss: 0.1770 - val_accuracy: 0.8498\n",
      "Epoch 365/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0686 - accuracy: 0.8523 - val_loss: 0.1842 - val_accuracy: 0.8506\n",
      "Epoch 366/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0696 - accuracy: 0.8520 - val_loss: 0.1966 - val_accuracy: 0.8503\n",
      "Epoch 367/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0675 - accuracy: 0.8522 - val_loss: 0.1918 - val_accuracy: 0.8493\n",
      "Epoch 368/500\n",
      "3834/3834 [==============================] - 2s 641us/step - loss: 0.0696 - accuracy: 0.8517 - val_loss: 0.1984 - val_accuracy: 0.8486\n",
      "Epoch 369/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0683 - accuracy: 0.8521 - val_loss: 0.2131 - val_accuracy: 0.8490\n",
      "Epoch 370/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0677 - accuracy: 0.8518 - val_loss: 0.1752 - val_accuracy: 0.8491\n",
      "Epoch 371/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0714 - accuracy: 0.8524 - val_loss: 0.1902 - val_accuracy: 0.8504\n",
      "Epoch 372/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0683 - accuracy: 0.8523 - val_loss: 0.2113 - val_accuracy: 0.8488\n",
      "Epoch 373/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0688 - accuracy: 0.8522 - val_loss: 0.1752 - val_accuracy: 0.8510\n",
      "Epoch 374/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0693 - accuracy: 0.8518 - val_loss: 0.1870 - val_accuracy: 0.8499\n",
      "Epoch 375/500\n",
      "3834/3834 [==============================] - 3s 691us/step - loss: 0.0689 - accuracy: 0.8521 - val_loss: 0.1916 - val_accuracy: 0.8495\n",
      "Epoch 376/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0668 - accuracy: 0.8520 - val_loss: 0.1733 - val_accuracy: 0.8512\n",
      "Epoch 377/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0673 - accuracy: 0.8520 - val_loss: 0.1779 - val_accuracy: 0.8488\n",
      "Epoch 378/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0687 - accuracy: 0.8521 - val_loss: 0.1812 - val_accuracy: 0.8489\n",
      "Epoch 379/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0681 - accuracy: 0.8522 - val_loss: 0.2037 - val_accuracy: 0.8499\n",
      "Epoch 380/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0661 - accuracy: 0.8520 - val_loss: 0.1903 - val_accuracy: 0.8497\n",
      "Epoch 381/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0695 - accuracy: 0.8524 - val_loss: 0.1991 - val_accuracy: 0.8485\n",
      "Epoch 382/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0672 - accuracy: 0.8521 - val_loss: 0.1827 - val_accuracy: 0.8502\n",
      "Epoch 383/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0692 - accuracy: 0.8524 - val_loss: 0.1959 - val_accuracy: 0.8498\n",
      "Epoch 384/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0680 - accuracy: 0.8523 - val_loss: 0.1794 - val_accuracy: 0.8513\n",
      "Epoch 385/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0671 - accuracy: 0.8521 - val_loss: 0.1942 - val_accuracy: 0.8493\n",
      "Epoch 386/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0679 - accuracy: 0.8520 - val_loss: 0.1844 - val_accuracy: 0.8483\n",
      "Epoch 387/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0672 - accuracy: 0.8522 - val_loss: 0.1818 - val_accuracy: 0.8463\n",
      "Epoch 388/500\n",
      "3834/3834 [==============================] - 3s 697us/step - loss: 0.0658 - accuracy: 0.8522 - val_loss: 0.1802 - val_accuracy: 0.8505\n",
      "Epoch 389/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0688 - accuracy: 0.8519 - val_loss: 0.1802 - val_accuracy: 0.8504\n",
      "Epoch 390/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0672 - accuracy: 0.8519 - val_loss: 0.1929 - val_accuracy: 0.8502\n",
      "Epoch 391/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0656 - accuracy: 0.8523 - val_loss: 0.2030 - val_accuracy: 0.8489\n",
      "Epoch 392/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0665 - accuracy: 0.8522 - val_loss: 0.1916 - val_accuracy: 0.8505\n",
      "Epoch 393/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0680 - accuracy: 0.8519 - val_loss: 0.1850 - val_accuracy: 0.8478\n",
      "Epoch 394/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0651 - accuracy: 0.8523 - val_loss: 0.1780 - val_accuracy: 0.8504\n",
      "Epoch 395/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0659 - accuracy: 0.8521 - val_loss: 0.1968 - val_accuracy: 0.8497\n",
      "Epoch 396/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0663 - accuracy: 0.8522 - val_loss: 0.1736 - val_accuracy: 0.8490\n",
      "Epoch 397/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0685 - accuracy: 0.8521 - val_loss: 0.1926 - val_accuracy: 0.8474\n",
      "Epoch 398/500\n",
      "3834/3834 [==============================] - 2s 652us/step - loss: 0.0669 - accuracy: 0.8523 - val_loss: 0.1873 - val_accuracy: 0.8498\n",
      "Epoch 399/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0667 - accuracy: 0.8523 - val_loss: 0.1933 - val_accuracy: 0.8504\n",
      "Epoch 400/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0668 - accuracy: 0.8525 - val_loss: 0.1761 - val_accuracy: 0.8494\n",
      "Epoch 401/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0641 - accuracy: 0.8524 - val_loss: 0.1810 - val_accuracy: 0.8502\n",
      "Epoch 402/500\n",
      "3834/3834 [==============================] - 3s 690us/step - loss: 0.0673 - accuracy: 0.8526 - val_loss: 0.1868 - val_accuracy: 0.8506\n",
      "Epoch 403/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0648 - accuracy: 0.8525 - val_loss: 0.1808 - val_accuracy: 0.8501\n",
      "Epoch 404/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0655 - accuracy: 0.8523 - val_loss: 0.1944 - val_accuracy: 0.8488\n",
      "Epoch 405/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0656 - accuracy: 0.8521 - val_loss: 0.1766 - val_accuracy: 0.8497\n",
      "Epoch 406/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0655 - accuracy: 0.8523 - val_loss: 0.1765 - val_accuracy: 0.8501\n",
      "Epoch 407/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0638 - accuracy: 0.8529 - val_loss: 0.1742 - val_accuracy: 0.8491\n",
      "Epoch 408/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0667 - accuracy: 0.8522 - val_loss: 0.1869 - val_accuracy: 0.8495\n",
      "Epoch 409/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0660 - accuracy: 0.8527 - val_loss: 0.1762 - val_accuracy: 0.8492\n",
      "Epoch 410/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0648 - accuracy: 0.8524 - val_loss: 0.1633 - val_accuracy: 0.8500\n",
      "Epoch 411/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0656 - accuracy: 0.8521 - val_loss: 0.1958 - val_accuracy: 0.8485\n",
      "Epoch 412/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0649 - accuracy: 0.8524 - val_loss: 0.1800 - val_accuracy: 0.8504\n",
      "Epoch 413/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0681 - accuracy: 0.8522 - val_loss: 0.1932 - val_accuracy: 0.8475\n",
      "Epoch 414/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0669 - accuracy: 0.8521 - val_loss: 0.1866 - val_accuracy: 0.8495\n",
      "Epoch 415/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0651 - accuracy: 0.8522 - val_loss: 0.1856 - val_accuracy: 0.8502\n",
      "Epoch 416/500\n",
      "3834/3834 [==============================] - 3s 695us/step - loss: 0.0651 - accuracy: 0.8523 - val_loss: 0.2058 - val_accuracy: 0.8474\n",
      "Epoch 417/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0646 - accuracy: 0.8523 - val_loss: 0.2014 - val_accuracy: 0.8483\n",
      "Epoch 418/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0661 - accuracy: 0.8524 - val_loss: 0.1811 - val_accuracy: 0.8508\n",
      "Epoch 419/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0643 - accuracy: 0.8526 - val_loss: 0.1859 - val_accuracy: 0.8480\n",
      "Epoch 420/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0665 - accuracy: 0.8523 - val_loss: 0.1827 - val_accuracy: 0.8501\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0651 - accuracy: 0.8521 - val_loss: 0.1868 - val_accuracy: 0.8498\n",
      "Epoch 422/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0628 - accuracy: 0.8525 - val_loss: 0.2261 - val_accuracy: 0.8460\n",
      "Epoch 423/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0647 - accuracy: 0.8525 - val_loss: 0.2253 - val_accuracy: 0.8499\n",
      "Epoch 424/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0662 - accuracy: 0.8523 - val_loss: 0.1898 - val_accuracy: 0.8499\n",
      "Epoch 425/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0636 - accuracy: 0.8523 - val_loss: 0.1967 - val_accuracy: 0.8508\n",
      "Epoch 426/500\n",
      "3834/3834 [==============================] - 2s 639us/step - loss: 0.0657 - accuracy: 0.8523 - val_loss: 0.1974 - val_accuracy: 0.8496\n",
      "Epoch 427/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0649 - accuracy: 0.8524 - val_loss: 0.1939 - val_accuracy: 0.8472\n",
      "Epoch 428/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0658 - accuracy: 0.8524 - val_loss: 0.1924 - val_accuracy: 0.8501\n",
      "Epoch 429/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0653 - accuracy: 0.8523 - val_loss: 0.1922 - val_accuracy: 0.8502\n",
      "Epoch 430/500\n",
      "3834/3834 [==============================] - 3s 668us/step - loss: 0.0656 - accuracy: 0.8524 - val_loss: 0.1797 - val_accuracy: 0.8494\n",
      "Epoch 431/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0630 - accuracy: 0.8525 - val_loss: 0.2257 - val_accuracy: 0.8503\n",
      "Epoch 432/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0645 - accuracy: 0.8523 - val_loss: 0.1857 - val_accuracy: 0.8511\n",
      "Epoch 433/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.0640 - accuracy: 0.8522 - val_loss: 0.2156 - val_accuracy: 0.8495\n",
      "Epoch 434/500\n",
      "3834/3834 [==============================] - 2s 642us/step - loss: 0.0646 - accuracy: 0.8526 - val_loss: 0.1965 - val_accuracy: 0.8473\n",
      "Epoch 435/500\n",
      "3834/3834 [==============================] - 2s 641us/step - loss: 0.0639 - accuracy: 0.8528 - val_loss: 0.2248 - val_accuracy: 0.8503\n",
      "Epoch 436/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0654 - accuracy: 0.8523 - val_loss: 0.2043 - val_accuracy: 0.8505\n",
      "Epoch 437/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.0633 - accuracy: 0.8527 - val_loss: 0.1917 - val_accuracy: 0.8501\n",
      "Epoch 438/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0652 - accuracy: 0.8525 - val_loss: 0.1880 - val_accuracy: 0.8482\n",
      "Epoch 439/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0646 - accuracy: 0.8527 - val_loss: 0.2049 - val_accuracy: 0.8503\n",
      "Epoch 440/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0610 - accuracy: 0.8526 - val_loss: 0.2101 - val_accuracy: 0.8509\n",
      "Epoch 441/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0656 - accuracy: 0.8524 - val_loss: 0.2058 - val_accuracy: 0.8500\n",
      "Epoch 442/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0634 - accuracy: 0.8524 - val_loss: 0.1973 - val_accuracy: 0.8495\n",
      "Epoch 443/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0635 - accuracy: 0.8526 - val_loss: 0.2056 - val_accuracy: 0.8492\n",
      "Epoch 444/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0625 - accuracy: 0.8526 - val_loss: 0.1924 - val_accuracy: 0.8504\n",
      "Epoch 445/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0633 - accuracy: 0.8525 - val_loss: 0.2172 - val_accuracy: 0.8503\n",
      "Epoch 446/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0644 - accuracy: 0.8525 - val_loss: 0.2278 - val_accuracy: 0.8483\n",
      "Epoch 447/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0631 - accuracy: 0.8524 - val_loss: 0.1972 - val_accuracy: 0.8503\n",
      "Epoch 448/500\n",
      "3834/3834 [==============================] - 2s 645us/step - loss: 0.0618 - accuracy: 0.8528 - val_loss: 0.1869 - val_accuracy: 0.8509\n",
      "Epoch 449/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0643 - accuracy: 0.8523 - val_loss: 0.2265 - val_accuracy: 0.8503\n",
      "Epoch 450/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0643 - accuracy: 0.8524 - val_loss: 0.1845 - val_accuracy: 0.8500\n",
      "Epoch 451/500\n",
      "3834/3834 [==============================] - 2s 641us/step - loss: 0.0624 - accuracy: 0.8526 - val_loss: 0.1902 - val_accuracy: 0.8504\n",
      "Epoch 452/500\n",
      "3834/3834 [==============================] - 2s 647us/step - loss: 0.0633 - accuracy: 0.8526 - val_loss: 0.1802 - val_accuracy: 0.8495\n",
      "Epoch 453/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0635 - accuracy: 0.8526 - val_loss: 0.1678 - val_accuracy: 0.8508\n",
      "Epoch 454/500\n",
      "3834/3834 [==============================] - 3s 685us/step - loss: 0.0610 - accuracy: 0.8529 - val_loss: 0.1916 - val_accuracy: 0.8496\n",
      "Epoch 455/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0616 - accuracy: 0.8528 - val_loss: 0.2150 - val_accuracy: 0.8493\n",
      "Epoch 456/500\n",
      "3834/3834 [==============================] - 2s 651us/step - loss: 0.0636 - accuracy: 0.8526 - val_loss: 0.2334 - val_accuracy: 0.8489\n",
      "Epoch 457/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0630 - accuracy: 0.8524 - val_loss: 0.1891 - val_accuracy: 0.8492\n",
      "Epoch 458/500\n",
      "3834/3834 [==============================] - 3s 652us/step - loss: 0.0625 - accuracy: 0.8525 - val_loss: 0.1673 - val_accuracy: 0.8490\n",
      "Epoch 459/500\n",
      "3834/3834 [==============================] - 2s 649us/step - loss: 0.0622 - accuracy: 0.8529 - val_loss: 0.1703 - val_accuracy: 0.8509\n",
      "Epoch 460/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0629 - accuracy: 0.8528 - val_loss: 0.1918 - val_accuracy: 0.8502\n",
      "Epoch 461/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0632 - accuracy: 0.8529 - val_loss: 0.2446 - val_accuracy: 0.8512\n",
      "Epoch 462/500\n",
      "3834/3834 [==============================] - 3s 691us/step - loss: 0.0617 - accuracy: 0.8529 - val_loss: 0.1855 - val_accuracy: 0.8498\n",
      "Epoch 463/500\n",
      "3834/3834 [==============================] - 2s 648us/step - loss: 0.0618 - accuracy: 0.8530 - val_loss: 0.1895 - val_accuracy: 0.8498\n",
      "Epoch 464/500\n",
      "3834/3834 [==============================] - 3s 686us/step - loss: 0.0643 - accuracy: 0.8527 - val_loss: 0.1951 - val_accuracy: 0.8486\n",
      "Epoch 465/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0626 - accuracy: 0.8529 - val_loss: 0.1843 - val_accuracy: 0.8482\n",
      "Epoch 466/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0626 - accuracy: 0.8525 - val_loss: 0.1917 - val_accuracy: 0.8487\n",
      "Epoch 467/500\n",
      "3834/3834 [==============================] - 2s 646us/step - loss: 0.0610 - accuracy: 0.8527 - val_loss: 0.1834 - val_accuracy: 0.8496\n",
      "Epoch 468/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0617 - accuracy: 0.8528 - val_loss: 0.1686 - val_accuracy: 0.8498\n",
      "Epoch 469/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0613 - accuracy: 0.8529 - val_loss: 0.1887 - val_accuracy: 0.8498\n",
      "Epoch 470/500\n",
      "3834/3834 [==============================] - 3s 697us/step - loss: 0.0606 - accuracy: 0.8528 - val_loss: 0.1740 - val_accuracy: 0.8503\n",
      "Epoch 471/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0617 - accuracy: 0.8527 - val_loss: 0.2382 - val_accuracy: 0.8505\n",
      "Epoch 472/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0624 - accuracy: 0.8529 - val_loss: 0.1967 - val_accuracy: 0.8496\n",
      "Epoch 473/500\n",
      "3834/3834 [==============================] - 3s 669us/step - loss: 0.0622 - accuracy: 0.8527 - val_loss: 0.1863 - val_accuracy: 0.8490\n",
      "Epoch 474/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0610 - accuracy: 0.8529 - val_loss: 0.1821 - val_accuracy: 0.8488\n",
      "Epoch 475/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0629 - accuracy: 0.8527 - val_loss: 0.1846 - val_accuracy: 0.8492\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0608 - accuracy: 0.8531 - val_loss: 0.2151 - val_accuracy: 0.8508\n",
      "Epoch 477/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0625 - accuracy: 0.8529 - val_loss: 0.2062 - val_accuracy: 0.8498\n",
      "Epoch 478/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0638 - accuracy: 0.8528 - val_loss: 0.1867 - val_accuracy: 0.8512\n",
      "Epoch 479/500\n",
      "3834/3834 [==============================] - 3s 653us/step - loss: 0.0609 - accuracy: 0.8530 - val_loss: 0.1954 - val_accuracy: 0.8499\n",
      "Epoch 480/500\n",
      "3834/3834 [==============================] - 3s 660us/step - loss: 0.0609 - accuracy: 0.8531 - val_loss: 0.2171 - val_accuracy: 0.8515\n",
      "Epoch 481/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0610 - accuracy: 0.8533 - val_loss: 0.1933 - val_accuracy: 0.8496\n",
      "Epoch 482/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0610 - accuracy: 0.8530 - val_loss: 0.1962 - val_accuracy: 0.8511\n",
      "Epoch 483/500\n",
      "3834/3834 [==============================] - 3s 692us/step - loss: 0.0609 - accuracy: 0.8530 - val_loss: 0.2183 - val_accuracy: 0.8499\n",
      "Epoch 484/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0606 - accuracy: 0.8529 - val_loss: 0.2033 - val_accuracy: 0.8502\n",
      "Epoch 485/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0629 - accuracy: 0.8530 - val_loss: 0.1884 - val_accuracy: 0.8507\n",
      "Epoch 486/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0613 - accuracy: 0.8530 - val_loss: 0.2186 - val_accuracy: 0.8479\n",
      "Epoch 487/500\n",
      "3834/3834 [==============================] - 3s 657us/step - loss: 0.0605 - accuracy: 0.8531 - val_loss: 0.1788 - val_accuracy: 0.8496\n",
      "Epoch 488/500\n",
      "3834/3834 [==============================] - 3s 658us/step - loss: 0.0603 - accuracy: 0.8532 - val_loss: 0.2136 - val_accuracy: 0.8506\n",
      "Epoch 489/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0599 - accuracy: 0.8532 - val_loss: 0.1943 - val_accuracy: 0.8498\n",
      "Epoch 490/500\n",
      "3834/3834 [==============================] - 3s 661us/step - loss: 0.0602 - accuracy: 0.8529 - val_loss: 0.2161 - val_accuracy: 0.8485\n",
      "Epoch 491/500\n",
      "3834/3834 [==============================] - 3s 662us/step - loss: 0.0606 - accuracy: 0.8532 - val_loss: 0.1766 - val_accuracy: 0.8498\n",
      "Epoch 492/500\n",
      "3834/3834 [==============================] - 3s 655us/step - loss: 0.0629 - accuracy: 0.8531 - val_loss: 0.2060 - val_accuracy: 0.8505\n",
      "Epoch 493/500\n",
      "3834/3834 [==============================] - 3s 672us/step - loss: 0.0580 - accuracy: 0.8532 - val_loss: 0.2363 - val_accuracy: 0.8484\n",
      "Epoch 494/500\n",
      "3834/3834 [==============================] - 3s 665us/step - loss: 0.0603 - accuracy: 0.8530 - val_loss: 0.2017 - val_accuracy: 0.8487\n",
      "Epoch 495/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0592 - accuracy: 0.8533 - val_loss: 0.1890 - val_accuracy: 0.8497\n",
      "Epoch 496/500\n",
      "3834/3834 [==============================] - 3s 663us/step - loss: 0.0608 - accuracy: 0.8531 - val_loss: 0.1734 - val_accuracy: 0.8502\n",
      "Epoch 497/500\n",
      "3834/3834 [==============================] - 3s 656us/step - loss: 0.0608 - accuracy: 0.8527 - val_loss: 0.1990 - val_accuracy: 0.8489\n",
      "Epoch 498/500\n",
      "3834/3834 [==============================] - 3s 654us/step - loss: 0.0590 - accuracy: 0.8533 - val_loss: 0.1868 - val_accuracy: 0.8511\n",
      "Epoch 499/500\n",
      "3834/3834 [==============================] - 3s 659us/step - loss: 0.0605 - accuracy: 0.8530 - val_loss: 0.1842 - val_accuracy: 0.8507\n",
      "Epoch 500/500\n",
      "3834/3834 [==============================] - 2s 650us/step - loss: 0.0582 - accuracy: 0.8533 - val_loss: 0.1860 - val_accuracy: 0.8505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d837b18e08>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_name = \"models/model1\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 0, \n",
    "                                                save_best_only = True, mode ='auto')\n",
    "# Use the training data to fit (train) the model\n",
    "model.fit(X_train,Y_train,epochs=500,shuffle=True,verbose=1,validation_split = 0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 63)                1386      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 126)               8064      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 126)               16002     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 126)               16002     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 126)               16002     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 126)               16002     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 126)               16002     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 127       \n",
      "=================================================================\n",
      "Total params: 89,587\n",
      "Trainable params: 89,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(63, kernel_initializer='normal',activation='relu', input_dim=x_train.shape[1]))\n",
    "# Add a second hidden layer\n",
    "model2.add(Dense(126, kernel_initializer='normal',activation='relu'))\n",
    "model2.add(Dense(126, kernel_initializer='normal',activation='relu'))\n",
    "model2.add(Dense(126, kernel_initializer='normal',activation='relu'))\n",
    "model2.add(Dense(126, kernel_initializer='normal',activation='relu'))\n",
    "model2.add(Dense(126, kernel_initializer='normal',activation='relu'))\n",
    "model2.add(Dense(126, kernel_initializer='normal',activation='relu'))\n",
    "# Y_train = to_categorical(Y_train)\n",
    "# Add output layer\n",
    "model2.add(Dense(1,activation='linear'))\n",
    "model2.compile(loss=\"mean_squared_error\",optimizer=\"Adamax\", metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7076/7128 [============================>.] - ETA: 0s - loss: 74.3894 - accuracy: 0.2244INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 988us/step - loss: 74.0152 - accuracy: 0.2251 - val_loss: 46.1095 - val_accuracy: 0.3145\n",
      "Epoch 2/500\n",
      "7070/7128 [============================>.] - ETA: 0s - loss: 50.1612 - accuracy: 0.2649INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 49.9317 - accuracy: 0.2650 - val_loss: 36.0259 - val_accuracy: 0.3023\n",
      "Epoch 3/500\n",
      "7123/7128 [============================>.] - ETA: 0s - loss: 40.4486 - accuracy: 0.2689INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 40.4318 - accuracy: 0.2689 - val_loss: 23.9749 - val_accuracy: 0.2948\n",
      "Epoch 4/500\n",
      "7126/7128 [============================>.] - ETA: 0s - loss: 34.1667 - accuracy: 0.3077INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 34.1624 - accuracy: 0.3077 - val_loss: 23.3188 - val_accuracy: 0.3035\n",
      "Epoch 5/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 31.8448 - accuracy: 0.3098 - val_loss: 51.4201 - val_accuracy: 0.1878\n",
      "Epoch 6/500\n",
      "7116/7128 [============================>.] - ETA: 0s - loss: 31.4713 - accuracy: 0.3218INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 31.4567 - accuracy: 0.3219 - val_loss: 19.8449 - val_accuracy: 0.3302\n",
      "Epoch 7/500\n",
      "7089/7128 [============================>.] - ETA: 0s - loss: 27.8017 - accuracy: 0.3301INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 8s 1ms/step - loss: 28.7757 - accuracy: 0.3301 - val_loss: 16.0905 - val_accuracy: 0.3909\n",
      "Epoch 8/500\n",
      "7128/7128 [==============================] - 6s 908us/step - loss: 28.8592 - accuracy: 0.3406 - val_loss: 17.3564 - val_accuracy: 0.3611\n",
      "Epoch 9/500\n",
      "7072/7128 [============================>.] - ETA: 0s - loss: 28.9316 - accuracy: 0.3409INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 28.7918 - accuracy: 0.3411 - val_loss: 15.2701 - val_accuracy: 0.3595\n",
      "Epoch 10/500\n",
      "7128/7128 [==============================] - 6s 901us/step - loss: 28.0339 - accuracy: 0.3422 - val_loss: 15.4179 - val_accuracy: 0.3308\n",
      "Epoch 11/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 27.5913 - accuracy: 0.3474 - val_loss: 77.7647 - val_accuracy: 0.3562\n",
      "Epoch 12/500\n",
      "7107/7128 [============================>.] - ETA: 0s - loss: 26.6129 - accuracy: 0.3439INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 26.5681 - accuracy: 0.3439 - val_loss: 14.8737 - val_accuracy: 0.3609\n",
      "Epoch 13/500\n",
      "7128/7128 [==============================] - 7s 917us/step - loss: 26.8854 - accuracy: 0.3500 - val_loss: 14.9123 - val_accuracy: 0.3441\n",
      "Epoch 14/500\n",
      "7078/7128 [============================>.] - ETA: 0s - loss: 26.4098 - accuracy: 0.3534INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 8s 1ms/step - loss: 26.2925 - accuracy: 0.3534 - val_loss: 14.5192 - val_accuracy: 0.3676\n",
      "Epoch 15/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 26.0731 - accuracy: 0.3471 - val_loss: 14.8079 - val_accuracy: 0.3645\n",
      "Epoch 16/500\n",
      "7069/7128 [============================>.] - ETA: 0s - loss: 25.5496 - accuracy: 0.3579INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 25.4246 - accuracy: 0.3581 - val_loss: 14.3770 - val_accuracy: 0.3649\n",
      "Epoch 17/500\n",
      "7128/7128 [==============================] - 6s 894us/step - loss: 24.6879 - accuracy: 0.3514 - val_loss: 23.5858 - val_accuracy: 0.4046\n",
      "Epoch 18/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 25.0667 - accuracy: 0.3518 - val_loss: 14.7310 - val_accuracy: 0.3797\n",
      "Epoch 19/500\n",
      "7106/7128 [============================>.] - ETA: 0s - loss: 24.9489 - accuracy: 0.3569INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 8s 1ms/step - loss: 24.8923 - accuracy: 0.3569 - val_loss: 14.1550 - val_accuracy: 0.3679\n",
      "Epoch 20/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 24.1476 - accuracy: 0.3501 - val_loss: 15.6367 - val_accuracy: 0.3642\n",
      "Epoch 21/500\n",
      "7100/7128 [============================>.] - ETA: 0s - loss: 25.2642 - accuracy: 0.3563INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 25.2035 - accuracy: 0.3563 - val_loss: 13.8405 - val_accuracy: 0.3487\n",
      "Epoch 22/500\n",
      "7090/7128 [============================>.] - ETA: 0s - loss: 23.5291 - accuracy: 0.3571INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 8s 1ms/step - loss: 23.4489 - accuracy: 0.3571 - val_loss: 13.6053 - val_accuracy: 0.3591\n",
      "Epoch 23/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 24.2237 - accuracy: 0.3559 - val_loss: 13.8325 - val_accuracy: 0.3065\n",
      "Epoch 24/500\n",
      "7066/7128 [============================>.] - ETA: 0s - loss: 24.0127 - accuracy: 0.3580INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 23.8649 - accuracy: 0.3582 - val_loss: 13.3570 - val_accuracy: 0.3794\n",
      "Epoch 25/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 25.3807 - accuracy: 0.3577 - val_loss: 14.1676 - val_accuracy: 0.3573\n",
      "Epoch 26/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 23.6827 - accuracy: 0.3564 - val_loss: 14.2121 - val_accuracy: 0.3827\n",
      "Epoch 27/500\n",
      "7128/7128 [==============================] - 7s 929us/step - loss: 23.5139 - accuracy: 0.3564 - val_loss: 15.2760 - val_accuracy: 0.3478\n",
      "Epoch 28/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 23.3815 - accuracy: 0.3609 - val_loss: 16.0344 - val_accuracy: 0.3216\n",
      "Epoch 29/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 23.6380 - accuracy: 0.3619 - val_loss: 14.6629 - val_accuracy: 0.3475\n",
      "Epoch 30/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 23.3282 - accuracy: 0.3528 - val_loss: 16.6879 - val_accuracy: 0.3930\n",
      "Epoch 31/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 23.3579 - accuracy: 0.3646 - val_loss: 13.7595 - val_accuracy: 0.3739\n",
      "Epoch 32/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 23.0377 - accuracy: 0.3614 - val_loss: 22.9592 - val_accuracy: 0.2935\n",
      "Epoch 33/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 22.7600 - accuracy: 0.3582 - val_loss: 14.7050 - val_accuracy: 0.3641\n",
      "Epoch 34/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 23.0026 - accuracy: 0.3642 - val_loss: 15.1846 - val_accuracy: 0.2980\n",
      "Epoch 35/500\n",
      "7092/7128 [============================>.] - ETA: 0s - loss: 23.5527 - accuracy: 0.3624INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 8s 1ms/step - loss: 23.4750 - accuracy: 0.3625 - val_loss: 12.7947 - val_accuracy: 0.3726\n",
      "Epoch 36/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 22.9389 - accuracy: 0.3589 - val_loss: 16.6889 - val_accuracy: 0.3670\n",
      "Epoch 37/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 22.4348 - accuracy: 0.3661 - val_loss: 26.0930 - val_accuracy: 0.4323\n",
      "Epoch 38/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 22.8004 - accuracy: 0.3644 - val_loss: 29.1774 - val_accuracy: 0.3277\n",
      "Epoch 39/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 22.2987 - accuracy: 0.3674 - val_loss: 14.0945 - val_accuracy: 0.3208\n",
      "Epoch 40/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 22.6428 - accuracy: 0.3619 - val_loss: 13.7811 - val_accuracy: 0.3627\n",
      "Epoch 41/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 874us/step - loss: 22.3011 - accuracy: 0.3648 - val_loss: 12.8681 - val_accuracy: 0.3678\n",
      "Epoch 42/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 22.7082 - accuracy: 0.3620 - val_loss: 13.2331 - val_accuracy: 0.3837\n",
      "Epoch 43/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 22.1213 - accuracy: 0.3664 - val_loss: 13.8051 - val_accuracy: 0.3864\n",
      "Epoch 44/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 22.6458 - accuracy: 0.3683 - val_loss: 13.4885 - val_accuracy: 0.3736\n",
      "Epoch 45/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 22.2448 - accuracy: 0.3686 - val_loss: 13.4472 - val_accuracy: 0.3592\n",
      "Epoch 46/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 22.6459 - accuracy: 0.3699 - val_loss: 13.9040 - val_accuracy: 0.3720\n",
      "Epoch 47/500\n",
      "7128/7128 [==============================] - 6s 895us/step - loss: 23.2702 - accuracy: 0.3707 - val_loss: 14.1825 - val_accuracy: 0.3587\n",
      "Epoch 48/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 22.2921 - accuracy: 0.3681 - val_loss: 15.7950 - val_accuracy: 0.4089\n",
      "Epoch 49/500\n",
      "7088/7128 [============================>.] - ETA: 0s - loss: 23.3733 - accuracy: 0.3695INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 23.2747 - accuracy: 0.3696 - val_loss: 12.5858 - val_accuracy: 0.3693\n",
      "Epoch 50/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 22.3610 - accuracy: 0.3667 - val_loss: 15.4856 - val_accuracy: 0.3904\n",
      "Epoch 51/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 21.9764 - accuracy: 0.3696 - val_loss: 13.8912 - val_accuracy: 0.3623\n",
      "Epoch 52/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 22.3785 - accuracy: 0.3658 - val_loss: 14.4269 - val_accuracy: 0.3782\n",
      "Epoch 53/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 22.4813 - accuracy: 0.3693 - val_loss: 15.2145 - val_accuracy: 0.3760\n",
      "Epoch 54/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 22.1089 - accuracy: 0.3673 - val_loss: 13.4743 - val_accuracy: 0.3763\n",
      "Epoch 55/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 22.1805 - accuracy: 0.3696 - val_loss: 15.2892 - val_accuracy: 0.3523\n",
      "Epoch 56/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 22.0188 - accuracy: 0.3679 - val_loss: 12.9420 - val_accuracy: 0.3793\n",
      "Epoch 57/500\n",
      "7083/7128 [============================>.] - ETA: 0s - loss: 22.0016 - accuracy: 0.3655INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 21.9008 - accuracy: 0.3655 - val_loss: 12.4990 - val_accuracy: 0.3578\n",
      "Epoch 58/500\n",
      "7128/7128 [==============================] - 6s 892us/step - loss: 22.1622 - accuracy: 0.3637 - val_loss: 13.7496 - val_accuracy: 0.3734\n",
      "Epoch 59/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 22.5018 - accuracy: 0.3697 - val_loss: 13.4930 - val_accuracy: 0.3586\n",
      "Epoch 60/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 21.9803 - accuracy: 0.3693 - val_loss: 12.8172 - val_accuracy: 0.3523\n",
      "Epoch 61/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 21.9739 - accuracy: 0.3714 - val_loss: 13.4257 - val_accuracy: 0.3761\n",
      "Epoch 62/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 21.9172 - accuracy: 0.3723 - val_loss: 14.3216 - val_accuracy: 0.3725\n",
      "Epoch 63/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 22.0160 - accuracy: 0.3697 - val_loss: 17.9893 - val_accuracy: 0.2844\n",
      "Epoch 64/500\n",
      "7128/7128 [==============================] - 6s 908us/step - loss: 21.9991 - accuracy: 0.3670 - val_loss: 17.0253 - val_accuracy: 0.3364\n",
      "Epoch 65/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 21.5714 - accuracy: 0.3717 - val_loss: 15.2604 - val_accuracy: 0.3443\n",
      "Epoch 66/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 22.0199 - accuracy: 0.3703 - val_loss: 13.3522 - val_accuracy: 0.3826\n",
      "Epoch 67/500\n",
      "7068/7128 [============================>.] - ETA: 0s - loss: 22.1578 - accuracy: 0.3719INFO:tensorflow:Assets written to: models\\model2\\assets\n",
      "7128/7128 [==============================] - 7s 1ms/step - loss: 22.0619 - accuracy: 0.3716 - val_loss: 12.4045 - val_accuracy: 0.3488\n",
      "Epoch 68/500\n",
      "7128/7128 [==============================] - 6s 894us/step - loss: 21.6118 - accuracy: 0.3680 - val_loss: 18.1605 - val_accuracy: 0.3333\n",
      "Epoch 69/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 21.7051 - accuracy: 0.3731 - val_loss: 15.2204 - val_accuracy: 0.3395\n",
      "Epoch 70/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 21.6369 - accuracy: 0.3672 - val_loss: 12.9810 - val_accuracy: 0.3539\n",
      "Epoch 71/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 21.9279 - accuracy: 0.3709 - val_loss: 14.1163 - val_accuracy: 0.3722\n",
      "Epoch 72/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 21.4977 - accuracy: 0.3723 - val_loss: 15.2710 - val_accuracy: 0.3965\n",
      "Epoch 73/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 21.2624 - accuracy: 0.3738 - val_loss: 14.3513 - val_accuracy: 0.3933\n",
      "Epoch 74/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 22.4871 - accuracy: 0.3719 - val_loss: 12.5650 - val_accuracy: 0.3813\n",
      "Epoch 75/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 21.5472 - accuracy: 0.3729 - val_loss: 13.1795 - val_accuracy: 0.3546\n",
      "Epoch 76/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 23.0412 - accuracy: 0.3730 - val_loss: 28.8063 - val_accuracy: 0.4220\n",
      "Epoch 77/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 21.4733 - accuracy: 0.3732 - val_loss: 21.5413 - val_accuracy: 0.3186\n",
      "Epoch 78/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 21.8847 - accuracy: 0.3751 - val_loss: 14.0831 - val_accuracy: 0.3793\n",
      "Epoch 79/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 21.2718 - accuracy: 0.3741 - val_loss: 13.7704 - val_accuracy: 0.3767\n",
      "Epoch 80/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 21.4093 - accuracy: 0.3751 - val_loss: 13.2642 - val_accuracy: 0.3581\n",
      "Epoch 81/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 22.1751 - accuracy: 0.3755 - val_loss: 13.4435 - val_accuracy: 0.3787\n",
      "Epoch 82/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 21.2149 - accuracy: 0.3728 - val_loss: 14.7172 - val_accuracy: 0.3450\n",
      "Epoch 83/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 21.5474 - accuracy: 0.3773 - val_loss: 17.6626 - val_accuracy: 0.3677\n",
      "Epoch 84/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 21.6526 - accuracy: 0.3760 - val_loss: 13.9534 - val_accuracy: 0.3254\n",
      "Epoch 85/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 21.1965 - accuracy: 0.3752 - val_loss: 15.4846 - val_accuracy: 0.3673\n",
      "Epoch 86/500\n",
      "7128/7128 [==============================] - 6s 899us/step - loss: 21.5204 - accuracy: 0.3743 - val_loss: 13.6821 - val_accuracy: 0.3783\n",
      "Epoch 87/500\n",
      "7128/7128 [==============================] - 6s 897us/step - loss: 22.5950 - accuracy: 0.3773 - val_loss: 13.1325 - val_accuracy: 0.3683\n",
      "Epoch 88/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 21.0190 - accuracy: 0.3770 - val_loss: 13.6540 - val_accuracy: 0.3672\n",
      "Epoch 89/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 21.0692 - accuracy: 0.3716 - val_loss: 13.8714 - val_accuracy: 0.3469\n",
      "Epoch 90/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 21.7790 - accuracy: 0.3722 - val_loss: 12.9516 - val_accuracy: 0.3756\n",
      "Epoch 91/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 21.1073 - accuracy: 0.3706 - val_loss: 13.9369 - val_accuracy: 0.3612\n",
      "Epoch 92/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 21.3398 - accuracy: 0.3764 - val_loss: 14.0442 - val_accuracy: 0.3707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 21.7662 - accuracy: 0.3759 - val_loss: 13.0531 - val_accuracy: 0.3540\n",
      "Epoch 94/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 21.0392 - accuracy: 0.3738 - val_loss: 12.9831 - val_accuracy: 0.3551\n",
      "Epoch 95/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 21.2184 - accuracy: 0.3746 - val_loss: 12.7970 - val_accuracy: 0.3857\n",
      "Epoch 96/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 21.6604 - accuracy: 0.3765 - val_loss: 15.2534 - val_accuracy: 0.3990\n",
      "Epoch 97/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 20.8423 - accuracy: 0.3728 - val_loss: 12.7158 - val_accuracy: 0.3786\n",
      "Epoch 98/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 21.5082 - accuracy: 0.3702 - val_loss: 13.0643 - val_accuracy: 0.3711\n",
      "Epoch 99/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 21.1270 - accuracy: 0.3753 - val_loss: 14.4616 - val_accuracy: 0.3446\n",
      "Epoch 100/500\n",
      "7128/7128 [==============================] - 6s 899us/step - loss: 21.4436 - accuracy: 0.3759 - val_loss: 13.2184 - val_accuracy: 0.3893\n",
      "Epoch 101/500\n",
      "7128/7128 [==============================] - 6s 895us/step - loss: 21.0553 - accuracy: 0.3780 - val_loss: 16.4709 - val_accuracy: 0.3433\n",
      "Epoch 102/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 20.8855 - accuracy: 0.3732 - val_loss: 12.9005 - val_accuracy: 0.3837\n",
      "Epoch 103/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 21.0701 - accuracy: 0.3792 - val_loss: 13.2253 - val_accuracy: 0.3877\n",
      "Epoch 104/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 21.0050 - accuracy: 0.3797 - val_loss: 14.1514 - val_accuracy: 0.3609\n",
      "Epoch 105/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 20.9073 - accuracy: 0.3735 - val_loss: 14.2502 - val_accuracy: 0.3770\n",
      "Epoch 106/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 21.6487 - accuracy: 0.3797 - val_loss: 14.0443 - val_accuracy: 0.4014\n",
      "Epoch 107/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 21.1884 - accuracy: 0.3767 - val_loss: 13.1375 - val_accuracy: 0.3555\n",
      "Epoch 108/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 21.7653 - accuracy: 0.3779 - val_loss: 13.5729 - val_accuracy: 0.3801\n",
      "Epoch 109/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 20.8064 - accuracy: 0.3766 - val_loss: 13.2299 - val_accuracy: 0.3746\n",
      "Epoch 110/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 20.7668 - accuracy: 0.3753 - val_loss: 13.2023 - val_accuracy: 0.3615\n",
      "Epoch 111/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 21.1999 - accuracy: 0.3770 - val_loss: 12.5636 - val_accuracy: 0.3829\n",
      "Epoch 112/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 21.2901 - accuracy: 0.3750 - val_loss: 13.8799 - val_accuracy: 0.3729\n",
      "Epoch 113/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 21.2566 - accuracy: 0.3735 - val_loss: 13.1899 - val_accuracy: 0.3760\n",
      "Epoch 114/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.5728 - accuracy: 0.3774 - val_loss: 13.1898 - val_accuracy: 0.3827\n",
      "Epoch 115/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 21.1573 - accuracy: 0.3792 - val_loss: 12.7460 - val_accuracy: 0.3851\n",
      "Epoch 116/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 20.7886 - accuracy: 0.3797 - val_loss: 13.1324 - val_accuracy: 0.3849\n",
      "Epoch 117/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 20.9101 - accuracy: 0.3785 - val_loss: 13.0703 - val_accuracy: 0.3836\n",
      "Epoch 118/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.7784 - accuracy: 0.3793 - val_loss: 15.2505 - val_accuracy: 0.3552\n",
      "Epoch 119/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.7851 - accuracy: 0.3761 - val_loss: 13.0908 - val_accuracy: 0.3845\n",
      "Epoch 120/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 20.8326 - accuracy: 0.3792 - val_loss: 14.4088 - val_accuracy: 0.3750\n",
      "Epoch 121/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 21.0450 - accuracy: 0.3791 - val_loss: 13.4998 - val_accuracy: 0.3651\n",
      "Epoch 122/500\n",
      "7128/7128 [==============================] - 7s 915us/step - loss: 20.8689 - accuracy: 0.3746 - val_loss: 21.3446 - val_accuracy: 0.3616\n",
      "Epoch 123/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 20.9588 - accuracy: 0.3781 - val_loss: 22.7338 - val_accuracy: 0.3624\n",
      "Epoch 124/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 21.0270 - accuracy: 0.3802 - val_loss: 12.8352 - val_accuracy: 0.3682\n",
      "Epoch 125/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 21.0307 - accuracy: 0.3780 - val_loss: 13.6092 - val_accuracy: 0.3723\n",
      "Epoch 126/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 23.3055 - accuracy: 0.3770 - val_loss: 12.5492 - val_accuracy: 0.3872\n",
      "Epoch 127/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 20.3784 - accuracy: 0.3789 - val_loss: 14.3980 - val_accuracy: 0.3497\n",
      "Epoch 128/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 20.6847 - accuracy: 0.3796 - val_loss: 13.1643 - val_accuracy: 0.3790\n",
      "Epoch 129/500\n",
      "7128/7128 [==============================] - 6s 901us/step - loss: 20.6139 - accuracy: 0.3789 - val_loss: 13.8262 - val_accuracy: 0.3773\n",
      "Epoch 130/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 21.2513 - accuracy: 0.3794 - val_loss: 13.9399 - val_accuracy: 0.3913\n",
      "Epoch 131/500\n",
      "7128/7128 [==============================] - 6s 896us/step - loss: 20.6796 - accuracy: 0.3767 - val_loss: 12.9808 - val_accuracy: 0.3694\n",
      "Epoch 132/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 20.9714 - accuracy: 0.3795 - val_loss: 13.7025 - val_accuracy: 0.3733\n",
      "Epoch 133/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 20.7716 - accuracy: 0.3785 - val_loss: 13.4236 - val_accuracy: 0.3551\n",
      "Epoch 134/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 20.6062 - accuracy: 0.3825 - val_loss: 14.5024 - val_accuracy: 0.3966\n",
      "Epoch 135/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 20.5639 - accuracy: 0.3809 - val_loss: 13.6358 - val_accuracy: 0.3886\n",
      "Epoch 136/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.7914 - accuracy: 0.3741 - val_loss: 13.2885 - val_accuracy: 0.3777\n",
      "Epoch 137/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 20.6593 - accuracy: 0.3786 - val_loss: 13.2541 - val_accuracy: 0.3718\n",
      "Epoch 138/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.5430 - accuracy: 0.3794 - val_loss: 14.0389 - val_accuracy: 0.3300\n",
      "Epoch 139/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 20.6312 - accuracy: 0.3774 - val_loss: 14.0559 - val_accuracy: 0.3800\n",
      "Epoch 140/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 20.4136 - accuracy: 0.3778 - val_loss: 15.9547 - val_accuracy: 0.3895\n",
      "Epoch 141/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 20.7333 - accuracy: 0.3780 - val_loss: 13.3033 - val_accuracy: 0.3779\n",
      "Epoch 142/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 20.5735 - accuracy: 0.3761 - val_loss: 14.1787 - val_accuracy: 0.3607\n",
      "Epoch 143/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.7599 - accuracy: 0.3818 - val_loss: 18.0039 - val_accuracy: 0.3626\n",
      "Epoch 144/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.2686 - accuracy: 0.3814 - val_loss: 12.7000 - val_accuracy: 0.3883\n",
      "Epoch 145/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 20.4114 - accuracy: 0.3813 - val_loss: 13.0844 - val_accuracy: 0.3913\n",
      "Epoch 146/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 20.6679 - accuracy: 0.3770 - val_loss: 13.3230 - val_accuracy: 0.3710\n",
      "Epoch 147/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 874us/step - loss: 20.7528 - accuracy: 0.3800 - val_loss: 12.8725 - val_accuracy: 0.3862\n",
      "Epoch 148/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 20.5838 - accuracy: 0.3806 - val_loss: 13.1956 - val_accuracy: 0.3811\n",
      "Epoch 149/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.5840 - accuracy: 0.3774 - val_loss: 13.0364 - val_accuracy: 0.3847\n",
      "Epoch 150/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 20.3595 - accuracy: 0.3825 - val_loss: 13.2921 - val_accuracy: 0.3664\n",
      "Epoch 151/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 20.5462 - accuracy: 0.3805 - val_loss: 16.9518 - val_accuracy: 0.3742\n",
      "Epoch 152/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 20.9233 - accuracy: 0.3806 - val_loss: 15.5369 - val_accuracy: 0.3787\n",
      "Epoch 153/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 20.3613 - accuracy: 0.3812 - val_loss: 18.8419 - val_accuracy: 0.3760\n",
      "Epoch 154/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 20.5586 - accuracy: 0.3826 - val_loss: 13.3832 - val_accuracy: 0.3873\n",
      "Epoch 155/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.3525 - accuracy: 0.3798 - val_loss: 13.0165 - val_accuracy: 0.3738\n",
      "Epoch 156/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.6800 - accuracy: 0.3802 - val_loss: 12.9441 - val_accuracy: 0.3783\n",
      "Epoch 157/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 20.4453 - accuracy: 0.3808 - val_loss: 14.7264 - val_accuracy: 0.3481\n",
      "Epoch 158/500\n",
      "7128/7128 [==============================] - 6s 867us/step - loss: 20.4529 - accuracy: 0.3844 - val_loss: 17.9978 - val_accuracy: 0.3423\n",
      "Epoch 159/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.4274 - accuracy: 0.3822 - val_loss: 12.9483 - val_accuracy: 0.3697\n",
      "Epoch 160/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 20.3389 - accuracy: 0.3821 - val_loss: 15.2628 - val_accuracy: 0.3980\n",
      "Epoch 161/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.4337 - accuracy: 0.3818 - val_loss: 15.7481 - val_accuracy: 0.3961\n",
      "Epoch 162/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.1403 - accuracy: 0.3807 - val_loss: 15.1167 - val_accuracy: 0.3897\n",
      "Epoch 163/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 20.2445 - accuracy: 0.3827 - val_loss: 14.4389 - val_accuracy: 0.3652\n",
      "Epoch 164/500\n",
      "7128/7128 [==============================] - 6s 895us/step - loss: 20.4009 - accuracy: 0.3814 - val_loss: 13.7725 - val_accuracy: 0.4049\n",
      "Epoch 165/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 20.6771 - accuracy: 0.3845 - val_loss: 12.9099 - val_accuracy: 0.3819\n",
      "Epoch 166/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 20.5780 - accuracy: 0.3785 - val_loss: 13.3290 - val_accuracy: 0.3833\n",
      "Epoch 167/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 20.7033 - accuracy: 0.3806 - val_loss: 13.9321 - val_accuracy: 0.3797\n",
      "Epoch 168/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.2040 - accuracy: 0.3814 - val_loss: 13.1319 - val_accuracy: 0.3895\n",
      "Epoch 169/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.3295 - accuracy: 0.3816 - val_loss: 14.8514 - val_accuracy: 0.3584\n",
      "Epoch 170/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 20.5061 - accuracy: 0.3820 - val_loss: 14.3682 - val_accuracy: 0.3749\n",
      "Epoch 171/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 20.3923 - accuracy: 0.3784 - val_loss: 17.2129 - val_accuracy: 0.3328\n",
      "Epoch 172/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.3039 - accuracy: 0.3790 - val_loss: 12.8946 - val_accuracy: 0.3960\n",
      "Epoch 173/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 20.2733 - accuracy: 0.3789 - val_loss: 13.9899 - val_accuracy: 0.3840\n",
      "Epoch 174/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 20.4472 - accuracy: 0.3792 - val_loss: 13.3654 - val_accuracy: 0.3782\n",
      "Epoch 175/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.9185 - accuracy: 0.3828 - val_loss: 12.8701 - val_accuracy: 0.3894\n",
      "Epoch 176/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 20.5521 - accuracy: 0.3829 - val_loss: 14.2445 - val_accuracy: 0.3848\n",
      "Epoch 177/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 20.1224 - accuracy: 0.3797 - val_loss: 13.1995 - val_accuracy: 0.3806\n",
      "Epoch 178/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 20.6550 - accuracy: 0.3800 - val_loss: 14.8127 - val_accuracy: 0.3758\n",
      "Epoch 179/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 20.3958 - accuracy: 0.3808 - val_loss: 13.0335 - val_accuracy: 0.3713\n",
      "Epoch 180/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 20.2287 - accuracy: 0.3822 - val_loss: 14.1650 - val_accuracy: 0.3733\n",
      "Epoch 181/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 20.1760 - accuracy: 0.3800 - val_loss: 14.6808 - val_accuracy: 0.3806\n",
      "Epoch 182/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 20.9535 - accuracy: 0.3802 - val_loss: 14.9451 - val_accuracy: 0.3671\n",
      "Epoch 183/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.5006 - accuracy: 0.3782 - val_loss: 14.2095 - val_accuracy: 0.3631\n",
      "Epoch 184/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.2633 - accuracy: 0.3803 - val_loss: 14.2297 - val_accuracy: 0.3822\n",
      "Epoch 185/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.0470 - accuracy: 0.3825 - val_loss: 13.1183 - val_accuracy: 0.3826\n",
      "Epoch 186/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.6200 - accuracy: 0.3803 - val_loss: 14.0170 - val_accuracy: 0.3764\n",
      "Epoch 187/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 19.9148 - accuracy: 0.3781 - val_loss: 13.7682 - val_accuracy: 0.3739\n",
      "Epoch 188/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.5296 - accuracy: 0.3799 - val_loss: 13.1211 - val_accuracy: 0.3783\n",
      "Epoch 189/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 20.5757 - accuracy: 0.3826 - val_loss: 13.2625 - val_accuracy: 0.3944\n",
      "Epoch 190/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 20.0625 - accuracy: 0.3781 - val_loss: 13.0044 - val_accuracy: 0.3710\n",
      "Epoch 191/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 20.7671 - accuracy: 0.3813 - val_loss: 13.1029 - val_accuracy: 0.3873\n",
      "Epoch 192/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 20.4383 - accuracy: 0.3769 - val_loss: 14.5187 - val_accuracy: 0.3747\n",
      "Epoch 193/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 21.3243 - accuracy: 0.3808 - val_loss: 14.0474 - val_accuracy: 0.3652\n",
      "Epoch 194/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 20.1790 - accuracy: 0.3760 - val_loss: 13.4266 - val_accuracy: 0.3765\n",
      "Epoch 195/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 19.9166 - accuracy: 0.3765 - val_loss: 13.8797 - val_accuracy: 0.3811\n",
      "Epoch 196/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 20.2203 - accuracy: 0.3797 - val_loss: 14.0716 - val_accuracy: 0.3769\n",
      "Epoch 197/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 20.0329 - accuracy: 0.3808 - val_loss: 15.4807 - val_accuracy: 0.3809\n",
      "Epoch 198/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 20.0160 - accuracy: 0.3787 - val_loss: 15.0594 - val_accuracy: 0.3625\n",
      "Epoch 199/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 20.9328 - accuracy: 0.3818 - val_loss: 13.7439 - val_accuracy: 0.3813\n",
      "Epoch 200/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 20.1309 - accuracy: 0.3746 - val_loss: 18.0565 - val_accuracy: 0.4039\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 882us/step - loss: 20.4361 - accuracy: 0.3763 - val_loss: 15.7145 - val_accuracy: 0.3726\n",
      "Epoch 202/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 20.0818 - accuracy: 0.3769 - val_loss: 14.9107 - val_accuracy: 0.3755\n",
      "Epoch 203/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.0012 - accuracy: 0.3816 - val_loss: 13.1270 - val_accuracy: 0.3783\n",
      "Epoch 204/500\n",
      "7128/7128 [==============================] - 6s 867us/step - loss: 20.6025 - accuracy: 0.3811 - val_loss: 13.8559 - val_accuracy: 0.3721\n",
      "Epoch 205/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 19.9965 - accuracy: 0.3810 - val_loss: 13.4276 - val_accuracy: 0.3814\n",
      "Epoch 206/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 19.8305 - accuracy: 0.3793 - val_loss: 13.4220 - val_accuracy: 0.3620\n",
      "Epoch 207/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 20.0623 - accuracy: 0.3824 - val_loss: 14.1913 - val_accuracy: 0.3779\n",
      "Epoch 208/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 19.8841 - accuracy: 0.3808 - val_loss: 15.7586 - val_accuracy: 0.4027\n",
      "Epoch 209/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 19.7638 - accuracy: 0.3828 - val_loss: 13.2258 - val_accuracy: 0.3819\n",
      "Epoch 210/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 20.0480 - accuracy: 0.3803 - val_loss: 14.7561 - val_accuracy: 0.3669\n",
      "Epoch 211/500\n",
      "7128/7128 [==============================] - 6s 895us/step - loss: 20.0004 - accuracy: 0.3815 - val_loss: 16.4558 - val_accuracy: 0.3668\n",
      "Epoch 212/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 20.1411 - accuracy: 0.3790 - val_loss: 14.5604 - val_accuracy: 0.3899\n",
      "Epoch 213/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 20.2804 - accuracy: 0.3820 - val_loss: 13.0047 - val_accuracy: 0.3927\n",
      "Epoch 214/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 19.8073 - accuracy: 0.3798 - val_loss: 14.2006 - val_accuracy: 0.3655\n",
      "Epoch 215/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 20.6662 - accuracy: 0.3807 - val_loss: 14.4027 - val_accuracy: 0.3781\n",
      "Epoch 216/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 20.5915 - accuracy: 0.3785 - val_loss: 13.2473 - val_accuracy: 0.3698\n",
      "Epoch 217/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 20.0986 - accuracy: 0.3819 - val_loss: 16.3107 - val_accuracy: 0.3721\n",
      "Epoch 218/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 20.6543 - accuracy: 0.3798 - val_loss: 13.7245 - val_accuracy: 0.3998\n",
      "Epoch 219/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 19.7714 - accuracy: 0.3823 - val_loss: 14.3351 - val_accuracy: 0.3689\n",
      "Epoch 220/500\n",
      "7128/7128 [==============================] - 6s 895us/step - loss: 19.9317 - accuracy: 0.3828 - val_loss: 14.2926 - val_accuracy: 0.3799\n",
      "Epoch 221/500\n",
      "7128/7128 [==============================] - 6s 892us/step - loss: 20.2984 - accuracy: 0.3817 - val_loss: 14.7429 - val_accuracy: 0.3818\n",
      "Epoch 222/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 20.1959 - accuracy: 0.3868 - val_loss: 15.7874 - val_accuracy: 0.3825\n",
      "Epoch 223/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 20.0738 - accuracy: 0.3741 - val_loss: 14.9233 - val_accuracy: 0.3955\n",
      "Epoch 224/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 19.9068 - accuracy: 0.3776 - val_loss: 14.2204 - val_accuracy: 0.3780\n",
      "Epoch 225/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 20.0418 - accuracy: 0.3740 - val_loss: 15.0843 - val_accuracy: 0.3843\n",
      "Epoch 226/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 19.6347 - accuracy: 0.3806 - val_loss: 13.7930 - val_accuracy: 0.3600\n",
      "Epoch 227/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 20.0732 - accuracy: 0.3776 - val_loss: 13.3342 - val_accuracy: 0.3885\n",
      "Epoch 228/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.9143 - accuracy: 0.3794 - val_loss: 13.0512 - val_accuracy: 0.3907\n",
      "Epoch 229/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 20.2498 - accuracy: 0.3806 - val_loss: 13.1302 - val_accuracy: 0.3737\n",
      "Epoch 230/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 19.7100 - accuracy: 0.3813 - val_loss: 13.3881 - val_accuracy: 0.3867\n",
      "Epoch 231/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 19.6543 - accuracy: 0.3817 - val_loss: 13.5665 - val_accuracy: 0.3852\n",
      "Epoch 232/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.8588 - accuracy: 0.3815 - val_loss: 15.1085 - val_accuracy: 0.3988\n",
      "Epoch 233/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 19.6648 - accuracy: 0.3815 - val_loss: 15.2359 - val_accuracy: 0.3608\n",
      "Epoch 234/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.9695 - accuracy: 0.3795 - val_loss: 13.4047 - val_accuracy: 0.3773\n",
      "Epoch 235/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 19.7505 - accuracy: 0.3758 - val_loss: 13.5016 - val_accuracy: 0.3771\n",
      "Epoch 236/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.8382 - accuracy: 0.3775 - val_loss: 21.5127 - val_accuracy: 0.3519\n",
      "Epoch 237/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.7417 - accuracy: 0.3786 - val_loss: 14.3656 - val_accuracy: 0.3868\n",
      "Epoch 238/500\n",
      "7128/7128 [==============================] - 6s 864us/step - loss: 20.2043 - accuracy: 0.3792 - val_loss: 13.8259 - val_accuracy: 0.3603\n",
      "Epoch 239/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 20.3980 - accuracy: 0.3756 - val_loss: 13.5322 - val_accuracy: 0.3791\n",
      "Epoch 240/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 19.6970 - accuracy: 0.3802 - val_loss: 13.8011 - val_accuracy: 0.3939\n",
      "Epoch 241/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 19.8366 - accuracy: 0.3821 - val_loss: 21.6102 - val_accuracy: 0.4087\n",
      "Epoch 242/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.8642 - accuracy: 0.3736 - val_loss: 13.7078 - val_accuracy: 0.3875\n",
      "Epoch 243/500\n",
      "7128/7128 [==============================] - 6s 892us/step - loss: 20.0164 - accuracy: 0.3814 - val_loss: 15.6878 - val_accuracy: 0.3783\n",
      "Epoch 244/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 19.7338 - accuracy: 0.3818 - val_loss: 14.5601 - val_accuracy: 0.3881\n",
      "Epoch 245/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.8155 - accuracy: 0.3818 - val_loss: 14.2124 - val_accuracy: 0.3866\n",
      "Epoch 246/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.5384 - accuracy: 0.3792 - val_loss: 16.8198 - val_accuracy: 0.3955\n",
      "Epoch 247/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 19.5827 - accuracy: 0.3785 - val_loss: 15.4073 - val_accuracy: 0.4000\n",
      "Epoch 248/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 20.2305 - accuracy: 0.3778 - val_loss: 13.7587 - val_accuracy: 0.3793\n",
      "Epoch 249/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 19.7427 - accuracy: 0.3785 - val_loss: 13.5123 - val_accuracy: 0.3745\n",
      "Epoch 250/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 19.7387 - accuracy: 0.3828 - val_loss: 13.7652 - val_accuracy: 0.3811\n",
      "Epoch 251/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 19.4888 - accuracy: 0.3798 - val_loss: 13.6334 - val_accuracy: 0.3489\n",
      "Epoch 252/500\n",
      "7128/7128 [==============================] - 7s 913us/step - loss: 19.6717 - accuracy: 0.3814 - val_loss: 13.2790 - val_accuracy: 0.3825\n",
      "Epoch 253/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 20.4164 - accuracy: 0.3815 - val_loss: 14.2948 - val_accuracy: 0.3849\n",
      "Epoch 254/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.4611 - accuracy: 0.3810 - val_loss: 13.2856 - val_accuracy: 0.3877\n",
      "Epoch 255/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 869us/step - loss: 19.8093 - accuracy: 0.3830 - val_loss: 13.2603 - val_accuracy: 0.3679\n",
      "Epoch 256/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 19.8106 - accuracy: 0.3736 - val_loss: 13.6976 - val_accuracy: 0.3517\n",
      "Epoch 257/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 19.8364 - accuracy: 0.3774 - val_loss: 14.6146 - val_accuracy: 0.3650\n",
      "Epoch 258/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 19.6455 - accuracy: 0.3806 - val_loss: 15.2615 - val_accuracy: 0.3435\n",
      "Epoch 259/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 19.8814 - accuracy: 0.3790 - val_loss: 14.0546 - val_accuracy: 0.3857\n",
      "Epoch 260/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.7943 - accuracy: 0.3821 - val_loss: 13.2976 - val_accuracy: 0.3923\n",
      "Epoch 261/500\n",
      "7128/7128 [==============================] - 6s 896us/step - loss: 19.5155 - accuracy: 0.3820 - val_loss: 14.0941 - val_accuracy: 0.3666\n",
      "Epoch 262/500\n",
      "7128/7128 [==============================] - 7s 933us/step - loss: 20.0049 - accuracy: 0.3820 - val_loss: 13.2960 - val_accuracy: 0.3783\n",
      "Epoch 263/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.4653 - accuracy: 0.3785 - val_loss: 13.1979 - val_accuracy: 0.3738\n",
      "Epoch 264/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 19.9485 - accuracy: 0.3816 - val_loss: 14.7515 - val_accuracy: 0.3949\n",
      "Epoch 265/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 19.5939 - accuracy: 0.3803 - val_loss: 13.1309 - val_accuracy: 0.3851\n",
      "Epoch 266/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.6420 - accuracy: 0.3828 - val_loss: 13.3076 - val_accuracy: 0.3677\n",
      "Epoch 267/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 20.0930 - accuracy: 0.3803 - val_loss: 16.4508 - val_accuracy: 0.3687\n",
      "Epoch 268/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 19.4359 - accuracy: 0.3844 - val_loss: 13.3056 - val_accuracy: 0.4009\n",
      "Epoch 269/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 19.3522 - accuracy: 0.3823 - val_loss: 16.6219 - val_accuracy: 0.3371\n",
      "Epoch 270/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 20.3366 - accuracy: 0.3777 - val_loss: 12.8449 - val_accuracy: 0.3882\n",
      "Epoch 271/500\n",
      "7128/7128 [==============================] - 6s 892us/step - loss: 19.6234 - accuracy: 0.3833 - val_loss: 15.7879 - val_accuracy: 0.3896\n",
      "Epoch 272/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 19.6571 - accuracy: 0.3802 - val_loss: 13.3451 - val_accuracy: 0.3598\n",
      "Epoch 273/500\n",
      "7128/7128 [==============================] - 6s 896us/step - loss: 19.1863 - accuracy: 0.3783 - val_loss: 13.6949 - val_accuracy: 0.3948\n",
      "Epoch 274/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 19.5899 - accuracy: 0.3814 - val_loss: 13.8876 - val_accuracy: 0.3777\n",
      "Epoch 275/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 19.7557 - accuracy: 0.3834 - val_loss: 14.2969 - val_accuracy: 0.3876\n",
      "Epoch 276/500\n",
      "7128/7128 [==============================] - 6s 900us/step - loss: 19.2720 - accuracy: 0.3803 - val_loss: 13.5858 - val_accuracy: 0.3862\n",
      "Epoch 277/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.7121 - accuracy: 0.3847 - val_loss: 14.0346 - val_accuracy: 0.3547\n",
      "Epoch 278/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 19.7038 - accuracy: 0.3810 - val_loss: 13.0706 - val_accuracy: 0.3797\n",
      "Epoch 279/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 19.4151 - accuracy: 0.3856 - val_loss: 13.6575 - val_accuracy: 0.3837\n",
      "Epoch 280/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 19.6444 - accuracy: 0.3805 - val_loss: 14.1180 - val_accuracy: 0.3643\n",
      "Epoch 281/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.3278 - accuracy: 0.3773 - val_loss: 15.5438 - val_accuracy: 0.3831\n",
      "Epoch 282/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 19.6531 - accuracy: 0.3784 - val_loss: 13.5811 - val_accuracy: 0.3786\n",
      "Epoch 283/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 19.3839 - accuracy: 0.3834 - val_loss: 15.0940 - val_accuracy: 0.4000\n",
      "Epoch 284/500\n",
      "7128/7128 [==============================] - 6s 896us/step - loss: 19.2283 - accuracy: 0.3845 - val_loss: 14.3272 - val_accuracy: 0.3857\n",
      "Epoch 285/500\n",
      "7128/7128 [==============================] - 6s 894us/step - loss: 19.5888 - accuracy: 0.3784 - val_loss: 13.8910 - val_accuracy: 0.3896\n",
      "Epoch 286/500\n",
      "7128/7128 [==============================] - 6s 860us/step - loss: 19.7065 - accuracy: 0.3801 - val_loss: 13.7255 - val_accuracy: 0.3770\n",
      "Epoch 287/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 19.2565 - accuracy: 0.3809 - val_loss: 15.6552 - val_accuracy: 0.3904\n",
      "Epoch 288/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 20.0807 - accuracy: 0.3862 - val_loss: 13.1043 - val_accuracy: 0.3742\n",
      "Epoch 289/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 19.8302 - accuracy: 0.3815 - val_loss: 13.9265 - val_accuracy: 0.3601\n",
      "Epoch 290/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.4135 - accuracy: 0.3827 - val_loss: 13.4393 - val_accuracy: 0.3656\n",
      "Epoch 291/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 20.0274 - accuracy: 0.3808 - val_loss: 18.7802 - val_accuracy: 0.4091\n",
      "Epoch 292/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 19.2357 - accuracy: 0.3810 - val_loss: 22.6625 - val_accuracy: 0.3763\n",
      "Epoch 293/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 19.4886 - accuracy: 0.3852 - val_loss: 13.5547 - val_accuracy: 0.3712\n",
      "Epoch 294/500\n",
      "7128/7128 [==============================] - 7s 926us/step - loss: 19.1046 - accuracy: 0.3843 - val_loss: 14.1163 - val_accuracy: 0.3779\n",
      "Epoch 295/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.1968 - accuracy: 0.3802 - val_loss: 14.1357 - val_accuracy: 0.3654\n",
      "Epoch 296/500\n",
      "7128/7128 [==============================] - 6s 867us/step - loss: 19.1991 - accuracy: 0.3853 - val_loss: 14.0138 - val_accuracy: 0.3681\n",
      "Epoch 297/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 19.1513 - accuracy: 0.3819 - val_loss: 13.5641 - val_accuracy: 0.3599\n",
      "Epoch 298/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 19.3008 - accuracy: 0.3826 - val_loss: 12.8638 - val_accuracy: 0.3743\n",
      "Epoch 299/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.6989 - accuracy: 0.3801 - val_loss: 14.5749 - val_accuracy: 0.3962\n",
      "Epoch 300/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 19.1846 - accuracy: 0.3814 - val_loss: 14.6827 - val_accuracy: 0.3848\n",
      "Epoch 301/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.2457 - accuracy: 0.3800 - val_loss: 13.0573 - val_accuracy: 0.3788\n",
      "Epoch 302/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 19.1051 - accuracy: 0.3841 - val_loss: 15.6263 - val_accuracy: 0.3830\n",
      "Epoch 303/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 19.6440 - accuracy: 0.3808 - val_loss: 14.2115 - val_accuracy: 0.3775\n",
      "Epoch 304/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 19.4542 - accuracy: 0.3812 - val_loss: 16.3309 - val_accuracy: 0.3801\n",
      "Epoch 305/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 19.1929 - accuracy: 0.3831 - val_loss: 14.4757 - val_accuracy: 0.3579\n",
      "Epoch 306/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 19.1686 - accuracy: 0.3853 - val_loss: 14.3272 - val_accuracy: 0.3713\n",
      "Epoch 307/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 18.9257 - accuracy: 0.3838 - val_loss: 15.6211 - val_accuracy: 0.3705\n",
      "Epoch 308/500\n",
      "7128/7128 [==============================] - 6s 888us/step - loss: 19.7072 - accuracy: 0.3821 - val_loss: 14.6951 - val_accuracy: 0.3750\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 895us/step - loss: 19.3403 - accuracy: 0.3847 - val_loss: 14.1040 - val_accuracy: 0.3790\n",
      "Epoch 310/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 19.0015 - accuracy: 0.3835 - val_loss: 14.0732 - val_accuracy: 0.3810\n",
      "Epoch 311/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 19.4867 - accuracy: 0.3785 - val_loss: 15.6676 - val_accuracy: 0.3609\n",
      "Epoch 312/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 19.7254 - accuracy: 0.3835 - val_loss: 13.2353 - val_accuracy: 0.3843\n",
      "Epoch 313/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 19.2689 - accuracy: 0.3802 - val_loss: 14.0104 - val_accuracy: 0.3627\n",
      "Epoch 314/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 19.2434 - accuracy: 0.3809 - val_loss: 14.7480 - val_accuracy: 0.3834\n",
      "Epoch 315/500\n",
      "7128/7128 [==============================] - 6s 894us/step - loss: 19.3033 - accuracy: 0.3867 - val_loss: 14.0374 - val_accuracy: 0.3680\n",
      "Epoch 316/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 19.1128 - accuracy: 0.3814 - val_loss: 13.6037 - val_accuracy: 0.3861\n",
      "Epoch 317/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 19.1472 - accuracy: 0.3835 - val_loss: 13.5796 - val_accuracy: 0.3953\n",
      "Epoch 318/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 19.1531 - accuracy: 0.3841 - val_loss: 14.4114 - val_accuracy: 0.3708\n",
      "Epoch 319/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 19.1262 - accuracy: 0.3801 - val_loss: 13.7290 - val_accuracy: 0.3894\n",
      "Epoch 320/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 19.1616 - accuracy: 0.3835 - val_loss: 15.0646 - val_accuracy: 0.3866\n",
      "Epoch 321/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.3697 - accuracy: 0.3876 - val_loss: 14.1035 - val_accuracy: 0.3835\n",
      "Epoch 322/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 19.2285 - accuracy: 0.3798 - val_loss: 13.6240 - val_accuracy: 0.3730\n",
      "Epoch 323/500\n",
      "7128/7128 [==============================] - 7s 919us/step - loss: 18.8230 - accuracy: 0.3845 - val_loss: 13.3739 - val_accuracy: 0.3609\n",
      "Epoch 324/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 19.4404 - accuracy: 0.3831 - val_loss: 13.3086 - val_accuracy: 0.3898\n",
      "Epoch 325/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 18.8848 - accuracy: 0.3819 - val_loss: 13.3847 - val_accuracy: 0.3899\n",
      "Epoch 326/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.5200 - accuracy: 0.3848 - val_loss: 13.1898 - val_accuracy: 0.3901\n",
      "Epoch 327/500\n",
      "7128/7128 [==============================] - 6s 893us/step - loss: 19.1027 - accuracy: 0.3860 - val_loss: 13.7715 - val_accuracy: 0.3911\n",
      "Epoch 328/500\n",
      "7128/7128 [==============================] - 6s 894us/step - loss: 19.4566 - accuracy: 0.3833 - val_loss: 15.6909 - val_accuracy: 0.3524\n",
      "Epoch 329/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 19.1348 - accuracy: 0.3807 - val_loss: 13.9486 - val_accuracy: 0.3888\n",
      "Epoch 330/500\n",
      "7128/7128 [==============================] - 6s 898us/step - loss: 19.0553 - accuracy: 0.3848 - val_loss: 13.9463 - val_accuracy: 0.3843\n",
      "Epoch 331/500\n",
      "7128/7128 [==============================] - 6s 899us/step - loss: 19.2832 - accuracy: 0.3841 - val_loss: 17.6612 - val_accuracy: 0.4015\n",
      "Epoch 332/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 19.1679 - accuracy: 0.3853 - val_loss: 14.7261 - val_accuracy: 0.3899\n",
      "Epoch 333/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 18.7986 - accuracy: 0.3836 - val_loss: 13.0861 - val_accuracy: 0.3846\n",
      "Epoch 334/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.5641 - accuracy: 0.3820 - val_loss: 14.4939 - val_accuracy: 0.3566\n",
      "Epoch 335/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 18.8520 - accuracy: 0.3820 - val_loss: 13.5844 - val_accuracy: 0.3838\n",
      "Epoch 336/500\n",
      "7128/7128 [==============================] - 6s 894us/step - loss: 19.1297 - accuracy: 0.3833 - val_loss: 14.0085 - val_accuracy: 0.3980\n",
      "Epoch 337/500\n",
      "7128/7128 [==============================] - 6s 897us/step - loss: 19.2019 - accuracy: 0.3835 - val_loss: 13.4732 - val_accuracy: 0.3797\n",
      "Epoch 338/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 19.2436 - accuracy: 0.3843 - val_loss: 13.3813 - val_accuracy: 0.3684\n",
      "Epoch 339/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 19.0579 - accuracy: 0.3760 - val_loss: 14.1133 - val_accuracy: 0.3832\n",
      "Epoch 340/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 19.2372 - accuracy: 0.3825 - val_loss: 13.3411 - val_accuracy: 0.3877\n",
      "Epoch 341/500\n",
      "7128/7128 [==============================] - 6s 893us/step - loss: 18.9573 - accuracy: 0.3833 - val_loss: 14.9104 - val_accuracy: 0.3814\n",
      "Epoch 342/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 18.9591 - accuracy: 0.3842 - val_loss: 13.9136 - val_accuracy: 0.3665\n",
      "Epoch 343/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.3475 - accuracy: 0.3860 - val_loss: 13.1323 - val_accuracy: 0.3903\n",
      "Epoch 344/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 19.2549 - accuracy: 0.3871 - val_loss: 13.1651 - val_accuracy: 0.3809\n",
      "Epoch 345/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 19.1568 - accuracy: 0.3880 - val_loss: 13.6109 - val_accuracy: 0.3814\n",
      "Epoch 346/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 19.0446 - accuracy: 0.3815 - val_loss: 14.5246 - val_accuracy: 0.3559\n",
      "Epoch 347/500\n",
      "7128/7128 [==============================] - 6s 900us/step - loss: 19.8904 - accuracy: 0.3829 - val_loss: 14.4315 - val_accuracy: 0.3936\n",
      "Epoch 348/500\n",
      "7128/7128 [==============================] - 6s 893us/step - loss: 19.0990 - accuracy: 0.3871 - val_loss: 13.7200 - val_accuracy: 0.3780\n",
      "Epoch 349/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.4264 - accuracy: 0.3791 - val_loss: 14.0325 - val_accuracy: 0.3603\n",
      "Epoch 350/500\n",
      "7128/7128 [==============================] - 6s 895us/step - loss: 18.8833 - accuracy: 0.3870 - val_loss: 13.1153 - val_accuracy: 0.3898\n",
      "Epoch 351/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 19.2044 - accuracy: 0.3851 - val_loss: 13.8527 - val_accuracy: 0.3861\n",
      "Epoch 352/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 19.2456 - accuracy: 0.3807 - val_loss: 16.2133 - val_accuracy: 0.3563\n",
      "Epoch 353/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 18.8268 - accuracy: 0.3813 - val_loss: 15.0015 - val_accuracy: 0.3732\n",
      "Epoch 354/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 19.1502 - accuracy: 0.3813 - val_loss: 13.4667 - val_accuracy: 0.3800\n",
      "Epoch 355/500\n",
      "7128/7128 [==============================] - 6s 892us/step - loss: 19.0142 - accuracy: 0.3852 - val_loss: 13.4514 - val_accuracy: 0.3843\n",
      "Epoch 356/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 19.0790 - accuracy: 0.3859 - val_loss: 13.7004 - val_accuracy: 0.3745\n",
      "Epoch 357/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 19.1067 - accuracy: 0.3863 - val_loss: 16.8096 - val_accuracy: 0.3659\n",
      "Epoch 358/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.2948 - accuracy: 0.3845 - val_loss: 14.3210 - val_accuracy: 0.3620\n",
      "Epoch 359/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 18.8612 - accuracy: 0.3826 - val_loss: 15.5034 - val_accuracy: 0.3590\n",
      "Epoch 360/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 19.3560 - accuracy: 0.3875 - val_loss: 13.3915 - val_accuracy: 0.3950\n",
      "Epoch 361/500\n",
      "7128/7128 [==============================] - 6s 892us/step - loss: 19.0230 - accuracy: 0.3855 - val_loss: 14.0676 - val_accuracy: 0.3773\n",
      "Epoch 362/500\n",
      "7128/7128 [==============================] - 6s 894us/step - loss: 18.6303 - accuracy: 0.3818 - val_loss: 15.2846 - val_accuracy: 0.3913\n",
      "Epoch 363/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 878us/step - loss: 19.0826 - accuracy: 0.3854 - val_loss: 14.1923 - val_accuracy: 0.3934\n",
      "Epoch 364/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 18.9513 - accuracy: 0.3858 - val_loss: 13.6669 - val_accuracy: 0.3957\n",
      "Epoch 365/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 18.6798 - accuracy: 0.3862 - val_loss: 14.9857 - val_accuracy: 0.3959\n",
      "Epoch 366/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 19.0373 - accuracy: 0.3863 - val_loss: 13.4531 - val_accuracy: 0.3944\n",
      "Epoch 367/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.5117 - accuracy: 0.3831 - val_loss: 13.6066 - val_accuracy: 0.3800\n",
      "Epoch 368/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 18.7862 - accuracy: 0.3798 - val_loss: 13.6974 - val_accuracy: 0.3646\n",
      "Epoch 369/500\n",
      "7128/7128 [==============================] - 6s 887us/step - loss: 19.0559 - accuracy: 0.3839 - val_loss: 13.8735 - val_accuracy: 0.3832\n",
      "Epoch 370/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.2373 - accuracy: 0.3796 - val_loss: 15.8838 - val_accuracy: 0.3971\n",
      "Epoch 371/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 18.5713 - accuracy: 0.3842 - val_loss: 13.2259 - val_accuracy: 0.3917\n",
      "Epoch 372/500\n",
      "7128/7128 [==============================] - 6s 872us/step - loss: 19.1677 - accuracy: 0.3852 - val_loss: 13.4363 - val_accuracy: 0.3708\n",
      "Epoch 373/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 19.1665 - accuracy: 0.3825 - val_loss: 14.6871 - val_accuracy: 0.3799\n",
      "Epoch 374/500\n",
      "7128/7128 [==============================] - 6s 891us/step - loss: 19.1510 - accuracy: 0.3796 - val_loss: 15.0734 - val_accuracy: 0.3753\n",
      "Epoch 375/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.1133 - accuracy: 0.3903 - val_loss: 13.1997 - val_accuracy: 0.3903\n",
      "Epoch 376/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 19.1376 - accuracy: 0.3844 - val_loss: 13.1212 - val_accuracy: 0.3871\n",
      "Epoch 377/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.2459 - accuracy: 0.3856 - val_loss: 13.2190 - val_accuracy: 0.3882\n",
      "Epoch 378/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 19.0997 - accuracy: 0.3847 - val_loss: 13.9996 - val_accuracy: 0.3544\n",
      "Epoch 379/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 18.5439 - accuracy: 0.3854 - val_loss: 15.8016 - val_accuracy: 0.4100\n",
      "Epoch 380/500\n",
      "7128/7128 [==============================] - 6s 856us/step - loss: 19.1468 - accuracy: 0.3854 - val_loss: 13.9388 - val_accuracy: 0.3979\n",
      "Epoch 381/500\n",
      "7128/7128 [==============================] - 6s 850us/step - loss: 18.9468 - accuracy: 0.3843 - val_loss: 13.4630 - val_accuracy: 0.3884\n",
      "Epoch 382/500\n",
      "7128/7128 [==============================] - 6s 854us/step - loss: 18.6713 - accuracy: 0.3832 - val_loss: 15.5765 - val_accuracy: 0.3523\n",
      "Epoch 383/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 18.7178 - accuracy: 0.3855 - val_loss: 15.9465 - val_accuracy: 0.3614\n",
      "Epoch 384/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 18.9285 - accuracy: 0.3842 - val_loss: 14.1267 - val_accuracy: 0.3921\n",
      "Epoch 385/500\n",
      "7128/7128 [==============================] - 6s 855us/step - loss: 19.0929 - accuracy: 0.3815 - val_loss: 15.0323 - val_accuracy: 0.3609\n",
      "Epoch 386/500\n",
      "7128/7128 [==============================] - 6s 864us/step - loss: 18.8365 - accuracy: 0.3886 - val_loss: 14.0085 - val_accuracy: 0.3872\n",
      "Epoch 387/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 18.6381 - accuracy: 0.3814 - val_loss: 13.9630 - val_accuracy: 0.3726\n",
      "Epoch 388/500\n",
      "7128/7128 [==============================] - 6s 873us/step - loss: 19.3232 - accuracy: 0.3849 - val_loss: 13.7462 - val_accuracy: 0.3855\n",
      "Epoch 389/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 18.9015 - accuracy: 0.3841 - val_loss: 14.2239 - val_accuracy: 0.3712\n",
      "Epoch 390/500\n",
      "7128/7128 [==============================] - 6s 880us/step - loss: 18.7368 - accuracy: 0.3871 - val_loss: 13.3823 - val_accuracy: 0.3830\n",
      "Epoch 391/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 18.6596 - accuracy: 0.3807 - val_loss: 13.7570 - val_accuracy: 0.3753\n",
      "Epoch 392/500\n",
      "7128/7128 [==============================] - 6s 859us/step - loss: 19.5766 - accuracy: 0.3869 - val_loss: 13.6013 - val_accuracy: 0.3963\n",
      "Epoch 393/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 19.1806 - accuracy: 0.3859 - val_loss: 15.4488 - val_accuracy: 0.3781\n",
      "Epoch 394/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 18.6280 - accuracy: 0.3846 - val_loss: 13.7567 - val_accuracy: 0.3793\n",
      "Epoch 395/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 18.8212 - accuracy: 0.3835 - val_loss: 13.5836 - val_accuracy: 0.3830\n",
      "Epoch 396/500\n",
      "7128/7128 [==============================] - 6s 885us/step - loss: 18.9059 - accuracy: 0.3827 - val_loss: 13.8446 - val_accuracy: 0.3927\n",
      "Epoch 397/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 18.6818 - accuracy: 0.3883 - val_loss: 13.8928 - val_accuracy: 0.3742\n",
      "Epoch 398/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 19.0496 - accuracy: 0.3819 - val_loss: 15.7923 - val_accuracy: 0.4025\n",
      "Epoch 399/500\n",
      "7128/7128 [==============================] - 6s 859us/step - loss: 18.7875 - accuracy: 0.3840 - val_loss: 15.6260 - val_accuracy: 0.3977\n",
      "Epoch 400/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.9125 - accuracy: 0.3830 - val_loss: 14.1796 - val_accuracy: 0.3938\n",
      "Epoch 401/500\n",
      "7128/7128 [==============================] - 6s 881us/step - loss: 18.9109 - accuracy: 0.3865 - val_loss: 14.8918 - val_accuracy: 0.3719\n",
      "Epoch 402/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 19.1266 - accuracy: 0.3855 - val_loss: 14.8513 - val_accuracy: 0.3999\n",
      "Epoch 403/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 19.0639 - accuracy: 0.3875 - val_loss: 13.8906 - val_accuracy: 0.3799\n",
      "Epoch 404/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 18.8885 - accuracy: 0.3853 - val_loss: 13.5959 - val_accuracy: 0.3875\n",
      "Epoch 405/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 18.5783 - accuracy: 0.3836 - val_loss: 14.2166 - val_accuracy: 0.3712\n",
      "Epoch 406/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 19.0332 - accuracy: 0.3835 - val_loss: 13.2342 - val_accuracy: 0.3948\n",
      "Epoch 407/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 18.7148 - accuracy: 0.3857 - val_loss: 14.9149 - val_accuracy: 0.3840\n",
      "Epoch 408/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 19.0695 - accuracy: 0.3829 - val_loss: 14.2399 - val_accuracy: 0.3869\n",
      "Epoch 409/500\n",
      "7128/7128 [==============================] - 6s 861us/step - loss: 19.4215 - accuracy: 0.3852 - val_loss: 13.8818 - val_accuracy: 0.3767\n",
      "Epoch 410/500\n",
      "7128/7128 [==============================] - 6s 858us/step - loss: 18.7567 - accuracy: 0.3869 - val_loss: 14.3941 - val_accuracy: 0.3676\n",
      "Epoch 411/500\n",
      "7128/7128 [==============================] - 6s 864us/step - loss: 18.9381 - accuracy: 0.3857 - val_loss: 13.9690 - val_accuracy: 0.3922\n",
      "Epoch 412/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 18.5597 - accuracy: 0.3836 - val_loss: 13.7544 - val_accuracy: 0.3641\n",
      "Epoch 413/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 18.4272 - accuracy: 0.3862 - val_loss: 14.4702 - val_accuracy: 0.3827\n",
      "Epoch 414/500\n",
      "7128/7128 [==============================] - 6s 889us/step - loss: 18.6609 - accuracy: 0.3834 - val_loss: 15.0825 - val_accuracy: 0.3947\n",
      "Epoch 415/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 18.4202 - accuracy: 0.3863 - val_loss: 14.7021 - val_accuracy: 0.3697\n",
      "Epoch 416/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 18.6800 - accuracy: 0.3811 - val_loss: 13.7835 - val_accuracy: 0.3744\n",
      "Epoch 417/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 867us/step - loss: 18.7823 - accuracy: 0.3857 - val_loss: 14.5470 - val_accuracy: 0.3873\n",
      "Epoch 418/500\n",
      "7128/7128 [==============================] - 6s 867us/step - loss: 18.9010 - accuracy: 0.3834 - val_loss: 14.2905 - val_accuracy: 0.3901\n",
      "Epoch 419/500\n",
      "7128/7128 [==============================] - 6s 864us/step - loss: 18.3955 - accuracy: 0.3805 - val_loss: 14.2173 - val_accuracy: 0.3674\n",
      "Epoch 420/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.4370 - accuracy: 0.3834 - val_loss: 13.6345 - val_accuracy: 0.3750\n",
      "Epoch 421/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 18.7429 - accuracy: 0.3880 - val_loss: 13.7483 - val_accuracy: 0.3837\n",
      "Epoch 422/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.8466 - accuracy: 0.3882 - val_loss: 13.3968 - val_accuracy: 0.4000\n",
      "Epoch 423/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 18.7629 - accuracy: 0.3853 - val_loss: 13.8091 - val_accuracy: 0.3761\n",
      "Epoch 424/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 18.9194 - accuracy: 0.3858 - val_loss: 13.4337 - val_accuracy: 0.3794\n",
      "Epoch 425/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 18.7974 - accuracy: 0.3857 - val_loss: 14.3531 - val_accuracy: 0.3995\n",
      "Epoch 426/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 18.7088 - accuracy: 0.3861 - val_loss: 14.4124 - val_accuracy: 0.3916\n",
      "Epoch 427/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.7724 - accuracy: 0.3899 - val_loss: 13.8083 - val_accuracy: 0.3914\n",
      "Epoch 428/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 18.8512 - accuracy: 0.3844 - val_loss: 13.8308 - val_accuracy: 0.3872\n",
      "Epoch 429/500\n",
      "7128/7128 [==============================] - 6s 861us/step - loss: 18.9059 - accuracy: 0.3813 - val_loss: 13.9711 - val_accuracy: 0.3808\n",
      "Epoch 430/500\n",
      "7128/7128 [==============================] - 6s 858us/step - loss: 18.6204 - accuracy: 0.3844 - val_loss: 14.0048 - val_accuracy: 0.3685\n",
      "Epoch 431/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 19.2123 - accuracy: 0.3908 - val_loss: 13.4015 - val_accuracy: 0.3995\n",
      "Epoch 432/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 19.0897 - accuracy: 0.3875 - val_loss: 14.1624 - val_accuracy: 0.3921\n",
      "Epoch 433/500\n",
      "7128/7128 [==============================] - 6s 864us/step - loss: 18.9734 - accuracy: 0.3873 - val_loss: 13.8871 - val_accuracy: 0.3808\n",
      "Epoch 434/500\n",
      "7128/7128 [==============================] - 6s 856us/step - loss: 18.4560 - accuracy: 0.3870 - val_loss: 14.3225 - val_accuracy: 0.3776\n",
      "Epoch 435/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 18.5845 - accuracy: 0.3830 - val_loss: 14.4415 - val_accuracy: 0.3672\n",
      "Epoch 436/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 18.7246 - accuracy: 0.3842 - val_loss: 13.7680 - val_accuracy: 0.3835\n",
      "Epoch 437/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 18.8999 - accuracy: 0.3834 - val_loss: 14.3448 - val_accuracy: 0.3831\n",
      "Epoch 438/500\n",
      "7128/7128 [==============================] - 6s 875us/step - loss: 18.8365 - accuracy: 0.3814 - val_loss: 14.1358 - val_accuracy: 0.3848\n",
      "Epoch 439/500\n",
      "7128/7128 [==============================] - 6s 856us/step - loss: 19.1362 - accuracy: 0.3859 - val_loss: 14.1130 - val_accuracy: 0.3810\n",
      "Epoch 440/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 18.9421 - accuracy: 0.3771 - val_loss: 13.3988 - val_accuracy: 0.3891\n",
      "Epoch 441/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.4766 - accuracy: 0.3844 - val_loss: 14.9832 - val_accuracy: 0.3911\n",
      "Epoch 442/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.5223 - accuracy: 0.3880 - val_loss: 13.4352 - val_accuracy: 0.3844\n",
      "Epoch 443/500\n",
      "7128/7128 [==============================] - 6s 854us/step - loss: 18.8642 - accuracy: 0.3842 - val_loss: 14.0252 - val_accuracy: 0.3748\n",
      "Epoch 444/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.5780 - accuracy: 0.3829 - val_loss: 15.3919 - val_accuracy: 0.3669\n",
      "Epoch 445/500\n",
      "7128/7128 [==============================] - 6s 876us/step - loss: 18.4664 - accuracy: 0.3840 - val_loss: 13.4624 - val_accuracy: 0.3845\n",
      "Epoch 446/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.3565 - accuracy: 0.3859 - val_loss: 15.0031 - val_accuracy: 0.3872\n",
      "Epoch 447/500\n",
      "7128/7128 [==============================] - 6s 870us/step - loss: 18.7244 - accuracy: 0.3822 - val_loss: 14.1900 - val_accuracy: 0.3653\n",
      "Epoch 448/500\n",
      "7128/7128 [==============================] - 6s 861us/step - loss: 18.6551 - accuracy: 0.3823 - val_loss: 13.9196 - val_accuracy: 0.3922\n",
      "Epoch 449/500\n",
      "7128/7128 [==============================] - 6s 865us/step - loss: 18.9434 - accuracy: 0.3852 - val_loss: 13.5903 - val_accuracy: 0.3832\n",
      "Epoch 450/500\n",
      "7128/7128 [==============================] - 6s 878us/step - loss: 18.7694 - accuracy: 0.3849 - val_loss: 13.8269 - val_accuracy: 0.4012\n",
      "Epoch 451/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 18.3837 - accuracy: 0.3840 - val_loss: 13.5918 - val_accuracy: 0.3889\n",
      "Epoch 452/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.4807 - accuracy: 0.3864 - val_loss: 14.1154 - val_accuracy: 0.4022\n",
      "Epoch 453/500\n",
      "7128/7128 [==============================] - 6s 860us/step - loss: 18.6024 - accuracy: 0.3871 - val_loss: 13.6983 - val_accuracy: 0.3743\n",
      "Epoch 454/500\n",
      "7128/7128 [==============================] - 6s 879us/step - loss: 18.7762 - accuracy: 0.3819 - val_loss: 13.7324 - val_accuracy: 0.3778\n",
      "Epoch 455/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.6372 - accuracy: 0.3825 - val_loss: 14.1165 - val_accuracy: 0.4020\n",
      "Epoch 456/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 18.9042 - accuracy: 0.3841 - val_loss: 13.4627 - val_accuracy: 0.3886\n",
      "Epoch 457/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 18.6326 - accuracy: 0.3849 - val_loss: 14.2507 - val_accuracy: 0.3808\n",
      "Epoch 458/500\n",
      "7128/7128 [==============================] - 6s 877us/step - loss: 18.6683 - accuracy: 0.3876 - val_loss: 13.8227 - val_accuracy: 0.3762\n",
      "Epoch 459/500\n",
      "7128/7128 [==============================] - 6s 867us/step - loss: 18.3586 - accuracy: 0.3874 - val_loss: 14.5154 - val_accuracy: 0.3823\n",
      "Epoch 460/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 18.5247 - accuracy: 0.3835 - val_loss: 14.3927 - val_accuracy: 0.3880\n",
      "Epoch 461/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 18.6311 - accuracy: 0.3871 - val_loss: 13.7888 - val_accuracy: 0.3939\n",
      "Epoch 462/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 18.6029 - accuracy: 0.3869 - val_loss: 14.0358 - val_accuracy: 0.3827\n",
      "Epoch 463/500\n",
      "7128/7128 [==============================] - 6s 886us/step - loss: 18.4805 - accuracy: 0.3883 - val_loss: 14.1288 - val_accuracy: 0.3961\n",
      "Epoch 464/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 18.6892 - accuracy: 0.3870 - val_loss: 14.1324 - val_accuracy: 0.3938\n",
      "Epoch 465/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.2689 - accuracy: 0.3875 - val_loss: 13.4699 - val_accuracy: 0.3917\n",
      "Epoch 466/500\n",
      "7128/7128 [==============================] - 6s 866us/step - loss: 19.3840 - accuracy: 0.3755 - val_loss: 13.3897 - val_accuracy: 0.3818\n",
      "Epoch 467/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.3858 - accuracy: 0.3844 - val_loss: 13.3623 - val_accuracy: 0.3753\n",
      "Epoch 468/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.3220 - accuracy: 0.3840 - val_loss: 13.7176 - val_accuracy: 0.3847\n",
      "Epoch 469/500\n",
      "7128/7128 [==============================] - 6s 858us/step - loss: 18.7305 - accuracy: 0.3887 - val_loss: 13.4440 - val_accuracy: 0.3827\n",
      "Epoch 470/500\n",
      "7128/7128 [==============================] - 6s 867us/step - loss: 18.3804 - accuracy: 0.3836 - val_loss: 15.5159 - val_accuracy: 0.3793\n",
      "Epoch 471/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128/7128 [==============================] - 6s 864us/step - loss: 18.4359 - accuracy: 0.3852 - val_loss: 14.1709 - val_accuracy: 0.3940\n",
      "Epoch 472/500\n",
      "7128/7128 [==============================] - 6s 883us/step - loss: 18.4897 - accuracy: 0.3842 - val_loss: 13.5738 - val_accuracy: 0.3956\n",
      "Epoch 473/500\n",
      "7128/7128 [==============================] - 6s 859us/step - loss: 18.2355 - accuracy: 0.3858 - val_loss: 14.6484 - val_accuracy: 0.3811\n",
      "Epoch 474/500\n",
      "7128/7128 [==============================] - 6s 847us/step - loss: 18.8441 - accuracy: 0.3844 - val_loss: 15.3670 - val_accuracy: 0.3968\n",
      "Epoch 475/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.4698 - accuracy: 0.3829 - val_loss: 13.8726 - val_accuracy: 0.3908\n",
      "Epoch 476/500\n",
      "7128/7128 [==============================] - 6s 882us/step - loss: 18.4752 - accuracy: 0.3827 - val_loss: 13.7370 - val_accuracy: 0.3800\n",
      "Epoch 477/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.2698 - accuracy: 0.3852 - val_loss: 15.1962 - val_accuracy: 0.3675\n",
      "Epoch 478/500\n",
      "7128/7128 [==============================] - 6s 869us/step - loss: 18.1199 - accuracy: 0.3824 - val_loss: 14.4797 - val_accuracy: 0.3736\n",
      "Epoch 479/500\n",
      "7128/7128 [==============================] - 6s 867us/step - loss: 18.4401 - accuracy: 0.3835 - val_loss: 14.4191 - val_accuracy: 0.3894\n",
      "Epoch 480/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.1722 - accuracy: 0.3868 - val_loss: 15.4878 - val_accuracy: 0.3552\n",
      "Epoch 481/500\n",
      "7128/7128 [==============================] - 6s 861us/step - loss: 18.3570 - accuracy: 0.3840 - val_loss: 13.4215 - val_accuracy: 0.3909\n",
      "Epoch 482/500\n",
      "7128/7128 [==============================] - 6s 854us/step - loss: 18.5801 - accuracy: 0.3856 - val_loss: 14.6715 - val_accuracy: 0.3525\n",
      "Epoch 483/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 18.6568 - accuracy: 0.3827 - val_loss: 13.8093 - val_accuracy: 0.3915\n",
      "Epoch 484/500\n",
      "7128/7128 [==============================] - 6s 862us/step - loss: 17.9608 - accuracy: 0.3855 - val_loss: 14.1077 - val_accuracy: 0.3934\n",
      "Epoch 485/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 18.5549 - accuracy: 0.3866 - val_loss: 13.3525 - val_accuracy: 0.3941\n",
      "Epoch 486/500\n",
      "7128/7128 [==============================] - 6s 864us/step - loss: 18.2074 - accuracy: 0.3874 - val_loss: 13.7406 - val_accuracy: 0.3785\n",
      "Epoch 487/500\n",
      "7128/7128 [==============================] - 6s 868us/step - loss: 18.3093 - accuracy: 0.3856 - val_loss: 13.4142 - val_accuracy: 0.3817\n",
      "Epoch 488/500\n",
      "7128/7128 [==============================] - 6s 888us/step - loss: 18.7859 - accuracy: 0.3829 - val_loss: 13.8823 - val_accuracy: 0.3843\n",
      "Epoch 489/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.5380 - accuracy: 0.3899 - val_loss: 15.7725 - val_accuracy: 0.3793\n",
      "Epoch 490/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.1752 - accuracy: 0.3860 - val_loss: 14.5826 - val_accuracy: 0.3625\n",
      "Epoch 491/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 18.5803 - accuracy: 0.3852 - val_loss: 13.7352 - val_accuracy: 0.3915\n",
      "Epoch 492/500\n",
      "7128/7128 [==============================] - 6s 890us/step - loss: 17.9279 - accuracy: 0.3846 - val_loss: 19.6355 - val_accuracy: 0.3368\n",
      "Epoch 493/500\n",
      "7128/7128 [==============================] - 6s 861us/step - loss: 19.3229 - accuracy: 0.3858 - val_loss: 13.3151 - val_accuracy: 0.3929\n",
      "Epoch 494/500\n",
      "7128/7128 [==============================] - 6s 863us/step - loss: 18.3612 - accuracy: 0.3865 - val_loss: 15.0699 - val_accuracy: 0.4016\n",
      "Epoch 495/500\n",
      "7128/7128 [==============================] - 6s 857us/step - loss: 18.4798 - accuracy: 0.3858 - val_loss: 14.4553 - val_accuracy: 0.3992\n",
      "Epoch 496/500\n",
      "7128/7128 [==============================] - 6s 852us/step - loss: 18.1275 - accuracy: 0.3855 - val_loss: 15.3225 - val_accuracy: 0.3672\n",
      "Epoch 497/500\n",
      "7128/7128 [==============================] - 6s 859us/step - loss: 18.4223 - accuracy: 0.3847 - val_loss: 13.7959 - val_accuracy: 0.3905\n",
      "Epoch 498/500\n",
      "7128/7128 [==============================] - 6s 884us/step - loss: 18.2007 - accuracy: 0.3843 - val_loss: 15.0476 - val_accuracy: 0.3679\n",
      "Epoch 499/500\n",
      "7128/7128 [==============================] - 6s 871us/step - loss: 18.3572 - accuracy: 0.3846 - val_loss: 13.2205 - val_accuracy: 0.3899\n",
      "Epoch 500/500\n",
      "7128/7128 [==============================] - 6s 874us/step - loss: 18.3521 - accuracy: 0.3905 - val_loss: 14.8319 - val_accuracy: 0.3892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d836d37288>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_name = \"models/model2\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 0, \n",
    "                                                save_best_only = True, mode ='auto')\n",
    "\n",
    "# Use the training data to fit (train) the model\n",
    "model2.fit(x_train,y_train,epochs=500,shuffle=True,verbose=1,validation_split = 0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "\n",
    "# ### BEGIN SOLUTION\n",
    "# X_scaler = StandardScaler().fit(X_train)\n",
    "# y_scaler = StandardScaler().fit(y_train)\n",
    "# ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "\n",
    "# ### BEGIN SOLUTION\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n",
    "# y_train_scaled = y_scaler.transform(y_train)\n",
    "# y_test_scaled = y_scaler.transform(y_test)\n",
    "# ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "import matplotlib.pyplot as plt\n",
    "predictions = model.predict(X_test)\n",
    "model.fit(X_train, Y_train)\n",
    "plt.scatter(model.predict(X_train), model.predict(X_train) - Y_train, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test), model.predict(X_test) - Y_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=Y_test.min(), xmax=Y_test.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1296157597528031, R2: 0.6047753732457466\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(Y_test, predictions)\n",
    "r2 = model.score(X_test, Y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.13632306261153787, R2: 0.5843234523224975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry Randall\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3618.0772938282425, tolerance: 4.510977062214414\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "lasso = Lasso(alpha=.01).fit(X_train,Y_train)\n",
    "\n",
    "predictions = lasso.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(Y_test, predictions)\n",
    "r2 = lasso.score(X_test, Y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.12961576234800976, R2: 0.6047753653324375\n"
     ]
    }
   ],
   "source": [
    "# Ridge model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ridge = Ridge(alpha=.01).fit(X_train, Y_train)\n",
    "\n",
    "predictions = ridge.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(Y_test, predictions)\n",
    "r2 = ridge.score(X_test, Y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.13309605623259924, R2: 0.5941632464500171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry Randall\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6453.513917290298, tolerance: 4.510977062214414\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "elasticnet = ElasticNet(alpha=.01).fit(X_train, Y_train)\n",
    "\n",
    "predictions = elasticnet.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(Y_test, predictions)\n",
    "r2 = elasticnet.score(X_test, Y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5703215010059912\n",
      "Testing Data Score: 0.6047753732457466\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train, Y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01032129]\n",
      "[[ 5.69035226e-06  2.76916134e-02 -6.71143068e-02  3.96267527e-02\n",
      "   6.95781171e-02 -5.15320030e-02 -5.47750671e-03 -1.80393622e-01\n",
      "   3.35354373e-01  3.48086345e-01  2.93163437e-01]]\n"
     ]
    }
   ],
   "source": [
    "#To retrieve the intercept:\n",
    "print(model.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.752262500000143\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_cases_processed=pd.DataFrame([],columns=['day1','day2','day3','day4','day5','day6','day7','day8'])\n",
    "state_cases_popcorrected=pd.DataFrame([],columns=['day1','day2','day3','day4','day5','day6','day7','day8'])\n",
    "cols=state_cases_processed.columns\n",
    "[r,c]=state_cases.shape\n",
    "for j in range (0,r):\n",
    "    pop=state_heatmap.iloc[j,3]\n",
    "    for i in range (1,c-7):\n",
    "        temp=pd.DataFrame(state_cases.iloc[j,i:i+8]).T\n",
    "        if temp.iloc[0,1]>0:\n",
    "            pop_temp=(temp*100000)/pop\n",
    "            new_cols = {x: y for x, y in zip(temp.columns, cols)}\n",
    "            state_cases_processed = state_cases_processed.append(temp.rename(columns=new_cols))\n",
    "            state_cases_popcorrected = state_cases_popcorrected.append(pop_temp.rename(columns=new_cols))\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.4193765\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "# state_cases_processed=pd.DataFrame([],columns=['day1','day2','day3','day4','day5','day6','day7','day8'])\n",
    "state_cases_popcorrected=pd.DataFrame([],columns=['day1','day2','day3','day4','day5','day6','day7','day8'])\n",
    "cols=state_cases_popcorrected.columns\n",
    "[r,c]=state_cases.shape\n",
    "for j in range (0,r):\n",
    "    pop=state_heatmap.iloc[j,3]\n",
    "    for i in range (1,c-7):\n",
    "        temp=pd.DataFrame(state_cases.iloc[j,i:i+8]).T\n",
    "        if temp.iloc[0,1]>0:\n",
    "            pop_temp=(temp*100000)/pop\n",
    "            new_cols = {x: y for x, y in zip(temp.columns, cols)}\n",
    "#             state_cases_processed = state_cases_processed.append(temp.rename(columns=new_cols))\n",
    "            state_cases_popcorrected = state_cases_popcorrected.append(pop_temp.rename(columns=new_cols))\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.918957699999737\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "# state_cases_processed=pd.DataFrame([],columns=['day1','day2','day3','day4','day5','day6','day7','day8'])\n",
    "state_cases_popcorrected=pd.DataFrame([],columns=['day1','day2','day3','day4','day5','day6','day7','day8'])\n",
    "cols=state_cases_popcorrected.columns\n",
    "[r,c]=state_cases.shape\n",
    "for j in range (0,r):\n",
    "    pop=state_heatmap.iloc[j,3]\n",
    "    for i in range (1,c-7):\n",
    "        if state_cases.iloc[j,i+1]>0:\n",
    "            temp=pd.DataFrame(state_cases.iloc[j,i:i+8]).T\n",
    "            pop_temp=(temp*100000)/pop\n",
    "            new_cols = {x: y for x, y in zip(temp.columns, cols)}\n",
    "#             state_cases_processed = state_cases_processed.append(temp.rename(columns=new_cols))\n",
    "            state_cases_popcorrected = state_cases_popcorrected.append(pop_temp.rename(columns=new_cols))\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2520"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_cases.iloc[j,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45681120000062947\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "state_cases_popcorrected={}\n",
    "k=0\n",
    "[r,c]=state_cases.shape\n",
    "for j in range (0,r):\n",
    "    pop=state_heatmap.iloc[j,3]\n",
    "    for i in range (1,c-7):\n",
    "        if state_cases.iloc[j,i+1]>0:\n",
    "            state_cases_popcorrected[k] = {\"day1\": (state_cases.iloc[j,i]*100000)/pop,\"day2\": (state_cases.iloc[j,i+1]*100000)/pop,\"day3\": (state_cases.iloc[j,i+2]*100000)/pop,\"day4\": (state_cases.iloc[j,i+3]*100000)/pop,\"day5\": (state_cases.iloc[j,i+4]*100000)/pop,\"day6\": (state_cases.iloc[j,i+5]*100000)/pop,\"day7\": (state_cases.iloc[j,i+6]*100000)/pop,\"day8\":(state_cases.iloc[j,i+7]*100000)/pop}\n",
    "            k=k+1\n",
    "state_cases_popcorrected = pd.DataFrame.from_dict(state_cases_popcorrected, \"index\")\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "      <th>day5</th>\n",
       "      <th>day6</th>\n",
       "      <th>day7</th>\n",
       "      <th>day8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "      <td>3.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "      <td>3.202000</td>\n",
       "      <td>3.997402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7625</th>\n",
       "      <td>405.522851</td>\n",
       "      <td>415.544294</td>\n",
       "      <td>422.628417</td>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>415.544294</td>\n",
       "      <td>422.628417</td>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>422.628417</td>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "      <td>478.437484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "      <td>478.437484</td>\n",
       "      <td>485.176040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "      <td>478.437484</td>\n",
       "      <td>485.176040</td>\n",
       "      <td>492.087380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7630 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day1        day2        day3        day4        day5        day6  \\\n",
       "0       0.000000    0.101975    0.142764    0.224344    0.591452    0.795401   \n",
       "1       0.101975    0.142764    0.224344    0.591452    0.795401    1.040140   \n",
       "2       0.142764    0.224344    0.591452    0.795401    1.040140    1.590803   \n",
       "3       0.224344    0.591452    0.795401    1.040140    1.590803    2.161860   \n",
       "4       0.591452    0.795401    1.040140    1.590803    2.161860    2.671733   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "7625  405.522851  415.544294  422.628417  427.639138  435.414395  447.336456   \n",
       "7626  415.544294  422.628417  427.639138  435.414395  447.336456  454.075012   \n",
       "7627  422.628417  427.639138  435.414395  447.336456  454.075012  464.096455   \n",
       "7628  427.639138  435.414395  447.336456  454.075012  464.096455  471.007794   \n",
       "7629  435.414395  447.336456  454.075012  464.096455  471.007794  478.437484   \n",
       "\n",
       "            day7        day8  \n",
       "0       1.040140    1.590803  \n",
       "1       1.590803    2.161860  \n",
       "2       2.161860    2.671733  \n",
       "3       2.671733    3.202000  \n",
       "4       3.202000    3.997402  \n",
       "...          ...         ...  \n",
       "7625  454.075012  464.096455  \n",
       "7626  464.096455  471.007794  \n",
       "7627  471.007794  478.437484  \n",
       "7628  478.437484  485.176040  \n",
       "7629  485.176040  492.087380  \n",
       "\n",
       "[7630 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_cases_popcorrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "      <th>day5</th>\n",
       "      <th>day6</th>\n",
       "      <th>day7</th>\n",
       "      <th>day8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "      <td>3.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "      <td>3.202000</td>\n",
       "      <td>3.997402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7625</th>\n",
       "      <td>405.522851</td>\n",
       "      <td>415.544294</td>\n",
       "      <td>422.628417</td>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>415.544294</td>\n",
       "      <td>422.628417</td>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>422.628417</td>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "      <td>478.437484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>427.639138</td>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "      <td>478.437484</td>\n",
       "      <td>485.176040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>435.414395</td>\n",
       "      <td>447.336456</td>\n",
       "      <td>454.075012</td>\n",
       "      <td>464.096455</td>\n",
       "      <td>471.007794</td>\n",
       "      <td>478.437484</td>\n",
       "      <td>485.176040</td>\n",
       "      <td>492.087380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7630 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day1        day2        day3        day4        day5        day6  \\\n",
       "0       0.000000    0.101975    0.142764    0.224344    0.591452    0.795401   \n",
       "1       0.101975    0.142764    0.224344    0.591452    0.795401    1.040140   \n",
       "2       0.142764    0.224344    0.591452    0.795401    1.040140    1.590803   \n",
       "3       0.224344    0.591452    0.795401    1.040140    1.590803    2.161860   \n",
       "4       0.591452    0.795401    1.040140    1.590803    2.161860    2.671733   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "7625  405.522851  415.544294  422.628417  427.639138  435.414395  447.336456   \n",
       "7626  415.544294  422.628417  427.639138  435.414395  447.336456  454.075012   \n",
       "7627  422.628417  427.639138  435.414395  447.336456  454.075012  464.096455   \n",
       "7628  427.639138  435.414395  447.336456  454.075012  464.096455  471.007794   \n",
       "7629  435.414395  447.336456  454.075012  464.096455  471.007794  478.437484   \n",
       "\n",
       "            day7        day8  \n",
       "0       1.040140    1.590803  \n",
       "1       1.590803    2.161860  \n",
       "2       2.161860    2.671733  \n",
       "3       2.671733    3.202000  \n",
       "4       3.202000    3.997402  \n",
       "...          ...         ...  \n",
       "7625  454.075012  464.096455  \n",
       "7626  464.096455  471.007794  \n",
       "7627  471.007794  478.437484  \n",
       "7628  478.437484  485.176040  \n",
       "7629  485.176040  492.087380  \n",
       "\n",
       "[7630 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_cases_popcorrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pov</th>\n",
       "      <th>popden</th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "      <th>day5</th>\n",
       "      <th>day6</th>\n",
       "      <th>day7</th>\n",
       "      <th>rad27day1</th>\n",
       "      <th>...</th>\n",
       "      <th>rad107day6</th>\n",
       "      <th>rad107day7</th>\n",
       "      <th>7day1</th>\n",
       "      <th>7day2</th>\n",
       "      <th>7day3</th>\n",
       "      <th>7day4</th>\n",
       "      <th>7day5</th>\n",
       "      <th>7day6</th>\n",
       "      <th>7day7</th>\n",
       "      <th>7day8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132113</td>\n",
       "      <td>0.158210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.244739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158210</td>\n",
       "      <td>0.231606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.244739</td>\n",
       "      <td>0.285529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>0.142764</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231606</td>\n",
       "      <td>0.361273</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.244739</td>\n",
       "      <td>0.285529</td>\n",
       "      <td>0.305924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>0.224344</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361273</td>\n",
       "      <td>0.440378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.244739</td>\n",
       "      <td>0.285529</td>\n",
       "      <td>0.305924</td>\n",
       "      <td>0.407898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>1.040140</td>\n",
       "      <td>1.590803</td>\n",
       "      <td>2.161860</td>\n",
       "      <td>2.671733</td>\n",
       "      <td>3.202000</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440378</td>\n",
       "      <td>0.596141</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.244739</td>\n",
       "      <td>0.285529</td>\n",
       "      <td>0.305924</td>\n",
       "      <td>0.407898</td>\n",
       "      <td>0.489478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372493</th>\n",
       "      <td>16.492958</td>\n",
       "      <td>2.960801</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>3.274523</td>\n",
       "      <td>...</td>\n",
       "      <td>12.411708</td>\n",
       "      <td>11.706079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372494</th>\n",
       "      <td>16.492958</td>\n",
       "      <td>2.960801</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>3.929427</td>\n",
       "      <td>...</td>\n",
       "      <td>11.706079</td>\n",
       "      <td>10.926726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372495</th>\n",
       "      <td>16.492958</td>\n",
       "      <td>2.960801</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>2.947071</td>\n",
       "      <td>...</td>\n",
       "      <td>10.926726</td>\n",
       "      <td>11.190021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372496</th>\n",
       "      <td>16.492958</td>\n",
       "      <td>2.960801</td>\n",
       "      <td>57.745056</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>3.929427</td>\n",
       "      <td>...</td>\n",
       "      <td>11.190021</td>\n",
       "      <td>10.458062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372497</th>\n",
       "      <td>16.492958</td>\n",
       "      <td>2.960801</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>72.181319</td>\n",
       "      <td>3.274523</td>\n",
       "      <td>...</td>\n",
       "      <td>10.458062</td>\n",
       "      <td>10.200033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380111 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pov     popden       day1       day2       day3       day4  \\\n",
       "0       17.049426  96.054497   0.000000   0.101975   0.142764   0.224344   \n",
       "1       17.049426  96.054497   0.101975   0.142764   0.224344   0.591452   \n",
       "2       17.049426  96.054497   0.142764   0.224344   0.591452   0.795401   \n",
       "3       17.049426  96.054497   0.224344   0.591452   0.795401   1.040140   \n",
       "4       17.049426  96.054497   0.591452   0.795401   1.040140   1.590803   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "372493  16.492958   2.960801  57.745056  57.745056  57.745056  57.745056   \n",
       "372494  16.492958   2.960801  57.745056  57.745056  57.745056  72.181319   \n",
       "372495  16.492958   2.960801  57.745056  57.745056  72.181319  72.181319   \n",
       "372496  16.492958   2.960801  57.745056  72.181319  72.181319  72.181319   \n",
       "372497  16.492958   2.960801  72.181319  72.181319  72.181319  72.181319   \n",
       "\n",
       "             day5       day6       day7  rad27day1  ...  rad107day6  \\\n",
       "0        0.591452   0.795401   1.040140   0.000000  ...    0.132113   \n",
       "1        0.795401   1.040140   1.590803   0.000000  ...    0.158210   \n",
       "2        1.040140   1.590803   2.161860   0.020395  ...    0.231606   \n",
       "3        1.590803   2.161860   2.671733   0.000000  ...    0.361273   \n",
       "4        2.161860   2.671733   3.202000   0.081580  ...    0.440378   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "372493  72.181319  72.181319  72.181319   3.274523  ...   12.411708   \n",
       "372494  72.181319  72.181319  72.181319   3.929427  ...   11.706079   \n",
       "372495  72.181319  72.181319  72.181319   2.947071  ...   10.926726   \n",
       "372496  72.181319  72.181319  72.181319   3.929427  ...   11.190021   \n",
       "372497  72.181319  72.181319  72.181319   3.274523  ...   10.458062   \n",
       "\n",
       "        rad107day7     7day1     7day2     7day3     7day4     7day5  \\\n",
       "0         0.158210  0.000000  0.000000  0.020395  0.000000  0.081580   \n",
       "1         0.231606  0.000000  0.020395  0.000000  0.081580  0.101975   \n",
       "2         0.361273  0.020395  0.000000  0.081580  0.101975  0.101975   \n",
       "3         0.440378  0.000000  0.081580  0.101975  0.101975  0.244739   \n",
       "4         0.596141  0.081580  0.101975  0.101975  0.244739  0.285529   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "372493   11.706079  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "372494   10.926726  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "372495   11.190021  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "372496   10.458062  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "372497   10.200033  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "           7day6     7day7     7day8  \n",
       "0       0.101975  0.101975  0.244739  \n",
       "1       0.101975  0.244739  0.285529  \n",
       "2       0.244739  0.285529  0.305924  \n",
       "3       0.285529  0.305924  0.407898  \n",
       "4       0.305924  0.407898  0.489478  \n",
       "...          ...       ...       ...  \n",
       "372493  0.000000  0.000000  0.000000  \n",
       "372494  0.000000  0.000000  0.000000  \n",
       "372495  0.000000  0.000000  0.000000  \n",
       "372496  0.000000  0.000000  0.000000  \n",
       "372497  0.000000  0.000000  0.000000  \n",
       "\n",
       "[380111 rows x 38 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_popcorrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pov</th>\n",
       "      <th>popden</th>\n",
       "      <th>casesday1</th>\n",
       "      <th>casesday2</th>\n",
       "      <th>casesday3</th>\n",
       "      <th>casesday4</th>\n",
       "      <th>casesday5</th>\n",
       "      <th>casesday6</th>\n",
       "      <th>casesday7</th>\n",
       "      <th>7caseday1</th>\n",
       "      <th>...</th>\n",
       "      <th>day6</th>\n",
       "      <th>day7</th>\n",
       "      <th>7day1</th>\n",
       "      <th>7day2</th>\n",
       "      <th>7day3</th>\n",
       "      <th>7day4</th>\n",
       "      <th>7day5</th>\n",
       "      <th>7day6</th>\n",
       "      <th>7day7</th>\n",
       "      <th>7day8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>4.935567</td>\n",
       "      <td>7.770459</td>\n",
       "      <td>10.544167</td>\n",
       "      <td>11.971810</td>\n",
       "      <td>14.154065</td>\n",
       "      <td>16.825798</td>\n",
       "      <td>18.335021</td>\n",
       "      <td>0.571057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203949</td>\n",
       "      <td>0.203949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.040790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>7.770459</td>\n",
       "      <td>10.544167</td>\n",
       "      <td>11.971810</td>\n",
       "      <td>14.154065</td>\n",
       "      <td>16.825798</td>\n",
       "      <td>18.335021</td>\n",
       "      <td>20.129773</td>\n",
       "      <td>0.917771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203949</td>\n",
       "      <td>0.469083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.081580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>10.544167</td>\n",
       "      <td>11.971810</td>\n",
       "      <td>14.154065</td>\n",
       "      <td>16.825798</td>\n",
       "      <td>18.335021</td>\n",
       "      <td>20.129773</td>\n",
       "      <td>21.618601</td>\n",
       "      <td>1.244089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469083</td>\n",
       "      <td>0.550662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.040790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>11.971810</td>\n",
       "      <td>14.154065</td>\n",
       "      <td>16.825798</td>\n",
       "      <td>18.335021</td>\n",
       "      <td>20.129773</td>\n",
       "      <td>21.618601</td>\n",
       "      <td>25.146920</td>\n",
       "      <td>1.121720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550662</td>\n",
       "      <td>0.652637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.122369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.049426</td>\n",
       "      <td>96.054497</td>\n",
       "      <td>14.154065</td>\n",
       "      <td>16.825798</td>\n",
       "      <td>18.335021</td>\n",
       "      <td>20.129773</td>\n",
       "      <td>21.618601</td>\n",
       "      <td>25.146920</td>\n",
       "      <td>30.490385</td>\n",
       "      <td>1.631593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652637</td>\n",
       "      <td>0.775006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.101975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197613</th>\n",
       "      <td>11.274222</td>\n",
       "      <td>2.049831</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197614</th>\n",
       "      <td>11.274222</td>\n",
       "      <td>2.049831</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197615</th>\n",
       "      <td>11.274222</td>\n",
       "      <td>2.049831</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197616</th>\n",
       "      <td>11.274222</td>\n",
       "      <td>2.049831</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197617</th>\n",
       "      <td>11.274222</td>\n",
       "      <td>2.049831</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>260.509177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>11.841326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204455 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pov     popden   casesday1   casesday2   casesday3   casesday4  \\\n",
       "0       17.049426  96.054497    4.935567    7.770459   10.544167   11.971810   \n",
       "1       17.049426  96.054497    7.770459   10.544167   11.971810   14.154065   \n",
       "2       17.049426  96.054497   10.544167   11.971810   14.154065   16.825798   \n",
       "3       17.049426  96.054497   11.971810   14.154065   16.825798   18.335021   \n",
       "4       17.049426  96.054497   14.154065   16.825798   18.335021   20.129773   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "197613  11.274222   2.049831  260.509177  260.509177  260.509177  260.509177   \n",
       "197614  11.274222   2.049831  260.509177  260.509177  260.509177  260.509177   \n",
       "197615  11.274222   2.049831  260.509177  260.509177  260.509177  260.509177   \n",
       "197616  11.274222   2.049831  260.509177  260.509177  260.509177  260.509177   \n",
       "197617  11.274222   2.049831  260.509177  260.509177  260.509177  260.509177   \n",
       "\n",
       "         casesday5   casesday6   casesday7  7caseday1  ...       day6  \\\n",
       "0        14.154065   16.825798   18.335021   0.571057  ...   0.203949   \n",
       "1        16.825798   18.335021   20.129773   0.917771  ...   0.203949   \n",
       "2        18.335021   20.129773   21.618601   1.244089  ...   0.469083   \n",
       "3        20.129773   21.618601   25.146920   1.121720  ...   0.550662   \n",
       "4        21.618601   25.146920   30.490385   1.631593  ...   0.652637   \n",
       "...            ...         ...         ...        ...  ...        ...   \n",
       "197613  260.509177  260.509177  260.509177   0.000000  ...  11.841326   \n",
       "197614  260.509177  260.509177  260.509177   0.000000  ...  11.841326   \n",
       "197615  260.509177  260.509177  260.509177   0.000000  ...  11.841326   \n",
       "197616  260.509177  260.509177  260.509177   0.000000  ...  11.841326   \n",
       "197617  260.509177  260.509177  260.509177   0.000000  ...  11.841326   \n",
       "\n",
       "             day7  7day1     7day2     7day3     7day4     7day5     7day6  \\\n",
       "0        0.203949    0.0  0.000000  0.000000  0.000000  0.000000  0.020395   \n",
       "1        0.469083    0.0  0.000000  0.000000  0.000000  0.020395  0.020395   \n",
       "2        0.550662    0.0  0.000000  0.000000  0.020395  0.020395  0.040790   \n",
       "3        0.652637    0.0  0.000000  0.020395  0.020395  0.040790  0.081580   \n",
       "4        0.775006    0.0  0.020395  0.020395  0.040790  0.081580  0.040790   \n",
       "...           ...    ...       ...       ...       ...       ...       ...   \n",
       "197613  11.841326    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "197614  11.841326    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "197615  11.841326    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "197616  11.841326    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "197617  11.841326    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "           7day7     7day8  \n",
       "0       0.020395  0.040790  \n",
       "1       0.040790  0.081580  \n",
       "2       0.081580  0.040790  \n",
       "3       0.040790  0.122369  \n",
       "4       0.122369  0.101975  \n",
       "...          ...       ...  \n",
       "197613  0.000000  0.000000  \n",
       "197614  0.000000  0.000000  \n",
       "197615  0.000000  0.000000  \n",
       "197616  0.000000  0.000000  \n",
       "197617  0.000000  0.000000  \n",
       "\n",
       "[204455 rows x 32 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_popcorrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Outdated- categorical\n",
    "\n",
    "# model2 = Sequential()\n",
    "# model2.add(Dense(27, activation='relu', input_dim=x_train.shape[1]))\n",
    "# # Add a second hidden layer\n",
    "# model2.add(Dense(52, activation='relu'))\n",
    "# model2.add(Dense(104, activation='relu'))\n",
    "# model2.add(Dense(208, activation='relu'))\n",
    "# model2.add(Dense(416, activation='relu'))\n",
    "# model2.add(Dense(832, activation='relu'))\n",
    "# model2.add(Dense(1664, activation='relu'))\n",
    "# model2.add(Dense(3328, activation='relu'))\n",
    "# model2.add(Dense(6656, activation='relu'))\n",
    "# y_train = to_categorical(y_train)\n",
    "# # Add output layer\n",
    "# model2.add(Dense(y_train.shape[1], activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
